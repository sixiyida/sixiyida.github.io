[{"content":"LangSmith调研记录 主要功能 Observability - 可观测性\nEvaluation - 评估，指的是评估什么？\nPrompt Engineering - 提示词工具？\nObservation Trace OpenAI模型调用 1 2 3 from langsmith.wrappers import wrap_openai openai_client = wrap_openai(OpenAI()) 使用wrapper包装client，就可以接入langsmith。\nTrace整个应用 使用@traceable装饰器：\n1 2 3 4 5 6 7 8 9 10 11 12 from openai import OpenAI from langsmith import traceable from langsmith.wrappers import wrap_openai openai_client = wrap_openai(OpenAI()) def retriever(query: str): //... @traceable def rag(question): //... 注：Traceable可以装饰任何函数，装饰后就可以在LangSmith观测input和output。\nTrace召回 使用@traceable装饰器：\n1 2 3 4 @traceable(run_type=\u0026#34;retriever\u0026#34;) def retriever(query: str): results = [\u0026#34;Harrison worked at Kensho\u0026#34;] return results Feedback/Metadata 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 //MetaData //方式1：在装饰器中加元数据 @traceable(metadata={\u0026#34;llm\u0026#34;: \u0026#34;gpt-4o-mini\u0026#34;}) def rag(question): //... //方式2：在调用后加参数 import uuid run_id = str(uuid.uuid4()) rag( \u0026#34;where did harrison work\u0026#34;, langsmith_extra={\u0026#34;run_id\u0026#34;: run_id, \u0026#34;metadata\u0026#34;: {\u0026#34;user_id\u0026#34;: \u0026#34;harrison\u0026#34;}} ) //反馈与metadata相关联的feedback from langsmith import Client ls_client = Client() ls_client.create_feedback( run_id, key=\u0026#34;user-score\u0026#34;, score=1.0, ) 异步任务提交Trace 1 2 3 4 5 6 7 8 9 10 11 12 13 from langsmith import Client client = Client() @traceable(client=client) async def my_traced_func(): # Your code here... pass try: await my_traced_func() finally: await client.flush() ","date":"2025-06-26T00:00:00Z","permalink":"https://sixiyida.github.io/p/langsmith%E8%B0%83%E7%A0%94%E8%AE%B0%E5%BD%95/","title":"LangSmith调研记录"},{"content":"可观测性的三大支柱 日志Log 用于回溯和调试，略。\n指标Metrics Metrics 是系统运行状态的量化数据，通常是随时间变化的数值。比如：\n每秒处理的请求数（QPS） 请求平均耗时（RT） 服务器CPU使用率 错误请求的比例 追踪Traces Traces 用于记录一个请求在分布式系统中的完整执行路径。想象用户一次点击，可能经过网关→订单服务→库存服务→支付服务→数据库。Traces 能完整还原这个链条中每一步发生了什么、花了多久。\n核心概念：Span（跨度） 每个服务处理请求的过程被记录为一个 Span，包含：\n操作名（如createOrder） 开始/结束时间戳 关键属性（HTTP状态码、DB查询语句） 父子关系（哪个服务调用了哪个服务） Trace ID：贯穿全链路的唯一标识，用于串联所有Span 工具解释 Micrometer 核心作用： Micrometer 是 ​​Java 应用的指标埋点门面库​​，提供统一 API（如计数器、计时器），让开发者无需关心后端监控系统（Prometheus、Datadog 等）。\n数据流向： 应用代码埋点 → Micrometer 生成指标数据 → 直接输出给 Prometheus。\n示例场景： 在 Spring Boot 中配置 Micrometer 的 Prometheus 导出器，指标会通过 /actuator/prometheus 端点暴露，供 Prometheus 拉取。\nOpenTelemetry（OTel） OTel是跨语言的可观测数据采集框架，统一处理 Metrics、Traces、Logs 的生成、转换和导出。\n与Micrometer的关系：OTel SDK可以包装Micrometer注册的 MeterRegistry ，将数据通过OTLP协议导出。\nTraces场景下：\nOTel是Trace 数据的主要采集器，可将Trace数据发给SkyWalking、Jaeger等。\nPrometheus 核心作用： 专注 ​​指标（Metrics）的存储、查询和告警​​，不处理 Trace 数据。\n与 Micrometer 协作： Micrometer 将指标暴露为 Prometheus 格式 → Prometheus 定时拉取并存储 → Grafana 可视化\nSkyWalking 定位：开源APM (Application Performance Management) 系统，专注于全链路追踪（Tracing） 和拓扑分析。\n核心能力：\n**调用链追踪：**记录请求跨服务的完整路径，可视化每个环节耗时与状态（Span 数据）。 服务拓扑：自动绘制服务依赖关系图，快速定位瓶颈节点。 指标集成：支持基础资源（JVM/线程池）和链路指标（慢请求比例）。 OTLP协议 OTLP（OpenTelemetry Protocol）是OpenTelemetry项目定义的标准数据传输协议，用于在分布式系统中高效、可靠地传输遥测数据（包括追踪信息、指标和日志）。\n传输方式 协议 默认端口 适用场景 OTLP/gRPC gRPC + Protobuf 4317 高性能内部通信（如应用→收集器） OTLP/HTTP HTTP/1.1或HTTP/2 + Protobuf/JSON 4318 穿透防火墙或兼容HTTP的环境 数据路径：\n应用 →（OTLP/gRPC）→ OpenTelemetry Collector →（转换格式）→ Prometheus/Jaeger。\n阿里云ARMS 定位：企业级全栈监控产品，整合日志、指标、追踪能力。\n兼容 OpenTelemetry、SkyWalking 等开源协议。\nMicrometer和OTel集成 Springboot对于Micrometer和OTel的集成做的较好，我们主要关注Micrometer的采集即可。\nMicrometer最佳实践 Micrometer Observation API的官方推荐架构模式：\n📋 Documentation (文档定义) ↓ 定义标准\n🎛️ Convention (约定实现) ↓ 处理规则\n📦 Context (上下文数据) ↓ 数据载体\n🔧 Handler (处理器执行) ↓ 实际处理\n📊 Metrics \u0026amp; Logs (输出结果)\nContext 是实际观测数据的载体，存储需要观测的所有信息。以GraphObservation实现为例：\n1 2 3 4 5 6 7 8 9 10 11 public class GraphNodeObservationContext extends Observation.Context { private final String nodeName; // 节点名称 private final String event; // 事件类型 (onStart/before/after/onError/onComplete) private final Map\u0026lt;String, Object\u0026gt; state; // 节点状态 private final Map\u0026lt;String, Object\u0026gt; output; // 节点输出 // 构造函数 + Getter方法 + Builder模式 public static Builder builder() { return new Builder(); } } Documentation 是制定的观测标准，约定观测的标签、指标名称等，同时分类高低基数标签。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 public enum GraphNodeObservationDocumentation implements ObservationDocumentation { GRAPH_NODE { @Override public Class\u0026lt;? extends ObservationConvention\u0026lt;? extends Context\u0026gt;\u0026gt; getDefaultConvention() { return GraphNodeObservationConvention.class; // 👈 指定约定类 } @Override public KeyName[] getLowCardinalityKeyNames() { return LowCardinalityKeyNames.values(); // 👈 低基数标签 } @Override public KeyName[] getHighCardinalityKeyNames() { return HighCardinalityKeyNames.values(); // 👈 高基数标签 } }; // 低基数标签定义 (适合聚合查询) public enum LowCardinalityKeyNames implements KeyName { SPRING_AI_ALIBABA_KIND, // spring.ai.alibaba.kind GRAPH_NODE_NAME, // spring.ai.alibaba.graph.node.name GRAPH_EVENT // spring.ai.alibaba.graph.event } // 高基数标签定义 (详细信息) public enum HighCardinalityKeyNames implements KeyName { GRAPH_NODE_STATE, // spring.ai.alibaba.graph.node.state GRAPH_NODE_OUTPUT // spring.ai.alibaba.graph.node.output } } Convention 处理Documentation，分离高低基数标签，将Context数据转换为观测标签。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 public class DefaultGraphNodeObservationConvention implements GraphNodeObservationConvention { @Override public String getName() { return \u0026#34;spring.ai.alibaba.graph.node\u0026#34;; // 👈 观测名称 } @Override public String getContextualName(GraphNodeObservationContext context) { if (StringUtils.hasText(context.getName())) { return \u0026#34;%s %s\u0026#34;.formatted(DEFAULT_OPERATION_NAME, context.getName()); } return DEFAULT_OPERATION_NAME; // 👈 上下文名称生成 } @Override public KeyValues getLowCardinalityKeyValues(GraphNodeObservationContext context) { return KeyValues.of( KeyValue.of(\u0026#34;spring.ai.alibaba.kind\u0026#34;, \u0026#34;graph_node\u0026#34;), KeyValue.of(\u0026#34;spring.ai.alibaba.graph.node.name\u0026#34;, context.getNodeName()), KeyValue.of(\u0026#34;spring.ai.alibaba.graph.event\u0026#34;, context.getEvent()) ); // 👈 低基数标签生成 } @Override public KeyValues getHighCardinalityKeyValues(GraphNodeObservationContext context) { return KeyValues.of( KeyValue.of(\u0026#34;spring.ai.alibaba.graph.node.state\u0026#34;, context.getState().toString()), KeyValue.of(\u0026#34;spring.ai.alibaba.graph.node.output\u0026#34;, context.getOutput().toString()) ); // 👈 高基数标签生成 } } Handler 处理观测的事件，具体作用参见组件协作流程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 public class GraphNodeObservationHandler implements ObservationHandler\u0026lt;GraphNodeObservationContext\u0026gt; { private final MeterRegistry meterRegistry; @Override public void onStop(GraphNodeObservationContext context) { // 1. 记录成功日志 logger.info(\u0026#34;Graph nodeName: {} event: {} state: {} output: {}\u0026#34;, context.getNodeName(), context.getEvent(), context.getState(), context.getOutput()); // 2. 生成成功指标 GraphMetricsGenerator.generate(context, meterRegistry, true); } @Override public void onError(GraphNodeObservationContext context) { // 1. 记录错误日志 logger.error(\u0026#34;Graph nodeName: {} event: {} state: {} output: {}\u0026#34;, ...); // 2. 生成失败指标 GraphMetricsGenerator.generate(context, meterRegistry, false); } @Override public boolean supportsContext(Observation.Context context) { return context instanceof GraphNodeObservationContext; // 👈 支持类型判断 } } 组件协作流程 当创建一个观测时：\n1 2 3 4 // 1. 创建观测时 Observation.start(GraphObservationDocumentation.GRAPH.getName(), () -\u0026gt; new GraphObservationContext(nodeId, state, null), observationRegistry) 会发生以下步骤：\n首先根据Observation传入的Convention将Context里面的数据转换成KeyValue对（其中Convention会从对应的Documentation里面去找高低基数键和名字） Convention的应用在Handler被调用之前，他会给Observation.Context基类中添加Convention标准化后的KeyValue，然后这个Context会被后续的Handler所使用 然后被注册到ObservationReg里面的Handler，会使用MetricsGenerator去创建Metrics，同时Metrics会注册到meterReg里面 MetircsGenerator会创建所需要的Tag，包括直接创建的和被KeyValue中的Key所转换的。 ObservationReg的作用 作用和职责：\nHandler 管理：注册和管理 ObservationHandler Convention 管理：管理观测约定（如何转换Context为标签） Filter 管理：管理观测过滤器 观测生命周期控制：协调观测的创建、启动、停止 MeterReg的作用 作用和职责：\n指标管理中心：创建、注册和管理所有的指标对象（Counter、Timer、Gauge等） 指标数据存储：在内存中维护指标的当前值 指标数据发布：将收集的指标数据发布到各种监控系统 Trace相关 刚刚的最佳实践仅仅落脚在metrics，关于trace，并没有说明。\n在SpringBoot中，当有Micrometer Tracing桥接库时候，自动配置会生效，配置TracingObservationHandler以及相关组件。\n1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.micrometer\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;micrometer-tracing-bridge-otel\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; TracingObservationHandler 会被自动注册到 ObservationRegistry 中，监听 start、stop、error 等事件，生成对应的 Span 数据。\n基本概念的区分 Tag和Metrics的关系 Tag是Metrics的组成部分，一个完整的Metric由name + tags + value组成。\n1 2 3 4 5 6 7 // 一个完整的Metric由 name + tags + value 组成 Counter.builder(\u0026#34;api.requests\u0026#34;) // ← Metric名称 .tag(\u0026#34;method\u0026#34;, \u0026#34;GET\u0026#34;) // ← Tag 1 .tag(\u0026#34;status\u0026#34;, \u0026#34;200\u0026#34;) // ← Tag 2 .tag(\u0026#34;endpoint\u0026#34;, \u0026#34;/users\u0026#34;) // ← Tag 3 .register(registry) .increment(); // ← 值的操作 同时，Tag可以为Metric提供聚合能力，比如可以筛选出Tag=特定值的Metric个数。\n聚合以后的Metrics，也可以叫做Metric，更精准的叫法是Calculated Metric。\nTag的基数 高低基数是Tag的分类依据，基数是什么意思呢，就是说Tag的可能值。比如Tag的key是用户用时，那么可能的value就会非常多，就是高基数Tag。反之，Tag的key可能是RESTful API的method，那一共就那么几种，就是低基数Tag。\nSpan和Metrics的关系 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // Metric 示例：聚合统计 Counter.builder(\u0026#34;http.requests.total\u0026#34;) .tag(\u0026#34;method\u0026#34;, \u0026#34;GET\u0026#34;) .tag(\u0026#34;status\u0026#34;, \u0026#34;200\u0026#34;) .register(registry) .increment(); // 结果：http_requests_total{method=\u0026#34;GET\u0026#34;,status=\u0026#34;200\u0026#34;} 1500 // Span 示例：单个请求详情 Span span = tracer.spanBuilder(\u0026#34;http-request\u0026#34;) .setAttribute(\u0026#34;http.method\u0026#34;, \u0026#34;GET\u0026#34;) .setAttribute(\u0026#34;http.url\u0026#34;, \u0026#34;/api/users/12345\u0026#34;) .setAttribute(\u0026#34;http.status_code\u0026#34;, 200) .setAttribute(\u0026#34;user.id\u0026#34;, \u0026#34;12345\u0026#34;) .setAttribute(\u0026#34;response.size\u0026#34;, 2048) .startSpan(); 对比来看，Span是微观视图，Metric是宏观视图。\nTrace和Span的关系 Trace的基本单位是一个一个的span，多个span通过parent-child关系组成完整的Trace。\n每个span包含：\n1 2 3 4 5 6 7 8 9 10 11 12 { \u0026#34;traceId\u0026#34;: \u0026#34;c227f936a3eb510e7da12fda10a8ffab\u0026#34;, \u0026#34;spanId\u0026#34;: \u0026#34;884c2f1abf7f956b\u0026#34;, \u0026#34;parentSpanId\u0026#34;: \u0026#34;293e5b7de78ff24c\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;chat qwen-max\u0026#34;, \u0026#34;kind\u0026#34;: 1, \u0026#34;startTimeUnixNano\u0026#34;: \u0026#34;1733482368328941400\u0026#34;, \u0026#34;endTimeUnixNano\u0026#34;: \u0026#34;1733482372190192300\u0026#34;, \u0026#34;attributes\u0026#34;: [...], \u0026#34;events\u0026#34;: [...], \u0026#34;status\u0026#34;: {...} } Span的上传时机 自动上传时机：\nSpan完成时：当一个操作结束，对应的span会自动结束并触发上传\n缓冲区满时：当内存中积累的span数据达到一定大小（如1MB）时批量上传\n定时上传：OpenTelemetry SDK会定期flush未上传的span\n应用关闭时：通过shutdown()方法确保所有span都被上传\n手动上传时机：\n调用flush()：可以手动触发span上传\n应用重启前：确保数据不丢失\nspan结束后的上传：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Override public CompletableResultCode export(Collection\u0026lt;SpanData\u0026gt; spans) { if (!studioObservabilityProperties.isEnabled()) { return CompletableResultCode.ofSuccess(); } if (isShutdown.get()) { return CompletableResultCode.ofFailure(); } // 立即处理span数据 ResourceSpansMarshaler[] allResourceSpans = ResourceSpansMarshaler.create(spans); return studioObservabilityService.export(List.of(allResourceSpans)); } 到达阈值后批量上传：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 try (BufferedWriter writer = Files.newBufferedWriter(outputPath, StandardOpenOption.APPEND)) { StringBuilder sb = new StringBuilder(); for (ResourceSpansMarshaler resourceSpans : allResourceSpans) { String json = generateJson(resourceSpans); sb.append(json).append(LINE_SEPARATOR); // 当缓存达到1MB时批量写入 if (sb.length() \u0026gt; 1024 * 1024) { writer.write(sb.toString()); sb.setLength(0); } } if (!sb.isEmpty()) { writer.write(sb.toString()); } } Spring AI通过OTel与Langfuse集成 Spring AI实现了基于micrometer的埋点，可以轻松的使用OTLP协议导出，进而实现观测数据上传至Langfuse。\n引入依赖 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-actuator\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud.ai\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-ai-alibaba-starter-dashscope\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.ai\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-ai-autoconfigure-model-chat-observation\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.ai\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-ai-autoconfigure-model-embedding-observation\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.ai\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-ai-autoconfigure-model-image-observation\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.ai\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-ai-autoconfigure-vector-store-observation\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.ai\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-ai-vector-store\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud.ai\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-ai-alibaba-starter-tool-calling-weather\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.opentelemetry.instrumentation\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;opentelemetry-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.9.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.micrometer\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;micrometer-tracing-bridge-otel\u0026lt;/artifactId\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-api\u0026lt;/artifactId\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.opentelemetry\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;opentelemetry-exporter-otlp\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 配置LangFuse 注册账号、获取API Key：\nhttps://cloud.langfuse.com\nLinux/MacOS：\n1 echo -n \u0026#34;public_key:secret_key\u0026#34; | base64 Windows PowerShell：\n1 [System.Convert]::ToBase64String([System.Text.Encoding]::UTF8.GetBytes(\u0026#34;public_key:secret_key\u0026#34;)) 配置application.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 spring: application: name: observability-models-dashscope ai: dashscope: api-key: ${AI_DASHSCOPE_API_KEY} # spring ai alibaba weather tool calling config alibaba: toolcalling: weather: api-key: ${WEATHER_API_KEY} enabled: true # Chat config items chat: client: observations: # default value is false. log-prompt: true observations: log-prompt: true log-completion: true include-error-logging: true # vector store config items vectorstore: observations: log-query-response: true # tools config items tools: observations: # default value is false. include-content: true image: observations: log-prompt: true http: client: read-timeout: 60s management: endpoints: web: exposure: include: \u0026#34;*\u0026#34; endpoint: health: # health status check with detailed messages show-details: always tracing: sampling: # trace information with every request probability: 1.0 observations: annotations: enabled: true otel: service: name: spring-ai-alibaba-graph-langfuse resource: attributes: deployment.environment: development # configure exporter traces: exporter: otlp sampler: always_on metrics: exporter: otlp # logs exportation inhibited for langfuse currently cannot support logs: exporter: none exporter: otlp: endpoint: \u0026#34;https://cloud.langfuse.com/api/public/otel\u0026#34; headers: Authorization: \u0026#34;Basic ${YOUR_BASE64_ENCODED_CREDENTIALS}\u0026#34; protocol: http/protobuf ","date":"2025-06-25T00:00:00Z","permalink":"https://sixiyida.github.io/p/%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7observation%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"可观测性Observation学习笔记"},{"content":"\nList ArrayList LinkedList Vector CopyOnWriteArrayList 类似C++的Vector，略 类似C++的List，略 同步ArrayList 写时复制，读无锁，提升并发性能 遍历时修改 用foreach不能修改，容易出现问题。\n用迭代器/for遍历，可以修改，迭代器修改要使用迭代器的set方法。\n对COWA，可以修改，因为在副本上修改。\nArrayList多线程访问下可能出现的问题 以多线程add元素为例。\n竞争扩容导致部分值设置为null。 竞争导致不扩容，导致越界访问。 覆盖同一位置的值。 扩容操作 类似C++中Vector，只是在Java中扩容倍数是1.5倍，而Vector是两倍。\nCOAW的线程安全 读时无锁，写时获取互斥锁并复制。\nMAP HashMap LinkedHashMap TreeMap HashTable ConcurrentHashMap unordered_map + 红黑树链地址法 双向链表维护底层，迭代顺序和插入顺序一致。 map 加大锁的HashMap 元素级锁的HashMap 遍历方法 For-each+entrySet/keySet 迭代器 foreach方法 StreamAPI HashMap竞争问题 JDK1.7之前 Entry散链死循环问题：\n由于头插法（在链表头部插入），当线程T1、T2同时扩容时，可能会出现以下情况：\nT2扩容后反转链表为B-\u0026gt;A，但是T1仍然操纵旧链表的头节点A，且认为A的next是B，导致AB之间相互指向。\n数据丢失问题：\n类似于List的扩容null问题。\nJDK1.8之后 散链改成了红黑树结构，只存在数据覆盖问题。 Put流程 前面hash-\u0026gt;CAS跳过，后续是：检查散链大小（8）-\u0026gt;转红黑树？-\u0026gt;检查负载因子-\u0026gt;扩容两倍？\n注意：key可以为null，当为null时候令hashCode为0\nHashMap用String做Key的原因 String不可变，保证Key稳定性。\n对重写hashCode()和equals()的限制 equals是hashCode相等的充分不必要条件。\nHashMap扩容是两倍的原因 新hash值=旧哈希值+新hash值最高位代表数值（0或者是旧容量）。\nConcurrentHashMap原理 1.8以后：当容器为空/散链为空，用CAS初始化；当不为空，对散链头节点加互斥锁，锁粒度减小，并发量上升。\n","date":"2025-06-24T00:00:00Z","permalink":"https://sixiyida.github.io/p/%E5%85%AB%E8%82%A1%E6%96%87%E4%B9%8Bjava%E9%9B%86%E5%90%88/","title":"八股文之Java集合"},{"content":"深拷贝的三种方法 实现clone接口，要求引用属性全部实现clonable接口，递归调用。 直接序列化然后反序列化，要求引用属性全部实现serializable接口。 手动递归复制。 反射的应用场景 加载数据库驱动，动态加载驱动类。 IOC容器自动装配，根据类名动态加载实例。（这个在spring八股里面细说） 注解 本质上是一种继承自Annotation的特殊接口，在定义注解时候，编译器会将其转换为接口并生成字节码。\n根据作用范围分类：\n源码级别注解 类文件级别注解（在.class中但是运行不可见） 运行时（在.class中运行可见） 注解的解析 所有可以被注解修饰的元素都实现了AnnotatedElement接口，底层依赖本地方法，JVM在加载类的时候会解析.class中的注解信息存储在内存中，并创建注解代理对象获取注解属性值。\n作用域 类、方法、属性、构造函数、局部变量。\n异常 Error：严重问题，程序无法处理，无法捕捉。 RuntimeException：运行时的问题，如非法内存访问。 非运行时异常：编译时候的问题，如类文件不存在等。 Try-Catch 注意：finally中的return会覆盖try中的。\nLambda表达式和匿名内部类 匿名内部类：\n1 2 3 4 new Runnable(){ @Override public void run(){} } lambda表达式：\n1 () -\u0026gt; {} //等于重写函数式接口唯一方法 异步编程 Future 表示异步计算的结果，只能阻塞或者轮询获取，不支持回调方法。\n回调地狱：指的是当异步操作需要顺序执行的时候，需要将每个操作的回调函数嵌套在上一个工作的回调中，形成深层嵌套。\nCompletableFuture 更为简洁，可读性更好。\n可以通过函数式编程思想对异步调用进行编排。\n（例子待补充）\n单例模式实现 双重检查锁定：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class SingleTon { // volatile 关键字修饰变量 防止指令重排序 private static volatile SingleTon instance = null; private SingleTon(){} public static SingleTon getInstance(){ if(instance == null){ synchronized(SingleTon.class){ if(instance == null){ instance = new SingleTon(); } } } return instance; } } **第一重检查：**优化性能，否则每次都进入方法级加锁同步。\n**第二重检查：**解决竞争问题。\n与C++对比：不支持局部静态变量。\n代理模式和适配器模式 代理模式 略。\n适配器模式 指将旧类适配新接口的新类。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 目标接口（新接口） interface PaymentProcessor { void processPayment(double amount); } // 适配者（旧类） class OldPaymentSystem { void makePayment(double amount) { System.out.println(\u0026#34;旧支付系统扣款\u0026#34;); } } // 适配器 class PaymentAdapter implements PaymentProcessor { private OldPaymentSystem oldSystem; @Override public void processPayment(double amount) { oldSystem.makePayment(amount); // 调用旧类方法 } } 对比 维度 代理模式 适配器模式 核心目标 控制对对象的访问，添加额外功能 解决接口不兼容问题，无功能增强。 角色关系 代理与目标对象实现相同接口 适配器实现目标接口，但包装适配者。 功能增强 可添加逻辑（如日志、权限） 仅转换接口，不增强功能。 应用场景 权限控制、延迟加载、远程调用 旧系统整合、第三方库兼容。 实现关键 代理持有目标对象引用 适配器持有适配者对象引用。 主要区别：就是目的不同，一个增强功能，一个转换适配。\nI/O BIO/NIO/AIO BIO 同步阻塞IO，传统java.io包。\nNIO Java1.4引入，同步非阻塞IO，包含IO多路复用，经典NIO框架是Netty，实现了Reactor和Proactor模式。\nAIO Java1.7引入，异步IO，对内存访问也是异步的。\nNative方法 类似于C++动态库加载函数 ，步骤有以下几步：\n**生成JNI头文件：**使用javah工具从你的Java类生成C/C++的头文件，这个头文件包含了所有native方法的原型。\n**编写本地代码：**使用C/C++编写本地方法的实现，并确保方法签名与生成的头文件中的原型匹配。\n**编译本地代码：**将C/C++代码编译成动态链接库（DLL，在Windows上），共享库（SO，在Linux上）。\n**加载本地库：**在Java程序中，使用System.loadLibrary()方法来加载你编译好的本地库，这样JVM就能找到并调用native方法的实现了。\n","date":"2025-06-20T00:00:00Z","permalink":"https://sixiyida.github.io/p/%E5%85%AB%E8%82%A1%E6%96%87%E4%B9%8Bjava%E5%9F%BA%E7%A1%80/","title":"八股文之Java基础"},{"content":"多线程竞争下的问题 **原子性：**互斥访问，原子操作atomic/串行访问synchronized限制。\n**可见性：**直接操作主内存，使用synchronized和volatile实现。\nvolatile\n读写直达主内存，绕过缓存。 写以后其他CPU变量的缓存自动失效强制重新加载。 有序性： 指令重排序导致的线程观测其他线程指令执行顺序不一致。\n线程的创建方式 继承Thread类，重写run()方法，用start()方法启动线程。 实现Runnable接口，函数式传给Thread构造函数。 实现Callable接口，并将其封装入FutureTask，最后函数式传给Thread构造函数。 Executor框架，executor.submit即可。 如何停止线程运行 在run方法中判断interrupted状态，如果是的话抛出异常/return。然后直接调用interrupt方法即可。如果线程正在执行Thread.sleep() / Thread.join() / Object.wait()等可中断方法，则解除阻塞并抛出异常。 根据约定变量显式判断 通过executor + future取消任务 有资源的情况下直接销毁资源，会弹出异常以退出 Java线程的状态 NEW：尚未start\nRUNNABLE：已经start等待调度/正在运行\nBLOCKED：等待锁\nWAITING：等待零一线程操作\nTIMED_WAITING：具有等待时间的等待\nTERMINATED：终止\nsleep vs wait sleep：任意位置调用，和锁无关，超时释放，释放cpu不是放锁\nwait：有锁下调用，notify/超时唤醒，作用主要是释放锁\nblocked vs waiting blocked：锁竞争失败进入，到锁可用解开阻塞，自动触发\nwaiting：特定方法主动唤醒\n线程的通信方式 Object类下wait/notify/notifyAll方法。\nLock和Condition接口：\n1 2 3 Condition condition = lock.newCondition(); condition.await(); condition.signal(); 基于volatile的共享变量\nCountDownLatch：计数同步辅助类\n1 2 3 4 5 6 CountDownLatch latch = new CountDownLatch(threadCount); new Thread(() -\u0026gt; { latch.countDown(); }).start(); latch.await(); CyclicBarrier：线程内部屏障点，等待所有/一定线程到达屏障点后继续运行。\n1 2 3 4 5 var barrier = new CyclicBarrier(threadCount, () -\u0026gt; {}); new Thread(() -\u0026gt; { barrier.await(;) }).start(); Semaphore：计数信号量，允许控制访问资源的线程数量\n1 2 3 Semaphore(int permits); // 构造函数 acquire(); // 线程内部aquire release(); // 线程内部释放 Java线程安全的保证 synchronized：通过监视器锁实现的同步代码块\nvolatile：通过直写内存/失效通知机制实现的确保变量在不同线程中的观测一致性\nlock/ReentrantLock：更多锁\nAtomic：原子操作\nThreadLocal：当前线程中的存储空间\n并发安全集合\nJUC工具类：如信号量/屏障等\n常见锁 监视器锁（sychronized）： Java提供的原子性内置锁，在同步的代码块前后加上monitorrenter和monitorexit字节码指令，底层依赖操作系统互斥锁。\n接着就是可重入锁的逻辑。\n1.6后的锁升级机制：\nNo Lock -\u0026gt; （首次访问同步块）-\u0026gt; Biased Lock(比对线程ID) -\u0026gt; (二线程锁竞争)\n-\u0026gt; 轻量级锁 (CAS) -\u0026gt; (CAS失败 )-\u0026gt; 大锁\n**轻量级锁：**线程备份锁对象Mark Word，CAS Mark Word指向备份的指针\nCAS成功：线程获得锁\nCAS失败：检查是否重入，如果重入则进入，如果不是则锁升级\n解锁：用CAS还原Mark Word\n还原成功：锁释放\n还原失败：已经是大锁，唤醒阻塞线程\n优化：锁消除（无竞争可能性消除锁）、锁粗化（多锁合一）、自旋锁（减少上下文切换开销）\nReentrantLock 引用计数，进入+1，出去-1，是0则释放锁。\n其他锁 读写锁：读写分离的锁，读和写线程分开获取锁\n乐观锁：版本号比较\n自旋锁/互斥锁：见OS\nAQS (AbstractQueuedSynchronizer) 1. 同步状态（int state） 核心共享变量（volatile int state） 由子类定义语义（例如）： ReentrantLock：重入次数 Semaphore：剩余许可数 CountDownLatch：未完成计数 2. FIFO 等待队列（CLH 变体） 双向链表结构（非严格的 CLH 队列）\n节点 Node存储线程 + 等待状态：\n1 2 3 4 5 6 static final class Node { volatile int waitStatus; // 状态：CANCELLED、SIGNAL、CONDITION等 volatile Node prev; // 前驱节点 volatile Node next; // 后继节点 volatile Thread thread; // 等待线程 } 3. 模板方法模式 子类仅需实现关键钩子方法：\n模版方法 需实现的方法 职责 acquire() tryAcquire() 尝试独占获取锁（需操作 state） release() tryRelease() 尝试独占释放锁 acquireShared() tryAcquireShared() 尝试共享获取（如 Semaphore 许可） releaseShared() tryReleaseShared() 尝试共享释放 4. 线程阻塞与唤醒机制 LockSupport.park()：阻塞当前线程 LockSupport.unpark(thread)：唤醒指定线程 ThreadLocal的原理 每个线程中都有一个独立的ThreadLocalMap，这个东西是哈希表，他的key是ThreadLocal，value是值。\n线程池的ThreadLocal泄露问题\n由于ThreadLocalMap中的value是强引用，线程不结束GC不能回收，所以由于线程池线程长久运行，导致资源无法自动释放。\nCAS的ABA问题 即CS之间存在A-\u0026gt;B-\u0026gt;A的变化，但是CAS会成功。\n解决方法：维护一个版本号（Java的办法）\nvolatile的作用 保证变量对所有线程的可见性 禁止重排序优化：保证写在所有读写完成之后，保证读在所有读写之前进行。 公平锁和非公平锁 **公平锁：**先进等待队列，需要切换两次上下文，慢\n非公平锁：先抢锁，失败进等待队列，成功则不需要切换上下文，快\nsynchronized是非公平锁，可重入锁是公平锁。\n线程池 线程池7个参数 核心线程数、最大线程数、阻塞队列、最大淘汰时间、工厂类、淘汰策略、时间单位\n拒绝策略 异常拒绝、默拒绝、主线程执行、抛弃最老任务\n线程池参数设置 CPU密集型：CPU核+1\nIO密集型：CPU核*2\n为什么不能用默认executor FixedThreadPool内部使用无界任务队列，导致如果消费速度小于生产速度，会无限堆积，导致内存占用过多OOM。\nCachedThreadPool内部使用无界任务队列，且核心线程数为0，如果生产速度大于消费速度，会导致线程无限创建，导致CPU过载等问题。\n","date":"2025-06-20T00:00:00Z","permalink":"https://sixiyida.github.io/p/%E5%85%AB%E8%82%A1%E6%96%87%E4%B9%8Bjava%E5%B9%B6%E5%8F%91/","title":"八股文之Java并发"},{"content":"spring-ai-alibaba-graph-core 源码阅读 ​\tSpring AI Alibaba Graph 是社区核心实现之一，也是整个框架在设计理念上区别于 Spring AI 只做底层原子抽象的地方，Spring AI Alibaba 期望帮助开发者更容易的构建智能体应用。基于 Graph 开发者可以构建工作流、多智能体应用。Spring AI Alibaba Graph 在设计理念上借鉴 Langgraph，因此在一定程度上可以理解为是 Java 版的 Langgraph 实现，社区在此基础上增加了大量预置 Node、简化了 State 定义过程等，让开发者更容易编写对等低代码平台的工作流、多智能体等。\n核心功能\n支持 Multi-agent，内置 ReAct Agent、Supervisor 等常规智能体模式 支持工作流，内置工作流节点，与主流低代码平台对齐 原生支持 Streaming Human-in-the-loop，通过人类确认节点，支持修改状态、恢复执行 支持记忆与持久存储 支持流程快照 支持嵌套分支、并行分支 PlantUML、Mermaid 可视化导出 1 StateGraph 1.1 基础结构 1 2 3 4 5 6 7 8 9 10 public class StateGraph { // 核心数据结构 final Nodes nodes = new Nodes(); // 存储所有节点 final Edges edges = new Edges(); // 存储所有边 // 特殊节点常量 public static final String END = \u0026#34;__END__\u0026#34;; // 结束节点 public static final String START = \u0026#34;__START__\u0026#34;; // 起始节点 public static final String ERROR = \u0026#34;__ERROR__\u0026#34;; // 错误节点 } 1.2 构造方法 1 public StateGraph(String name, KeyStrategyFactory keyStrategyFactory, PlainTextStateSerializer stateSerializer) 参数必选KeyStrategyFactory，其他可选，序列化默认JacksonSerializer()。\n1.3 节点管理 节点具体实现请见2\n1 2 3 4 5 6 7 8 public static class Nodes { public final Set\u0026lt;Node\u0026gt; elements; // 节点集合 // 节点操作方法 public boolean anyMatchById(String id) // 检查节点是否存在 public List\u0026lt;SubStateGraphNode\u0026gt; onlySubStateGraphNodes() // 获取子图节点 public List\u0026lt;Node\u0026gt; exceptSubStateGraphNodes() // 获取非子图节点 } 1.4 边管理 1 2 3 4 5 6 7 public static class Edges { public final List\u0026lt;Edge\u0026gt; elements; // 边集合 // 边操作方法 public Optional\u0026lt;Edge\u0026gt; edgeBySourceId(String sourceId) // 根据源节点查找边 public List\u0026lt;Edge\u0026gt; edgesByTargetId(String targetId) // 根据目标节点查找边 } 1.5 添加节点 1 2 3 4 5 6 7 8 // 添加普通节点 public StateGraph addNode(String id, AsyncNodeAction action) // 添加带配置的节点 public StateGraph addNode(String id, AsyncNodeActionWithConfig actionWithConfig) // 添加子图节点 public StateGraph addNode(String id, StateGraph subGraph) // 添加Command节点 public StateGraph addNode(String id, AsyncCommandAction action, Map\u0026lt;String, String\u0026gt; mappings) 1.6 添加边 1 2 3 4 // 添加普通边 public StateGraph addEdge(String sourceId, String targetId) // 添加条件边 public StateGraph addConditionalEdges(String sourceId, AsyncCommandAction condition, Map\u0026lt;String, String\u0026gt; mappings) 1.7 图验证、编译和可视化 1 2 3 4 5 6 // 验证图的正确性 void validateGraph() throws GraphStateException // 编译图 public CompiledGraph compile(CompileConfig config) throws GraphStateException // 可视化 public GraphRepresentation getGraph(GraphRepresentation.Type type, String title) 1.8 序列化器 1 2 3 static class JacksonSerializer extends JacksonStateSerializer static class GsonSerializer extends GsonStateSerializer 1.9 状态管理 1 2 3 4 // 状态工厂 private OverAllStateFactory overAllStateFactory; // 键策略工厂 private KeyStrategyFactory keyStrategyFactory; 2 Node 2.1 Node基础节点 1 2 3 4 5 6 7 8 9 public class Node { private final String id; // 节点唯一标识 private final ActionFactory actionFactory; // 动作工厂 // 动作工厂接口 public interface ActionFactory { AsyncNodeActionWithConfig apply(CompileConfig config) throws GraphStateException; } } 2.2 ParalellNode 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class ParallelNode extends Node { public static final String PARALLEL_PREFIX = \u0026#34;__PARALLEL__\u0026#34;; // 并行动作实现 record AsyncParallelNodeAction( List\u0026lt;AsyncNodeActionWithConfig\u0026gt; actions, // 并行执行的动作列表 Map\u0026lt;String, KeyStrategy\u0026gt; channels // 通道策略 ) implements AsyncNodeActionWithConfig { // 并行执行所有动作 public CompletableFuture\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; apply(OverAllState state, RunnableConfig config) { // 使用 CompletableFuture 实现并行执行 } } } 具体流转逻辑参见8.2.1.3 并行节点。\n2.3 子图节点 2.3.1 子图节点接口 1 2 3 4 5 6 7 public interface SubGraphNode { String PREFIX_FORMAT = \u0026#34;%s-%s\u0026#34;; // 节点ID格式化模板 String id(); // 获取节点ID StateGraph subGraph(); // 获取子图 String formatId(String nodeId); // 格式化节点ID } 2.3.2 状态图子图节点 1 2 3 4 5 6 7 8 public class SubStateGraphNode extends Node implements SubGraphNode { private final StateGraph subGraph; // 子图 // 格式化节点ID public String formatId(String nodeId) { return SubGraphNode.formatId(id(), nodeId); } } 2.3.3 编译后的子图节点 1 2 3 4 5 6 7 8 public class SubCompiledGraphNode extends Node implements SubGraphNode { private final CompiledGraph subGraph; // 编译后的子图 public SubCompiledGraphNode(String id, CompiledGraph subGraph) { super(id, (config) -\u0026gt; new SubCompiledGraphNodeAction(subGraph)); this.subGraph = subGraph; } } 3 Edge 3.1 基础边Edge 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public record Edge(String sourceId, List\u0026lt;EdgeValue\u0026gt; targets) { // 构造函数 public Edge(String sourceId, EdgeValue target) { this(sourceId, List.of(target)); } // 判断是否为并行边 public boolean isParallel() { return targets.size() \u0026gt; 1; } // 验证边的有效性 public void validate(StateGraph.Nodes nodes) throws GraphStateException { // 验证源节点存在 // 验证目标节点存在 // 验证并行边的目标不重复 } } 3.2 EdgeCondition 1 2 3 4 5 6 public record EdgeCondition( AsyncCommandAction action, // 异步命令动作 Map\u0026lt;String, String\u0026gt; mappings // 条件映射 ) { // 条件执行逻辑 } 3.3 EdgeValue 1 2 3 4 5 6 7 8 9 10 11 public record EdgeValue(String id, EdgeCondition value) { // 简单边值（只有ID） public EdgeValue(String id) { this(id, null); } // 条件边值（只有条件） public EdgeValue(EdgeCondition value) { this(null, value); } } 4 Command Command是一个record类，包含两个核心属性：\n1 public record Command(String gotoNode, Map\u0026lt;String, Object\u0026gt; update) Command用于用于在图的执行过程中动态地决定下一个要执行的节点并更新状态。\n4.1 CommandAction 1 2 3 4 5 6 @FunctionalInterface public interface CommandAction { Command apply(OverAllState state, RunnableConfig config) throws Exception; } 定义了返回Command的逻辑，同时，它可以是异步的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public interface AsyncCommandAction extends BiFunction\u0026lt;OverAllState, RunnableConfig, CompletableFuture\u0026lt;Command\u0026gt;\u0026gt; { static AsyncCommandAction node_async(CommandAction syncAction) { return (state, config) -\u0026gt; { var result = new CompletableFuture\u0026lt;Command\u0026gt;(); try { result.complete(syncAction.apply(state, config)); } catch (Exception e) { result.completeExceptionally(e); } return result; }; } static AsyncCommandAction of(AsyncEdgeAction action) { return (state, config) -\u0026gt; action.apply(state).thenApply(Command::new); } } 4.2 Command的使用 4.2.1 作为节点使用 1 2 3 public StateGraph addNode(String id, AsyncCommandAction action, Map\u0026lt;String, String\u0026gt; mappings) throws GraphStateException { return addNode(id, new CommandNode(id, action, mappings)); } 4.2.1.1 CommandNode apply方法直接返回一个包含有CommandAction和mappings的completeFuture。\n这块的mappings是指：当Command返回key时，跳转到value的节点。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 public class CommandNode extends Node { private final Map\u0026lt;String, String\u0026gt; mappings; private final AsyncCommandAction action; public CommandNode(String id, AsyncCommandAction action, Map\u0026lt;String, String\u0026gt; mappings) { super(id, (config) -\u0026gt; new AsyncCommandNodeActionWithConfig(action, mappings)); this.mappings = mappings; this.action = action; } public Map\u0026lt;String, String\u0026gt; getMappings() { return mappings; } public AsyncCommandAction getAction() { return action; } public record AsyncCommandNodeActionWithConfig(AsyncCommandAction action, Map\u0026lt;String, String\u0026gt; mappings) implements AsyncNodeActionWithConfig { @Override public CompletableFuture\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; apply(OverAllState state, RunnableConfig config) { return CompletableFuture.completedFuture(Map.of(\u0026#34;command\u0026#34;, action, \u0026#34;mappings\u0026#34;, mappings)); } } } 4.2.2 作为条件边的条件使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public StateGraph addConditionalEdges(String sourceId, AsyncCommandAction condition, Map\u0026lt;String, String\u0026gt; mappings) throws GraphStateException { if (Objects.equals(sourceId, END)) { throw Errors.invalidEdgeIdentifier.exception(END); } if (mappings == null || mappings.isEmpty()) { throw Errors.edgeMappingIsEmpty.exception(sourceId); } var newEdge = new Edge(sourceId, new EdgeValue(new EdgeCondition(condition, mappings))); if (edges.elements.contains(newEdge)) { throw Errors.duplicateConditionalEdgeError.exception(sourceId); } else { edges.elements.add(newEdge); } return this; } 5 OverAllState OverAllState 是状态管理的核心，它贯穿整个图的执行过程。\n所有的 Action 都需要依赖状态来执行和传递数据。\n5.1 核心数据结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public final class OverAllState implements Serializable { // 状态数据存储 private final Map\u0026lt;String, Object\u0026gt; data; // 键策略映射 private final Map\u0026lt;String, KeyStrategy\u0026gt; keyStrategies; // 恢复标志 private Boolean resume; // 人工反馈 private HumanFeedback humanFeedback; // 中断消息 private String interruptMessage; } 5.2 状态控制 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public void cover(OverAllState overAllState){ // 替换所有数据 } public OverAllState input(Map\u0026lt;String, Object\u0026gt; input) { // input是null或空直接返回 // 使用keyStrategies操作key对应value Map\u0026lt;String, KeyStrategy\u0026gt; keyStrategies = keyStrategies(); input.keySet().stream().filter(key -\u0026gt; keyStrategies.containsKey(key)).forEach(key -\u0026gt; { this.data.put(key, keyStrategies.get(key).apply(value(key, null), input.get(key))); }); return this; } public Map\u0026lt;String, Object\u0026gt; updateState(Map\u0026lt;String, Object\u0026gt; partialState) { // 用partialState更新状态，和input一样 } public static Map\u0026lt;String, Object\u0026gt; updateState(Map\u0026lt;String, Object\u0026gt; state, Map\u0026lt;String, Object\u0026gt; partialState, Map\u0026lt;String, KeyStrategy\u0026gt; keyStrategies){ // 同上 } private static Map\u0026lt;String, Object\u0026gt; updatePartialStateFromSchema(Map\u0026lt;String, Object\u0026gt; state, Map\u0026lt;String, Object\u0026gt; partialState, Map\u0026lt;String, KeyStrategy\u0026gt; keyStrategies){ // 返回更新后的partialState但不更新状态 } 5.3 策略控制 1 2 3 4 5 6 // 注册键策略 public OverAllState registerKeyAndStrategy(String key, KeyStrategy strategy) public OverAllState registerKeyAndStrategy(Map\u0026lt;String, KeyStrategy\u0026gt; keyStrategies) // 检查策略 public boolean containStrategy(String key) 6 Action 提供了Node、Edge、Command的同异步action接口，其中同步action可以转换为异步。\n1 2 3 4 5 6 7 8 9 10 // DeepResearch中的节点 public class BackgroundInvestigationNode implements NodeAction { @Override public Map\u0026lt;String, Object\u0026gt; apply(OverAllState state) throws Exception { //... return resultMap; } } 7 Config 7.1 CompileConfig CompileConfig主要用于在图编译阶段设置各种配置选项。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class CompileConfig { // 检查点保存器配置 private SaverConfig saverConfig = new SaverConfig().register(MEMORY, new MemorySaver()); // 待阅读 // 生命周期监听器队列 private Deque\u0026lt;GraphLifecycleListener\u0026gt; lifecycleListeners = new LinkedBlockingDeque\u0026lt;\u0026gt;(25); // 中断点配置 private Set\u0026lt;String\u0026gt; interruptsBefore = Set.of(); // 节点执行前中断 private Set\u0026lt;String\u0026gt; interruptsAfter = Set.of(); // 节点执行后中断 // 线程释放标志 private boolean releaseThread = false; } 一般配置用法：\n1 2 3 4 5 6 7 8 CompileConfig config = CompileConfig.builder() .interruptBefore(\u0026#34;node1\u0026#34;, \u0026#34;node2\u0026#34;) // 在node1和node2前中断 .interruptAfter(\u0026#34;node3\u0026#34;) // 在node3后中断 .withLifecycleListener(listener) // 添加生命周期监听器 .releaseThread(true) // 启用线程释放 .build(); CompiledGraph graph = stateGraph.compile(config); 7.2 RunnableConfig 主要用于在图执行过程中传递运行时参数。\nthreadId: 线程标识符，用于多线程场景\ncheckPointId: 检查点ID，用于状态恢复\nnextNode: 指定下一个要执行的节点\nstreamMode: 流模式配置\nmetadata: 自定义元数据\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 public final class RunnableConfig implements HasMetadata\u0026lt;RunnableConfig.Builder\u0026gt; { private final String threadId; private final String checkPointId; private final String nextNode; private final CompiledGraph.StreamMode streamMode; private final Map\u0026lt;String, Object\u0026gt; metadata; public CompiledGraph.StreamMode streamMode() { return streamMode; } public Optional\u0026lt;String\u0026gt; threadId() { return ofNullable(threadId); } public Optional\u0026lt;String\u0026gt; checkPointId() { return ofNullable(checkPointId); } public Optional\u0026lt;String\u0026gt; nextNode() { return ofNullable(nextNode); } public RunnableConfig withStreamMode(CompiledGraph.StreamMode streamMode) { if (this.streamMode == streamMode) { return this; } return RunnableConfig.builder(this).streamMode(streamMode).build(); } public RunnableConfig withCheckPointId(String checkPointId) { if (Objects.equals(this.checkPointId, checkPointId)) { return this; } return RunnableConfig.builder(this).checkPointId(checkPointId).build(); } 一般配置用法：\n1 2 3 4 5 6 7 8 9 RunnableConfig runConfig = RunnableConfig.builder() .threadId(\u0026#34;thread-001\u0026#34;) .checkPointId(\u0026#34;checkpoint-123\u0026#34;) .nextNode(\u0026#34;startNode\u0026#34;) .streamMode(CompiledGraph.StreamMode.VALUES) .addMetadata(\u0026#34;userId\u0026#34;, \u0026#34;user123\u0026#34;) .build(); graph.invoke(initialState, runConfig); 7.3 ActionWithConfig 主要作用就是允许Action在运行时访问RunnableConfig。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 public interface AsyncNodeActionWithConfig extends BiFunction\u0026lt;OverAllState, RunnableConfig, CompletableFuture\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt;\u0026gt; { /** * Applies this action to the given agent state. * @param state the agent state * @return a CompletableFuture representing the result of the action */ CompletableFuture\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; apply(OverAllState state, RunnableConfig config); static AsyncNodeActionWithConfig node_async(NodeActionWithConfig syncAction) { return (state, config) -\u0026gt; { CompletableFuture\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; result = new CompletableFuture\u0026lt;\u0026gt;(); try { result.complete(syncAction.apply(state, config)); } catch (Exception e) { result.completeExceptionally(e); } return result; }; } /** * Adapts a simple AsyncNodeAction to an AsyncNodeActionWithConfig. * @param action the simple AsyncNodeAction to be adapted * @return an AsyncNodeActionWithConfig that wraps the given AsyncNodeAction */ static AsyncNodeActionWithConfig of(AsyncNodeAction action) { return (t, config) -\u0026gt; action.apply(t); } } 8 CompiledGraph CompiledGraph是Graph框架的核心，提供了以下功能：\n图编译: 将StateGraph转换为可执行结构 流式执行: 支持异步流式处理 状态管理: 完整的状态历史和检查点机制 中断控制: 支持执行前后的中断点 生命周期管理: 完整的执行生命周期监听 子图支持: 递归处理子图结构 异常处理: 完善的错误处理机制 8.1 核心属性 1 2 3 4 5 6 7 public final StateGraph stateGraph; // 状态图 private final Map\u0026lt;String, KeyStrategy\u0026gt; keyStrategyMap; // 键策略映射 final Map\u0026lt;String, AsyncNodeActionWithConfig\u0026gt; nodes; // 节点映射 final Map\u0026lt;String, EdgeValue\u0026gt; edges; // 边映射 private final ProcessedNodesEdgesAndConfig processedData; // 处理后的节点和边配置 private int maxIterations = 25; // 最大迭代次数 public final CompileConfig compileConfig; // 编译配置 8.2 状态流转逻辑 8.2.1 流式模式 8.2.1.1 入口接口 以DeepResearch的实现为例子：\n1 2 3 4 5 6 7 8 9 10 11 @RequestMapping(value = \u0026#34;/chat/stream\u0026#34;, method = RequestMethod.POST, produces = MediaType.TEXT_EVENT_STREAM_VALUE) public Flux\u0026lt;ServerSentEvent\u0026lt;String\u0026gt;\u0026gt; chatStream(@RequestBody(required = false) ChatRequest chatRequest) throws GraphRunnerException { //... else { ChatRequestProcess.initializeObjectMap(chatRequest, objectMap); logger.info(\u0026#34;init inputs: {}\u0026#34;, objectMap); AsyncGenerator\u0026lt;NodeOutput\u0026gt; resultFuture = compiledGraph.stream(objectMap, runnableConfig); graphProcess.processStream(resultFuture, sink); } } 这是一个Controller接口，可以看到，图是从这个方法进去的compiledGraph.stream(objectMap, runnableConfig);。\n我们来看看具体实现：\n1 2 3 4 5 public AsyncGenerator\u0026lt;NodeOutput\u0026gt; stream(Map\u0026lt;String, Object\u0026gt; inputs, RunnableConfig config) throws GraphRunnerException { Objects.requireNonNull(config, \u0026#34;config cannot be null\u0026#34;); final AsyncNodeGenerator\u0026lt;NodeOutput\u0026gt; generator = new AsyncNodeGenerator\u0026lt;\u0026gt;(stateCreate(inputs), config); return new AsyncGenerator.WithEmbed\u0026lt;\u0026gt;(generator); } 这个地方返回了一个AsyncGenerator.WithEmbed，这玩意是什么呢？\n简而言之，这个东西是一个允许其他的AsyncGenerator在其执行过程中执行的包装类。\n执行流程是：\n从堆栈顶部获取当前生成器\n调用当前生成器的next()方法获取结果\n如果结果表示生成器已完成：\n清除之前的返回值（如果有）\n将结果推入返回值堆栈\n执行完成回调（如果有）\n如果这是最后一个生成器，返回结果\n否则，弹出当前生成器，递归调用next()继续处理下一个生成器\n如果结果包含一个嵌入生成器： 检查嵌套深度（目前不支持递归嵌套）\n将嵌入生成器推入堆栈\n递归调用next()处理嵌入生成器\n否则，直接返回结果 看看具体实现：\n1 2 protected final Deque\u0026lt;Embed\u0026lt;E\u0026gt;\u0026gt; generatorsStack = new ArrayDeque\u0026lt;\u0026gt;(2); private final Deque\u0026lt;Data\u0026lt;E\u0026gt;\u0026gt; returnValueStack = new ArrayDeque\u0026lt;\u0026gt;(2); 首先核心数据结构是利用这两个双端队列维护返回值和生成器栈。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @Override public Data\u0026lt;E\u0026gt; next() { if (generatorsStack.isEmpty()) { // GUARD throw new IllegalStateException(\u0026#34;no generator found!\u0026#34;); } final Embed\u0026lt;E\u0026gt; embed = generatorsStack.peek(); final Data\u0026lt;E\u0026gt; result = embed.generator.next(); if (result.isDone()) { clearPreviousReturnsValuesIfAny(); returnValueStack.push(result); if (embed.onCompletion != null) { try { embed.onCompletion.accept(result.resultValue); } catch (Exception e) { return Data.error(e); } } if (isLastGenerator()) { return result; } generatorsStack.pop(); return next(); } if (result.embed != null) { if (generatorsStack.size() \u0026gt;= 2) { return Data.error(new UnsupportedOperationException( \u0026#34;Currently recursive nested generators are not supported!\u0026#34;)); } generatorsStack.push(result.embed); return next(); } return result; } 这个方法是核心方法，递归地处理了嵌入的生成器。\n在状态流转中，处理嵌入的Generator的逻辑如下：\n主AsyncNodeGenerator → 发现嵌入生成器 → WithEmbed接管 → 执行嵌入生成器 → 完成后恢复 → 主AsyncNodeGenerator继续\n8.2.1.2 状态流转 AsyncNodeGenerator是整个图流转执行的唯一状态机，\n然后我们来看看AsyncNodeGenerator的实现：\n核心方法是next，其实现了状态图流转。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 @Override public Data\u0026lt;o\u0026gt; next() { try { // 检查最大迭代次数 if (++iteration \u0026gt; maxIterations) { return Data.error(new IllegalStateException( format(\u0026#34;Maximum number of iterations (%d) reached!\u0026#34;, maxIterations))); } // 检查是否已结束 if (nextNodeId == null \u0026amp;\u0026amp; currentNodeId == null) { return releaseThread().map(Data::\u0026lt;o\u0026gt;done).orElseGet(() -\u0026gt; Data.done(currentState)); } // 是否从嵌入恢复 if (resumedFromEmbed) { final CompletableFuture\u0026lt;o\u0026gt; future = getNodeOutput(); resumedFromEmbed = false; return Data.of(future); } // 处理START节点 if (START.equals(currentNodeId)) { doListeners(START, null); var nextNodeCommand = getEntryPoint(currentState, config); nextNodeId = nextNodeCommand.gotoNode(); currentState = nextNodeCommand.update(); var cp = addCheckpoint(config, START, currentState, nextNodeId); var output = (cp.isPresent() \u0026amp;\u0026amp; config.streamMode() == StreamMode.SNAPSHOTS) ? buildStateSnapshot(cp.get()) : buildNodeOutput(currentNodeId); currentNodeId = nextNodeId; return Data.of(output); } // 处理END节点 if (END.equals(nextNodeId)) { nextNodeId = null; currentNodeId = null; doListeners(END, null); return Data.of(buildNodeOutput(END)); } // 检查中断条件 if (shouldInterruptAfter(currentNodeId, nextNodeId)) { return Data.done(currentNodeId); } if (shouldInterruptBefore(nextNodeId, currentNodeId)) { return Data.done(currentNodeId); } // 更新当前节点ID currentNodeId = nextNodeId; // 获取当前节点对应的动作 var action = nodes.get(currentNodeId); if (action == null) throw RunnableErrors.missingNode.exception(currentNodeId); // 执行节点动作 return evaluateAction(action, this.overAllState).get(); } catch (Exception e) { doListeners(ERROR, e); log.error(e.getMessage(), e); return Data.error(e); } } 其中evaluateAction执行了nodeAction，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 private Command nextNodeId(String nodeId, OverAllState overAllState, Map\u0026lt;String, Object\u0026gt; state, RunnableConfig config) throws Exception { EdgeValue route = edges.get(nodeId); if (route == null) { throw RunnableErrors.missingEdge.exception(nodeId); } // 如果边有固定的目标ID if (route.id() != null) { return new Command(route.id(), state); } // 如果边有条件逻辑 if (route.value() != null) { // 执行边的条件动作 var command = route.value().action().apply(overAllState, config).get(); var newRoute = command.gotoNode(); // 根据条件结果查找映射的目标节点 String result = route.value().mappings().get(newRoute); if (result == null) { throw RunnableErrors.missingNodeInEdgeMapping.exception(nodeId, newRoute); } // 更新状态 var currentState = OverAllState.updateState(state, command.update(), keyStrategyMap); overAllState.updateState(command.update()); return new Command(result, currentState); } throw RunnableErrors.executionError.exception(format(\u0026#34;invalid edge value for nodeId: [%s] !\u0026#34;, nodeId)); } 下一个节点由nextNodeId方法决定：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 private Command nextNodeId(String nodeId, OverAllState overAllState, Map\u0026lt;String, Object\u0026gt; state, RunnableConfig config) throws Exception { EdgeValue route = edges.get(nodeId); if (route == null) { throw RunnableErrors.missingEdge.exception(nodeId); } // 如果边有固定的目标ID if (route.id() != null) { return new Command(route.id(), state); } // 如果边有条件逻辑 if (route.value() != null) { // 执行边的条件动作 var command = route.value().action().apply(overAllState, config).get(); var newRoute = command.gotoNode(); // 根据条件结果查找映射的目标节点 String result = route.value().mappings().get(newRoute); if (result == null) { throw RunnableErrors.missingNodeInEdgeMapping.exception(nodeId, newRoute); } // 更新状态 var currentState = OverAllState.updateState(state, command.update(), keyStrategyMap); overAllState.updateState(command.update()); return new Command(result, currentState); } throw RunnableErrors.executionError.exception(format(\u0026#34;invalid edge value for nodeId: [%s] !\u0026#34;, nodeId)); } 8.2.1.3 并行节点 首先，编译时会检测边的target数量，发现有并行边以后就创建并行节点并替换图结构。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 for (var e : processedData.edges().elements) { var targets = e.targets(); if (targets.size() == 1) { edges.put(e.sourceId(), targets.get(0)); // 单一目标，正常处理 } else { // 发现多个目标，处理并行分支 Supplier\u0026lt;Stream\u0026lt;EdgeValue\u0026gt;\u0026gt; parallelNodeStream = () -\u0026gt; targets.stream() .filter(target -\u0026gt; nodes.containsKey(target.id())); // 验证并行分支的合法性 var parallelNodeTargets = parallelNodeEdges.stream() .map(ee -\u0026gt; ee.target().id()) .collect(Collectors.toSet()); if (parallelNodeTargets.size() \u0026gt; 1) { // 检查条件边 - 并行分支不允许条件边 var conditionalEdges = parallelNodeEdges.stream() .filter(ee -\u0026gt; ee.target().value() != null) .toList(); if (!conditionalEdges.isEmpty()) { throw Errors.unsupportedConditionalEdgeOnParallelNode.exception(...); } // 检查多目标 - 所有分支必须汇聚到同一个节点 throw Errors.illegalMultipleTargetsOnParallelNode.exception(...); } // 创建ParallelNode var actions = parallelNodeStream.get() .map(target -\u0026gt; nodes.get(target.id())) // 收集所有分支的Action .toList(); var parallelNode = new ParallelNode(e.sourceId(), actions, keyStrategyMap); // 替换图结构 nodes.put(parallelNode.id(), parallelNode.actionFactory().apply(compileConfig)); edges.put(e.sourceId(), new EdgeValue(parallelNode.id())); // 原节点 → ParallelNode edges.put(parallelNode.id(), new EdgeValue(parallelNodeTargets.iterator().next())); // ParallelNode → 汇聚节点 } } 运行时，ParallelNode执行逻辑如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 @Override public CompletableFuture\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; apply(OverAllState state, RunnableConfig config) { Map\u0026lt;String, Object\u0026gt; partialMergedStates = new HashMap\u0026lt;\u0026gt;(); Map\u0026lt;String, Object\u0026gt; asyncGenerators = new HashMap\u0026lt;\u0026gt;(); // 创建所有分支的并行执行任务 var futures = actions.stream().map(action -\u0026gt; action.apply(state, config).thenApply(partialState -\u0026gt; { partialState.forEach((key, value) -\u0026gt; { if (value instanceof AsyncGenerator\u0026lt;?\u0026gt; || value instanceof GeneratorSubscriber) { // AsyncGenerator类型 → 放入异步生成器集合 ((List) asyncGenerators.computeIfAbsent(key, k -\u0026gt; new ArrayList\u0026lt;\u0026gt;())).add(value); } else { // 普通值 → 放入状态合并集合 partialMergedStates.put(key, value); } }); state.updateState(partialMergedStates); // 立即更新状态 return action; }) ).toList().toArray(new CompletableFuture[0]); // 等待所有分支完成 return CompletableFuture.allOf(futures) .thenApply((p) -\u0026gt; CollectionUtils.isEmpty(asyncGenerators) ? state.data() : // 没有AsyncGenerator，返回合并状态 asyncGenerators); // 有AsyncGenerator，触发嵌入机制 } 此时，会被evaluateAction的thenApply回调所处理，由于返回了AsnycGenerator，会进入getEmbedGenerator进行处理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 return action.apply(withState, config).thenApply(updateState -\u0026gt; { try { // updateState 就是NodeAction返回的Map\u0026lt;String,Object\u0026gt; // 1. 特殊处理：CommandNode ... // 2. 检查嵌入生成器 Optional\u0026lt;Data\u0026lt;o\u0026gt;\u0026gt; embed = getEmbedGenerator(updateState); if (embed.isPresent()) { return embed.get(); // 触发嵌入生成器处理 } // 3. 常规状态更新 ... // 4. 计算下一个节点 ... } catch (Exception e) { throw new CompletionException(e); } }); 来看看getEmbedGenerator的实现：\n这里主要做了两件事：1. 看partialState里面有几个embedGenerator 2. 如果有多个，就合并成一个。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 private Optional\u0026lt;Data\u0026lt;Output\u0026gt;\u0026gt; getEmbedGenerator(Map\u0026lt;String, Object\u0026gt; partialState) { // Extract all AsyncGenerator instances List\u0026lt;AsyncGenerator\u0026lt;Output\u0026gt;\u0026gt; asyncNodeGenerators = new ArrayList\u0026lt;\u0026gt;(); var generatorEntries = partialState.entrySet().stream().filter(e -\u0026gt; { // Fixed when parallel nodes return asynchronous generating the same key Object value = e.getValue(); if (value instanceof AsyncGenerator) { return true; } if (value instanceof Collection collection) { collection.forEach(o -\u0026gt; { if (o instanceof AsyncGenerator\u0026lt;?\u0026gt;) { asyncNodeGenerators.add((AsyncGenerator\u0026lt;Output\u0026gt;) o); } }); } return false; }).collect(Collectors.toList()); if (generatorEntries.isEmpty() \u0026amp;\u0026amp; asyncNodeGenerators.isEmpty()) { return Optional.empty(); } // Log information about found generators if (generatorEntries.size() \u0026gt; 1) { log.debug(\u0026#34;Multiple generators found: {} - keys: {}\u0026#34;, generatorEntries.size(), generatorEntries.stream().map(Map.Entry::getKey).collect(Collectors.joining(\u0026#34;, \u0026#34;))); } // Create appropriate generator (single or merged) AsyncGenerator\u0026lt;Output\u0026gt; generator = AsyncGeneratorUtils.createAppropriateGenerator(generatorEntries, asyncNodeGenerators, keyStrategyMap); // Create data processing logic for the generator return Optional.of(Data.composeWith(generator.map(n -\u0026gt; { n.setSubGraph(true); return n; }), data -\u0026gt; processGeneratorOutput(data, partialState, generatorEntries))); } 来看看合并Generator的代码具体实现：\n这可能看起来很复杂，主要就是返回了一个新的AsnycGenerator，它可以轮询执行所有输入的生成器。\n同时，这个AsnycGenerator可能被并发访问，故需要加锁。\n执行路径：\n使用乐观锁检查是否已经merge完成，如果有线程获取写锁，就获取悲观读锁读取验证。 开始merge，首先获取写锁，保证轮询符合操作的原子性。 释放写锁，无锁下执行next方法获取单个结果，由于前面保证了获取的不是同一个generator，所以这里是线程安全的。 再次获取写锁，更新状态，保证activeGenerators ↔ mergedResult ↔ generatorResults的状态一致性。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 public static \u0026lt;T\u0026gt; AsyncGenerator\u0026lt;T\u0026gt; createMergedGenerator(List\u0026lt;AsyncGenerator\u0026lt;T\u0026gt;\u0026gt; generators, Map\u0026lt;String, KeyStrategy\u0026gt; keyStrategyMap) { return new AsyncGenerator\u0026lt;\u0026gt;() { // Switch to StampedLock to simplify lock management private final StampedLock lock = new StampedLock(); private AtomicInteger pollCounter = new AtomicInteger(0); private Map\u0026lt;String, Object\u0026gt; mergedResult = new HashMap\u0026lt;\u0026gt;(); private final List\u0026lt;AsyncGenerator\u0026lt;T\u0026gt;\u0026gt; activeGenerators = new CopyOnWriteArrayList\u0026lt;\u0026gt;(generators); private final Map\u0026lt;AsyncGenerator\u0026lt;T\u0026gt;, Map\u0026lt;String, Object\u0026gt;\u0026gt; generatorResults = new HashMap\u0026lt;\u0026gt;(); @Override public AsyncGenerator.Data\u0026lt;T\u0026gt; next() { while (true) { // Read optimistically and check quickly long stamp = lock.tryOptimisticRead(); boolean empty = activeGenerators.isEmpty(); if (!lock.validate(stamp)) { stamp = lock.readLock(); try { empty = activeGenerators.isEmpty(); } finally { lock.unlockRead(stamp); } } if (empty) { return AsyncGenerator.Data.done(mergedResult); } // Fine-grained lock control final int currentIdx; AsyncGenerator\u0026lt;T\u0026gt; current; long writeStamp = lock.writeLock(); try { final int size = activeGenerators.size(); if (size == 0) return AsyncGenerator.Data.done(mergedResult); currentIdx = pollCounter.updateAndGet(i -\u0026gt; (i + 1) % size); current = activeGenerators.get(currentIdx); } finally { lock.unlockWrite(writeStamp); } // Execute the generator \u0026#39;next()\u0026#39; in the unlocked state AsyncGenerator.Data\u0026lt;T\u0026gt; data = current.next(); writeStamp = lock.writeLock(); try { // Double checks prevent status changes if (!activeGenerators.contains(current)) { continue; } if (data.isDone() || data.isError()) { handleCompletedGenerator(current, data); if (activeGenerators.isEmpty()) { return AsyncGenerator.Data.done(mergedResult); } continue; } handleCompletedGenerator(current, data); return data; } finally { lock.unlockWrite(writeStamp); } } } /** * Helper method to handle completed or errored generators */ private void handleCompletedGenerator(AsyncGenerator\u0026lt;T\u0026gt; generator, AsyncGenerator.Data\u0026lt;T\u0026gt; data) { // Remove generator if done or error if (data.isDone() || data.isError()) { activeGenerators.remove(generator); } // Process result if exists data.resultValue().ifPresent(result -\u0026gt; { if (result instanceof Map) { @SuppressWarnings(\u0026#34;unchecked\u0026#34;) Map\u0026lt;String, Object\u0026gt; mapResult = (Map\u0026lt;String, Object\u0026gt;) result; mergedResult = OverAllState.updateState(mergedResult, mapResult, keyStrategyMap); } }); // Remove from generator results if present generatorResults.remove(generator); } }; } 8.2.2 AsyncGenerator 施工中。。。\n8.3 GraphLifeCycleLister 暴露的钩子函数，可以通过配置Lister队列来在图的不同状态触发自定义函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 private void doListeners(String scene, Exception e) { Deque\u0026lt;GraphLifecycleListener\u0026gt; listeners = new LinkedBlockingDeque\u0026lt;\u0026gt;(compileConfig.lifecycleListeners()); processListenersLIFO(listeners, scene, e); } private void processListenersLIFO(Deque\u0026lt;GraphLifecycleListener\u0026gt; listeners, String scene, Exception e) { if (listeners.isEmpty()) { return; } GraphLifecycleListener listener = listeners.pollLast(); try { if (START.equals(scene)) { listener.onStart(START, this.currentState); } else if (END.equals(scene)) { listener.onComplete(END, this.currentState); } else if (ERROR.equals(scene)) { listener.onError(this.currentNodeId, this.currentState, e); } processListenersLIFO(listeners, scene, e); } catch (Exception ex) { log.debug(\u0026#34;Error occurred during listener processing: {}\u0026#34;, ex.getMessage()); } } 8.4 子图处理 主要实现了：\n把子图的节点和边嫁接到主图上面，然后返回修改后的主图。\n把子图中断转移到子图入口。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 record ProcessedNodesEdgesAndConfig(StateGraph.Nodes nodes, StateGraph.Edges edges, Set\u0026lt;String\u0026gt; interruptsBefore, Set\u0026lt;String\u0026gt; interruptsAfter) { /** * Instantiates a new Processed nodes edges and config. * @param stateGraph the state graph * @param config the config */ ProcessedNodesEdgesAndConfig(StateGraph stateGraph, CompileConfig config) { this(stateGraph.nodes, stateGraph.edges, config.interruptsBefore(), config.interruptsAfter()); } /** * Process processed nodes edges and config. * @param stateGraph the state graph * @param config the config * @return the processed nodes edges and config * @throws GraphStateException the graph state exception */ static ProcessedNodesEdgesAndConfig process(StateGraph stateGraph, CompileConfig config) throws GraphStateException { var subgraphNodes = stateGraph.nodes.onlySubStateGraphNodes(); if (subgraphNodes.isEmpty()) { return new ProcessedNodesEdgesAndConfig(stateGraph, config); } var interruptsBefore = config.interruptsBefore(); var interruptsAfter = config.interruptsAfter(); var nodes = new StateGraph.Nodes(stateGraph.nodes.exceptSubStateGraphNodes()); var edges = new StateGraph.Edges(stateGraph.edges.elements); for (var subgraphNode : subgraphNodes) { var sgWorkflow = subgraphNode.subGraph(); // // Process START Node // var sgEdgeStart = sgWorkflow.edges.edgeBySourceId(START).orElseThrow(); if (sgEdgeStart.isParallel()) { throw new GraphStateException(\u0026#34;subgraph not support start with parallel branches yet!\u0026#34;); } var sgEdgeStartTarget = sgEdgeStart.target(); if (sgEdgeStartTarget.id() == null) { throw new GraphStateException(format(\u0026#34;the target for node \u0026#39;%s\u0026#39; is null!\u0026#34;, subgraphNode.id())); } var sgEdgeStartRealTargetId = subgraphNode.formatId(sgEdgeStartTarget.id()); // Process Interruption (Before) Subgraph(s) interruptsBefore = interruptsBefore.stream() .map(interrupt -\u0026gt; Objects.equals(subgraphNode.id(), interrupt) ? sgEdgeStartRealTargetId : interrupt) .collect(Collectors.toUnmodifiableSet()); var edgesWithSubgraphTargetId = edges.edgesByTargetId(subgraphNode.id()); if (edgesWithSubgraphTargetId.isEmpty()) { throw new GraphStateException( format(\u0026#34;the node \u0026#39;%s\u0026#39; is not present as target in graph!\u0026#34;, subgraphNode.id())); } for (var edgeWithSubgraphTargetId : edgesWithSubgraphTargetId) { var newEdge = edgeWithSubgraphTargetId.withSourceAndTargetIdsUpdated(subgraphNode, Function.identity(), id -\u0026gt; new EdgeValue((Objects.equals(id, subgraphNode.id()) ? subgraphNode.formatId(sgEdgeStartTarget.id()) : id))); edges.elements.remove(edgeWithSubgraphTargetId); edges.elements.add(newEdge); } // // Process END Nodes // var sgEdgesEnd = sgWorkflow.edges.edgesByTargetId(END); var edgeWithSubgraphSourceId = edges.edgeBySourceId(subgraphNode.id()).orElseThrow(); if (edgeWithSubgraphSourceId.isParallel()) { throw new GraphStateException(\u0026#34;subgraph not support routes to parallel branches yet!\u0026#34;); } // Process Interruption (After) Subgraph(s) if (interruptsAfter.contains(subgraphNode.id())) { var exceptionMessage = (edgeWithSubgraphSourceId.target() .id() == null) ? \u0026#34;\u0026#39;interruption after\u0026#39; on subgraph is not supported yet!\u0026#34; : format( \u0026#34;\u0026#39;interruption after\u0026#39; on subgraph is not supported yet! consider to use \u0026#39;interruption before\u0026#39; node: \u0026#39;%s\u0026#39;\u0026#34;, edgeWithSubgraphSourceId.target().id()); throw new GraphStateException(exceptionMessage); } sgEdgesEnd.stream() .map(e -\u0026gt; e.withSourceAndTargetIdsUpdated(subgraphNode, subgraphNode::formatId, id -\u0026gt; (Objects.equals(id, END) ? edgeWithSubgraphSourceId.target() : new EdgeValue(subgraphNode.formatId(id))))) .forEach(edges.elements::add); edges.elements.remove(edgeWithSubgraphSourceId); // // Process edges // sgWorkflow.edges.elements.stream() .filter(e -\u0026gt; !Objects.equals(e.sourceId(), START)) .filter(e -\u0026gt; !e.anyMatchByTargetId(END)) .map(e -\u0026gt; e.withSourceAndTargetIdsUpdated(subgraphNode, subgraphNode::formatId, id -\u0026gt; new EdgeValue(subgraphNode.formatId(id)))) .forEach(edges.elements::add); // // Process nodes // sgWorkflow.nodes.elements.stream().map(n -\u0026gt; { if (n instanceof CommandNode commandNode) { Map\u0026lt;String, String\u0026gt; mappings = commandNode.getMappings(); HashMap\u0026lt;String, String\u0026gt; newMappings = new HashMap\u0026lt;\u0026gt;(); mappings.forEach((key, value) -\u0026gt; { newMappings.put(key, subgraphNode.formatId(value)); }); return new CommandNode(subgraphNode.formatId(n.id()), AsyncCommandAction.node_async((state, config1) -\u0026gt; { Command command = commandNode.getAction().apply(state, config1).join(); String NewGoToNode = subgraphNode.formatId(command.gotoNode()); return new Command(NewGoToNode, command.update()); }), newMappings); } return n.withIdUpdated(subgraphNode::formatId); }).forEach(nodes.elements::add); } return new ProcessedNodesEdgesAndConfig(nodes, edges, interruptsBefore, interruptsAfter); } 8.5 中断处理 8.5.1 中断 CompiledConfig中定义了中断点。graph运行时会自动生成每个节点的Checkpoint并存到Saver里面。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 private boolean shouldInterruptBefore(String nodeId, String previousNodeId) { if (previousNodeId == null) { // FIX RESUME ERROR return false; } return compileConfig.interruptsBefore().contains(nodeId); } private boolean shouldInterruptAfter(String nodeId, String previousNodeId) { if (nodeId == null) { // FIX RESUME ERROR return false; } return compileConfig.interruptsAfter().contains(nodeId); } private Optional\u0026lt;Checkpoint\u0026gt; addCheckpoint(RunnableConfig config, String nodeId, Map\u0026lt;String, Object\u0026gt; state, String nextNodeId) throws Exception { if (compileConfig.checkpointSaver().isPresent()) { var cp = Checkpoint.builder().nodeId(nodeId).state(cloneState(state)).nextNodeId(nextNodeId).build(); compileConfig.checkpointSaver().get().put(config, cp); return Optional.of(cp); } return Optional.empty(); } 运行时，到达中断点后，直接return Data.done()\n1 2 3 4 5 6 7 8 9 10 11 12 // check on previous node if (shouldInterruptAfter(currentNodeId, nextNodeId)) { return Data.done(currentNodeId); } if (shouldInterruptBefore(nextNodeId, currentNodeId)) { return Data.done(currentNodeId); } currentNodeId = nextNodeId; var action = nodes.get(currentNodeId); 8.5.2 恢复 AsyncNodeGenerator构造函数中，会检查是开始还是恢复。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 protected AsyncNodeGenerator(OverAllState overAllState, RunnableConfig config) throws GraphRunnerException { if (overAllState.isResume()) { // ← 检查是否为恢复请求 log.trace(\u0026#34;RESUME REQUEST\u0026#34;); // 1. 获取CheckpointSaver实例 BaseCheckpointSaver saver = compileConfig.checkpointSaver() .orElseThrow(() -\u0026gt; (new IllegalStateException( \u0026#34;inputs cannot be null (ie. resume request) if no checkpoint saver is configured\u0026#34;))); // 2. 从CheckpointSaver读取检查点数据 ← 核心读取位置！ Checkpoint startCheckpoint = saver.get(config) .orElseThrow(() -\u0026gt; (new IllegalStateException(\u0026#34;Resume request without a saved checkpoint!\u0026#34;))); // 3. 恢复状态数据 this.currentState = startCheckpoint.getState(); // ← 状态恢复 this.config = config.withCheckPointId(null); this.overAllState = overAllState.input(this.currentState); this.nextNodeId = startCheckpoint.getNextNodeId(); // ← 恢复下一个节点 this.currentNodeId = null; log.trace(\u0026#34;RESUME FROM {}\u0026#34;, startCheckpoint.getNodeId()); } } 9 序列化 9.1 使用场景 9.1.1 Checkpoint保存（持久化状态） 1 2 3 4 5 6 7 8 9 10 private Optional\u0026lt;Checkpoint\u0026gt; addCheckpoint(RunnableConfig config, String nodeId, Map\u0026lt;String, Object\u0026gt; state, String nextNodeId) throws Exception { if (compileConfig.checkpointSaver().isPresent()) { var cp = Checkpoint.builder().nodeId(nodeId).state(cloneState(state)).nextNodeId(nextNodeId).build(); compileConfig.checkpointSaver().get().put(config, cp); return Optional.of(cp); } return Optional.empty(); } 9.1.2 Resume反序列化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 protected AsyncNodeGenerator(OverAllState overAllState, RunnableConfig config) throws GraphRunnerException { if (overAllState.isResume()) { log.trace(\u0026#34;RESUME REQUEST\u0026#34;); BaseCheckpointSaver saver = compileConfig.checkpointSaver() .orElseThrow(() -\u0026gt; (new IllegalStateException( \u0026#34;inputs cannot be null (ie. resume request) if no checkpoint saver is configured\u0026#34;))); Checkpoint startCheckpoint = saver.get(config) .orElseThrow(() -\u0026gt; (new IllegalStateException(\u0026#34;Resume request without a saved checkpoint!\u0026#34;))); this.currentState = startCheckpoint.getState(); // Reset checkpoint id this.config = config.withCheckPointId(null); this.overAllState = overAllState.input(this.currentState); this.nextNodeId = startCheckpoint.getNextNodeId(); this.currentNodeId = null; log.trace(\u0026#34;RESUME FROM {}\u0026#34;, startCheckpoint.getNodeId()); } 9.1.3 状态深拷贝 1 2 3 OverAllState cloneState(Map\u0026lt;String, Object\u0026gt; data) throws IOException, ClassNotFoundException { return stateGraph.getStateSerializer().cloneObject(data); } ","date":"2025-06-06T00:00:00Z","permalink":"https://sixiyida.github.io/p/spring-ai-alibaba-graph-core-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/","title":"spring-ai-alibaba-graph-core 源码阅读"},{"content":"1. Deep Research Executor节点并行 1.1 问题描述 ​\t当前架构中，Research Team节点后的负责执行plan的Executors (Researcher/Coder) 是串行执行的，每一步都需要等待上一个step执行完毕，耗费大量时间。经测试，一个5step的plan耗时需要4分钟，占据了整个执行流程的70%。\n​\t测试观察发现，ResearcherNode的step基本没有上下文依赖，每个step相对独立，所以可以异步并行执行，增加速度。CoderNode在获取了ResearcherNode的上下文后，也可以异步并行执行。\n1.2 修改策略 ​\t并行实现有两种方案：\n​\t（1）直接在ResearcherTeam中，异步动态创建nodeaction并执行，即有多少个Step就创建多少个ExecutorNode，一次即可完成整个step，并在ResearcherNode连一条自旋边，阻塞线程以等待。\n​\t（2）利用Graph库提供的并行节点，即创建一个节点，异步执行nodeaction，这样利用了已有的能力，维护性较好。\n1.3 具体实现 ​\t两种方案都需要依赖在step中进行状态控制，即三种状态：assigned、processing、completed。并且附上给节点分配的id。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Data public static class Step { @JsonProperty(\u0026#34;need_web_search\u0026#34;) private boolean needWebSearch; private String title; private String description; @JsonProperty(\u0026#34;step_type\u0026#34;) private StepType stepType; private String executionRes; private String executionStatus; } 1.3.1 方案1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 step.setExecutionStatus(assignedStatus); CompletableFuture.runAsync(() -\u0026gt; { try { if (step.getStepType() == Plan.StepType.RESEARCH) { logger.info(\u0026#34;Executing research step {}: {}\u0026#34;, stepIndex, step.getTitle()); // 为每个研究步骤创建新的Agent ChatClient researchAgent = applicationContext.getBean(\u0026#34;researchAgent\u0026#34;, ChatClient.class); ResearcherNode researcherNode = new ResearcherNode(researchAgent, executorNodeId); researcherNode.apply(state); } else { logger.info(\u0026#34;Executing processing step {}: {}\u0026#34;, stepIndex, step.getTitle()); // 为每个处理步骤创建新的Agent ChatClient coderAgent = applicationContext.getBean(\u0026#34;coderAgent\u0026#34;, ChatClient.class); CoderNode coderNode = new CoderNode(coderAgent, executorNodeId); coderNode.apply(state); } } catch (Exception e) { logger.error(\u0026#34;Error executing step {}: {}\u0026#34;, stepIndex, step.getTitle(), e); } }, executorService); 以上为核心代码，比较简单粗暴。即ResearcherTeamNode直接创建新节点，并且等待。\n1.3.2 方案2 方案2是最终采纳的方案。阅读Graph发现当前graph实现有以下限制：\n（1）子图节点不能包含有并行节点\n（2）并行节点必须是总分总的结构，并且会在汇总节点等待所有异步任务执行完毕。\n（3）并行节点总分总结构中所有边不能是conditional。\n（4）不支持并行流式处理。\n为绕开/解决限制，采取以下方案：\n对于（1），直接不使用子图节点，在大图中进行结构修改。\n对于（3），由于当前researcherTeamNode需要到reporterNode或者executorNode，故并行节点不能是researcherTeamNode，需要单独创建一个ParallelExecutorNode来给ExecutorNode分配任务。\n对于（2），采取researcherTeamNode -\u0026gt; ParallelExecutorNode -\u0026gt; ExecutorNodes -\u0026gt; researcherTeamNode的环形结构，在第二次进入researcherTeamNode的时候等待。\n对于（4），分析并修改Graph Core代码。\n1.3.2.1 ParallelExecutorNode 主要任务：分配step给后续节点。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 /* * Copyright 2025 the original author or authors. * * Licensed under the Apache License, Version 2.0 (the \u0026#34;License\u0026#34;); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * https://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \u0026#34;AS IS\u0026#34; BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.alibaba.cloud.ai.example.deepresearch.node; import com.alibaba.cloud.ai.example.deepresearch.model.ParallelEnum; import com.alibaba.cloud.ai.example.deepresearch.model.dto.Plan; import com.alibaba.cloud.ai.example.deepresearch.util.StateUtil; import com.alibaba.cloud.ai.example.deepresearch.config.DeepResearchProperties; import com.alibaba.cloud.ai.graph.OverAllState; import com.alibaba.cloud.ai.graph.action.NodeAction; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.util.CollectionUtils; import org.springframework.util.StringUtils; import java.util.Map; /** * @author sixiyida * @since 2025/6/12 */ public class ParallelExecutorNode implements NodeAction { private static final Logger logger = LoggerFactory.getLogger(ParallelExecutorNode.class); private final Map\u0026lt;String, Integer\u0026gt; parallelNodeCount; public ParallelExecutorNode(DeepResearchProperties properties) { this.parallelNodeCount = properties.getParallelNodeCount(); } @Override public Map\u0026lt;String, Object\u0026gt; apply(OverAllState state) throws Exception { long currResearcher = 0; long currCoder = 0; Plan curPlan = StateUtil.getPlan(state); for (Plan.Step step : curPlan.getSteps()) { // 跳过不需要处理的步骤 if (StringUtils.hasText(step.getExecutionRes()) || StringUtils.hasText(step.getExecutionStatus())) { continue; } Plan.StepType stepType = step.getStepType(); switch (stepType) { case PROCESSING: if (areAllResearchStepsCompleted(curPlan)) { step.setExecutionStatus(assignRole(stepType, currCoder)); currCoder = (currCoder + 1) % parallelNodeCount.get(ParallelEnum.RESEARCHER.getValue()); } logger.info(\u0026#34;Waiting for remaining research steps executed\u0026#34;); break; case RESEARCH: step.setExecutionStatus(assignRole(stepType, currResearcher)); currResearcher = (currResearcher + 1) % parallelNodeCount.get(ParallelEnum.CODER.getValue()); break; // 处理其他可能的StepType default: logger.debug(\u0026#34;Unhandled step type: {}\u0026#34;, stepType); } } return Map.of(); } private String assignRole(Plan.StepType type, long executorId) { String role = type == Plan.StepType.PROCESSING ? ParallelEnum.CODER.getValue() : ParallelEnum.RESEARCHER.getValue(); return StateUtil.EXECUTION_STATUS_ASSIGNED_PREFIX + role + \u0026#34;_\u0026#34; + executorId; } private boolean areAllResearchStepsCompleted(Plan plan) { if (CollectionUtils.isEmpty(plan.getSteps())) { return true; } return plan.getSteps() .stream() .filter(step -\u0026gt; step.getStepType() == Plan.StepType.RESEARCH) .allMatch(step -\u0026gt; step.getExecutionStatus().startsWith(StateUtil.EXECUTION_STATUS_COMPLETED_PREFIX)); } } 1.3.2.2 ResearcherNode 主要任务：执行step，流式返回，更新状态。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 /* * Copyright 2025 the original author or authors. * * Licensed under the Apache License, Version 2.0 (the \u0026#34;License\u0026#34;); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * https://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \u0026#34;AS IS\u0026#34; BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.alibaba.cloud.ai.example.deepresearch.node; import com.alibaba.cloud.ai.example.deepresearch.model.dto.Plan; import com.alibaba.cloud.ai.example.deepresearch.util.StateUtil; import com.alibaba.cloud.ai.graph.OverAllState; import com.alibaba.cloud.ai.graph.action.NodeAction; import com.alibaba.cloud.ai.graph.streaming.StreamingChatGenerator; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.ai.chat.client.ChatClient; import org.springframework.ai.chat.messages.Message; import org.springframework.ai.chat.messages.UserMessage; import org.springframework.util.StringUtils; import java.util.ArrayList; import java.util.HashMap; import java.util.List; import java.util.Map; import java.util.Objects; /** * @author sixiyida * @since 2025/6/14 11:17 */ public class ResearcherNode implements NodeAction { private static final Logger logger = LoggerFactory.getLogger(ResearcherNode.class); private final ChatClient researchAgent; private final String executorNodeId; private final String nodeName; public ResearcherNode(ChatClient researchAgent) { this(researchAgent, \u0026#34;0\u0026#34;); } public ResearcherNode(ChatClient researchAgent, String executorNodeId) { this.researchAgent = researchAgent; this.executorNodeId = executorNodeId; this.nodeName = \u0026#34;researcher_\u0026#34; + executorNodeId; } @Override public Map\u0026lt;String, Object\u0026gt; apply(OverAllState state) throws Exception { logger.info(\u0026#34;researcher node {} is running.\u0026#34;, executorNodeId); Plan currentPlan = StateUtil.getPlan(state); List\u0026lt;String\u0026gt; observations = StateUtil.getMessagesByType(state, \u0026#34;observations\u0026#34;); Map\u0026lt;String, Object\u0026gt; updated = new HashMap\u0026lt;\u0026gt;(); Plan.Step assignedStep = null; for (Plan.Step step : currentPlan.getSteps()) { if (Plan.StepType.RESEARCH.equals(step.getStepType()) \u0026amp;\u0026amp; !StringUtils.hasText(step.getExecutionRes()) \u0026amp;\u0026amp; StringUtils.hasText(step.getExecutionStatus()) \u0026amp;\u0026amp; step.getExecutionStatus().equals(StateUtil.EXECUTION_STATUS_ASSIGNED_PREFIX + nodeName)) { assignedStep = step; break; } } // 如果没有找到分配的步骤，直接返回 if (assignedStep == null) { logger.info(\u0026#34;No remaining steps to be executed by {}\u0026#34;, nodeName); return updated; } // 标记步骤为正在执行 assignedStep.setExecutionStatus(StateUtil.EXECUTION_STATUS_PROCESSING_PREFIX + nodeName); // 添加任务消息 List\u0026lt;Message\u0026gt; messages = new ArrayList\u0026lt;\u0026gt;(); Message taskMessage = new UserMessage(String.format(\u0026#34;# Current Task\\n\\n##title\\n\\n%s\\n\\n##description\\n\\n%s\u0026#34;, assignedStep.getTitle(), assignedStep.getDescription())); messages.add(taskMessage); // 添加研究者特有的引用提醒 Message citationMessage = new UserMessage( \u0026#34;IMPORTANT: DO NOT include inline citations in the text. Instead, track all sources and include a References section at the end using link reference format. Include an empty line between each citation for better readability. Use this format for each reference:\\n- [Source Title](URL)\\n\\n- [Another Source](URL)\u0026#34;); messages.add(citationMessage); logger.debug(\u0026#34;researcher Node messages: {}\u0026#34;, messages); // 调用agent var streamResult = researchAgent.prompt().messages(messages).stream().chatResponse(); Plan.Step finalAssignedStep = assignedStep; logger.info(\u0026#34;ResearcherNode {} starting streaming with key: {}\u0026#34;, executorNodeId, \u0026#34;researcher_llm_stream_\u0026#34; + executorNodeId); var generator = StreamingChatGenerator.builder() .startingNode(\u0026#34;researcher_llm_stream_\u0026#34; + executorNodeId) .startingState(state) .mapResult(response -\u0026gt; { finalAssignedStep.setExecutionStatus(StateUtil.EXECUTION_STATUS_COMPLETED_PREFIX + executorNodeId); String researchContent = response.getResult().getOutput().getText(); finalAssignedStep.setExecutionRes(Objects.requireNonNull(researchContent)); logger.info(\u0026#34;{} completed, content: {}\u0026#34;, nodeName, researchContent); observations.add(researchContent); updated.put(\u0026#34;observations\u0026#34;, observations); updated.put(\u0026#34;researcher_content_\u0026#34; + executorNodeId, List.of(researchContent)); return updated; }) .build(streamResult); updated.put(\u0026#34;researcher_content_\u0026#34; + executorNodeId, generator); return updated; } } 1.3.2.3 CoderNode 同上，跳过。\n1.4 Graph Core修改 主要问题：不支持并行流式处理。\n1.4.1 调用链路分析 我们来看看目前的流式返回是如何实现的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 var generator = StreamingChatGenerator.builder() .startingNode(\u0026#34;researcher_llm_stream_\u0026#34; + executorNodeId) .startingState(state) .mapResult(response -\u0026gt; { finalAssignedStep.setExecutionStatus(StateUtil.EXECUTION_STATUS_COMPLETED_PREFIX + executorNodeId); String researchContent = response.getResult().getOutput().getText(); finalAssignedStep.setExecutionRes(Objects.requireNonNull(researchContent)); logger.info(\u0026#34;{} completed, content: {}\u0026#34;, nodeName, researchContent); observations.add(researchContent); updated.put(\u0026#34;observations\u0026#34;, observations); updated.put(\u0026#34;researcher_content_\u0026#34; + executorNodeId, List.of(researchContent)); return updated; }) .build(streamResult); updated.put(\u0026#34;researcher_content_\u0026#34; + executorNodeId, generator); 以上代码来自researcherNode，返回一个Map后，我们来看是在哪里执行的。\n1.4.1.1 入口接口 1 2 3 4 5 6 7 8 9 10 11 @RequestMapping(value = \u0026#34;/chat/stream\u0026#34;, method = RequestMethod.POST, produces = MediaType.TEXT_EVENT_STREAM_VALUE) public Flux\u0026lt;ServerSentEvent\u0026lt;String\u0026gt;\u0026gt; chatStream(@RequestBody(required = false) ChatRequest chatRequest) throws GraphRunnerException { //... else { ChatRequestProcess.initializeObjectMap(chatRequest, objectMap); logger.info(\u0026#34;init inputs: {}\u0026#34;, objectMap); AsyncGenerator\u0026lt;NodeOutput\u0026gt; resultFuture = compiledGraph.stream(objectMap, runnableConfig); graphProcess.processStream(resultFuture, sink); } } 这是一个Controller接口，可以看到，图是从这个方法进去的compiledGraph.stream(objectMap, runnableConfig);。\n我们来看看具体实现：\n1 2 3 4 5 public AsyncGenerator\u0026lt;NodeOutput\u0026gt; stream(Map\u0026lt;String, Object\u0026gt; inputs, RunnableConfig config) throws GraphRunnerException { Objects.requireNonNull(config, \u0026#34;config cannot be null\u0026#34;); final AsyncNodeGenerator\u0026lt;NodeOutput\u0026gt; generator = new AsyncNodeGenerator\u0026lt;\u0026gt;(stateCreate(inputs), config); return new AsyncGenerator.WithEmbed\u0026lt;\u0026gt;(generator); } 这个地方返回了一个AsyncGenerator.WithEmbed，这玩意是什么呢？\n简而言之，这个东西是一个允许其他的AsyncGenerator在其执行过程中执行的包装类。\n执行流程是：\n从堆栈顶部获取当前生成器\n调用当前生成器的next()方法获取结果\n如果结果表示生成器已完成：\n清除之前的返回值（如果有）\n将结果推入返回值堆栈\n执行完成回调（如果有）\n如果这是最后一个生成器，返回结果\n否则，弹出当前生成器，递归调用next()继续处理下一个生成器\n如果结果包含一个嵌入生成器： 检查嵌套深度（目前不支持递归嵌套）\n将嵌入生成器推入堆栈\n递归调用next()处理嵌入生成器\n否则，直接返回结果 看看具体实现：\n1 2 protected final Deque\u0026lt;Embed\u0026lt;E\u0026gt;\u0026gt; generatorsStack = new ArrayDeque\u0026lt;\u0026gt;(2); private final Deque\u0026lt;Data\u0026lt;E\u0026gt;\u0026gt; returnValueStack = new ArrayDeque\u0026lt;\u0026gt;(2); 首先核心数据结构是利用这两个双端队列维护返回值和生成器栈。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @Override public Data\u0026lt;E\u0026gt; next() { if (generatorsStack.isEmpty()) { // GUARD throw new IllegalStateException(\u0026#34;no generator found!\u0026#34;); } final Embed\u0026lt;E\u0026gt; embed = generatorsStack.peek(); final Data\u0026lt;E\u0026gt; result = embed.generator.next(); if (result.isDone()) { clearPreviousReturnsValuesIfAny(); returnValueStack.push(result); if (embed.onCompletion != null) { try { embed.onCompletion.accept(result.resultValue); } catch (Exception e) { return Data.error(e); } } if (isLastGenerator()) { return result; } generatorsStack.pop(); return next(); } if (result.embed != null) { if (generatorsStack.size() \u0026gt;= 2) { return Data.error(new UnsupportedOperationException( \u0026#34;Currently recursive nested generators are not supported!\u0026#34;)); } generatorsStack.push(result.embed); return next(); } return result; } 这个方法是核心方法，递归地处理了嵌入的生成器。\n1.4.1.2 状态流转 然后我们来看看AsyncNodeGenerator的实现：\n核心方法是next，其实现了状态图流转。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 @Override public Data\u0026lt;o\u0026gt; next() { try { // 检查最大迭代次数 if (++iteration \u0026gt; maxIterations) { return Data.error(new IllegalStateException( format(\u0026#34;Maximum number of iterations (%d) reached!\u0026#34;, maxIterations))); } // 检查是否已结束 if (nextNodeId == null \u0026amp;\u0026amp; currentNodeId == null) { return releaseThread().map(Data::\u0026lt;o\u0026gt;done).orElseGet(() -\u0026gt; Data.done(currentState)); } // 是否从嵌入恢复 if (resumedFromEmbed) { final CompletableFuture\u0026lt;o\u0026gt; future = getNodeOutput(); resumedFromEmbed = false; return Data.of(future); } // 处理START节点 if (START.equals(currentNodeId)) { doListeners(START, null); var nextNodeCommand = getEntryPoint(currentState, config); nextNodeId = nextNodeCommand.gotoNode(); currentState = nextNodeCommand.update(); var cp = addCheckpoint(config, START, currentState, nextNodeId); var output = (cp.isPresent() \u0026amp;\u0026amp; config.streamMode() == StreamMode.SNAPSHOTS) ? buildStateSnapshot(cp.get()) : buildNodeOutput(currentNodeId); currentNodeId = nextNodeId; return Data.of(output); } // 处理END节点 if (END.equals(nextNodeId)) { nextNodeId = null; currentNodeId = null; doListeners(END, null); return Data.of(buildNodeOutput(END)); } // 检查中断条件 if (shouldInterruptAfter(currentNodeId, nextNodeId)) { return Data.done(currentNodeId); } if (shouldInterruptBefore(nextNodeId, currentNodeId)) { return Data.done(currentNodeId); } // 更新当前节点ID currentNodeId = nextNodeId; // 获取当前节点对应的动作 var action = nodes.get(currentNodeId); if (action == null) throw RunnableErrors.missingNode.exception(currentNodeId); // 执行节点动作 return evaluateAction(action, this.overAllState).get(); } catch (Exception e) { doListeners(ERROR, e); log.error(e.getMessage(), e); return Data.error(e); } } 其中evaluateAction执行了nodeAction，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 private Command nextNodeId(String nodeId, OverAllState overAllState, Map\u0026lt;String, Object\u0026gt; state, RunnableConfig config) throws Exception { EdgeValue route = edges.get(nodeId); if (route == null) { throw RunnableErrors.missingEdge.exception(nodeId); } // 如果边有固定的目标ID if (route.id() != null) { return new Command(route.id(), state); } // 如果边有条件逻辑 if (route.value() != null) { // 执行边的条件动作 var command = route.value().action().apply(overAllState, config).get(); var newRoute = command.gotoNode(); // 根据条件结果查找映射的目标节点 String result = route.value().mappings().get(newRoute); if (result == null) { throw RunnableErrors.missingNodeInEdgeMapping.exception(nodeId, newRoute); } // 更新状态 var currentState = OverAllState.updateState(state, command.update(), keyStrategyMap); overAllState.updateState(command.update()); return new Command(result, currentState); } throw RunnableErrors.executionError.exception(format(\u0026#34;invalid edge value for nodeId: [%s] !\u0026#34;, nodeId)); } 下一个节点由nextNodeId方法决定：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 private Command nextNodeId(String nodeId, OverAllState overAllState, Map\u0026lt;String, Object\u0026gt; state, RunnableConfig config) throws Exception { EdgeValue route = edges.get(nodeId); if (route == null) { throw RunnableErrors.missingEdge.exception(nodeId); } // 如果边有固定的目标ID if (route.id() != null) { return new Command(route.id(), state); } // 如果边有条件逻辑 if (route.value() != null) { // 执行边的条件动作 var command = route.value().action().apply(overAllState, config).get(); var newRoute = command.gotoNode(); // 根据条件结果查找映射的目标节点 String result = route.value().mappings().get(newRoute); if (result == null) { throw RunnableErrors.missingNodeInEdgeMapping.exception(nodeId, newRoute); } // 更新状态 var currentState = OverAllState.updateState(state, command.update(), keyStrategyMap); overAllState.updateState(command.update()); return new Command(result, currentState); } throw RunnableErrors.executionError.exception(format(\u0026#34;invalid edge value for nodeId: [%s] !\u0026#34;, nodeId)); } ","date":"2025-06-06T00:00:00Z","permalink":"https://sixiyida.github.io/p/spring-ai-alibaba%E7%BB%B4%E6%8A%A4%E8%AE%B0%E5%BD%95/","title":"spring-ai-alibaba维护记录"},{"content":"分库分表和分页 1. 分表（Table Sharding） 定义：将单张数据表按特定规则（如哈希、范围）拆分为多个结构相同的小表，存储在同一数据库或不同数据库中\n目的：解决单表数据量过大导致的查询性能下降（如索引膨胀、磁盘I/O瓶颈）\n适用场景：单表数据超千万级，但数据库实例资源未达瓶颈\n2. 分库（Database Sharding） 定义：将整个数据库按业务或数据维度拆分为多个独立的数据库实例，每个实例存储部分数据\n目的：解决单库连接数不足、磁盘空间不足、写并发压力大等问题\n适用场景：单库QPS过高、连接数耗尽或需故障隔离\n3. 分片（Sharding） 定义：分库+分表的组合策略，将数据按规则（如哈希、范围）分布到多个数据库节点（分片），每个节点包含部分库和表。\n目的：实现真正的水平扩展，支持海量数据与高并发\n适用场景：超大规模数据（TB/PB级）、需全局负载均衡\n核心区别总结 维度 分表 分库 分片 拆分对象 单张表 整个数据库实例 库+表组合的分布式节点 主要目标 解决单表性能瓶颈 解决单库资源瓶颈 全局水平扩展与高可用 数据分布 表内数据拆分 库间数据隔离 跨节点数据分片 典型场景 大表查询优化 高并发写入/连接数不足 超大规模系统（如社交平台） ","date":"2025-06-02T00:00:00Z","permalink":"https://sixiyida.github.io/p/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/","title":"系统设计"},{"content":"0. 前言 花了5天时间是跟着做完了黑马点评项目。虽说是烂大街项目之一，但我还是学到了不少东西。这个项目让我第一次看到了后端的全貌。这篇文章会记录我优化这个项目的过程，涉及中间件、功能拓展、LLM的引入等。\n1. 引入消息队列中间件 在项目的秒杀业务中，优惠券下单和数据持久化至数据库利用Redis Stream实现的消息队列解耦，优势主要在：\n简化下单流程，提高系统响应速度。 提高并发量和鲁棒性，防止数据库击穿。 1.1 为什么引入消息队列中间件？ 持久化：Redis Stream依赖AOF/RDB持久化，主从切换时异步复制可能导致数据丢失；消息队列中间件，如RocketMQ，同步刷盘+多副本（RAFT协议），提供金融级可靠性。\n消息积压：\n能力 Redis Stream 专业消息队列 存储介质 内存（成本高） 磁盘（成本低） 积压容忍度 需设置MAXLEN截断旧消息 支持TB级堆积（如Kafka） 内存风险 可能触发OOM（需手动扩内存） 磁盘空间自动扩容无压力 运维与生态：专业消息队列工具链更完善。\n高级功能：消息队列中间件引入了延迟队列、死信路由等企业级特性。\n1.2 引入哪一种？ 三种中间件对比：\n能力维度 RabbitMQ Kafka RocketMQ 吞吐量 万级 TPS 百万级 TPS 十万级 TPS 延迟 微秒级 毫秒级（批处理设计） 毫秒级 事务支持 轻量级事务（同步阻塞） 支持（≥0.11 版本） 分布式事务消息 顺序性保障 单队列有序 分区内有序 队列/分区严格有序 可靠性机制 镜像队列+持久化 多副本+ISR 同步刷盘+多副本+RAFT 协议 秒杀核心优势 削峰填谷、异步解耦 超高吞吐、日志流处理 高并发+强一致性+低延迟 结论：选择RocketMQ，秒杀场景在需要高吞吐量的同时，需要强一致性和可靠性。同时RocketMQ支撑阿里多次双十一活动，非常无敌，必须喽他。\n1.3 引入RocketMQ 1.3.1 部署RocketMQ 由于本人太穷，服务器只有2核2G，但又不想妥协用轻量级的MQ，为验证项目逻辑，在本地Windows环境部署RocketMQ。\n下载跳过。\n配置环境变量：\n1 2 %ROCKETMQ_HOME% = ...\\rocketmq-all-5.3.3-bin-release %NAMESRV_ADDR% = localhost:9876 启动NameServer和Broker：\n1 2 3 cd %ROCKETMQ_HOME% bin/mqnamesrv bin/mqbroker -n localhost:9876 测试生产消费：\n1 2 bin/tools org.apache.rocketmq.example.quickstart.Producer bin/tools org.apache.rocketmq.example.quickstart.Consumer 1.3.2 引入Java客户端依赖 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.rocketmq\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;rocketmq-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 1.3.3 修改applications.yml 1 2 3 4 5 rocketmq: name-server: http://localhost:9876 producer: group: ${spring.application.name} send-message-timeout: 3000 1.4 架构更新 目前架构：\n主线程：Lua(Redis校验下单资格 -\u0026gt; 创建订单至Redis) -\u0026gt; 向异步线程阻塞队列提交订单\n子线程：异步线程获取分布式锁 -\u0026gt; 持久化至数据库(Transactional) -\u0026gt; 解锁\n其中分布式锁的设计是原本在多台Tomcat下，会导致重复下单问题。但现在Redis由于是串行化的，无论多少台Tomcat都不会出现并发问题，且MQ也将创建订单的消息串行化了，故分布式锁可以取消。\n更新后架构：\n主线程：Lua(Redis校验下单资格 -\u0026gt; 创建订单至Redis) -\u0026gt; 向MQ生产订单消息\n子线程：消费MQ消息 -\u0026gt; 持久化至数据库(Transactional)\n需要注意的是，在秒杀场景下，用户不应该为DB的错误买单，而且分布式事务违背了异步下单提高性能的初衷。故如果DB更新失败，不应该回滚Redis，而是应该重试DB更新操作。\n1.5 RocketMQ分布式事务逻辑 1.6 代码实现 1.6.1 MQ配置类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @Configuration public class RocketMQConfig { @Value(\u0026#34;${rocketmq.name-server}\u0026#34;) private String nameServer; // 事务消息生产者 @Bean(initMethod = \u0026#34;start\u0026#34;, destroyMethod = \u0026#34;shutdown\u0026#34;) public TransactionMQProducer transactionProducer() { TransactionMQProducer producer = new TransactionMQProducer(\u0026#34;voucher_order_group\u0026#34;); producer.setNamesrvAddr(nameServer); producer.setTransactionListener(transactionListener()); // 绑定事务监听器 return producer; } // 事务监听器实现 @Bean public TransactionListener transactionListener() { return new VoucherOrderTransactionListener(); } } 简单，跳过。\n1.6.2 订单事务监听器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @Component public class VoucherOrderTransactionListener implements TransactionListener { @Lazy @Resource private VoucherOrderServiceImpl voucherOrderService; // 执行本地事务（订单创建） @Override public LocalTransactionState executeLocalTransaction(Message msg, Object arg) { try { VoucherOrder order = JSON.parseObject(msg.getBody(), VoucherOrder.class); voucherOrderService.createVoucherOrder(order); // 调用订单创建方法 return LocalTransactionState.COMMIT_MESSAGE; } catch (Exception e) { voucherOrderService.rollbackRedis(order.getVoucherId(), order.getUserId()); // 非数据库操作导致的回滚 return LocalTransactionState.ROLLBACK_MESSAGE; } } // 事务回查（防止本地事务未提交） @Override public LocalTransactionState checkLocalTransaction(MessageExt msg) { String orderId = msg.getKeys(); VoucherOrder order = voucherOrderService.getById(orderId); return order != null ? LocalTransactionState.COMMIT_MESSAGE : LocalTransactionState.ROLLBACK_MESSAGE; } } 这里几个关键点：\n@Lazy：由于Service中注入了transactionProducer，而其依赖配置类中创建的TransactionListener，故产生循环依赖，需要使用懒加载打破循环依赖。\n回滚：如注释。\n1.6.3 修改秒杀下单逻辑 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 @Resource private TransactionMQProducer transactionProducer; @Override public Result seckillVoucher(Long voucherId) { Long userId = UserHolder.getUser().getId(); Long result = stringRedisTemplate.execute( SECKILL_SCRIPT, Collections.emptyList(), voucherId.toString(), userId.toString() ); int r = result.intValue(); if (r != 0) { return Result.fail(r == 1 ? \u0026#34;库存不足\u0026#34; : \u0026#34;不能重复下单\u0026#34;); } // 保存order VoucherOrder order = new VoucherOrder(); order.setId(redisIdWorker.nextId(\u0026#34;order\u0026#34;)); order.setUserId(UserHolder.getUser().getId()); order.setVoucherId(voucherId); // 构造消息 Message msg = new Message(\u0026#34;voucher_order_topic\u0026#34;, JSON.toJSONBytes(order)); msg.setKeys(order.getId().toString()); try { transactionProducer.sendMessageInTransaction(msg, null); } catch (MQClientException e) { log.error(\u0026#34;MQ错误\u0026#34;); } return Result.ok(order.getId()); } @Transactional public void createVoucherOrder(VoucherOrder voucherOrder) { Long userId = voucherOrder.getUserId(); Long voucherId = voucherOrder.getVoucherId(); boolean success = seckillVoucherService.update() .setSql(\u0026#34;stock = stock - 1\u0026#34;) .eq(\u0026#34;voucher_id\u0026#34;, voucherId) .gt(\u0026#34;stock\u0026#34;, 0) // CAS乐观锁 .update(); if (!success) { // 数据库操作失败 // 1. 删除购买记录 String key = RedisConstants.SECKILL_ORDER_KEY + voucherId; stringRedisTemplate.opsForSet().remove(key, userId.toString()); // 2. 恢复预扣库存 stringRedisTemplate.opsForValue() .increment(RedisConstants.SECKILL_STOCK_KEY + voucherId, 1); throw new RuntimeException(\u0026#34;数据库扣减失败\u0026#34;); } save(voucherOrder); } //幂等Redis回滚 public void rollbackRedis(Long voucherId, Long userId) { String luaScript = \u0026#34;local orderKey = KEYS[1] \u0026#34; + \u0026#34;local stockKey = KEYS[2] \u0026#34; + \u0026#34;local userId = ARGV[1] \u0026#34; + // 只回滚存在的订单记录 \u0026#34;if redis.call(\u0026#39;sismember\u0026#39;, orderKey, userId) == 1 then \u0026#34; + \u0026#34; redis.call(\u0026#39;srem\u0026#39;, orderKey, userId) \u0026#34; + \u0026#34; redis.call(\u0026#39;incr\u0026#39;, stockKey) \u0026#34; + // 库存+1 \u0026#34; return 1 \u0026#34; + \u0026#34;else \u0026#34; + \u0026#34; return 0 \u0026#34; + // 已处理或无记录 \u0026#34;end\u0026#34;; String orderKey = RedisConstants.SECKILL_ORDER_KEY + voucherId; String stockKey = RedisConstants.SECKILL_STOCK_KEY + voucherId; // 执行Lua脚本 Long result = stringRedisTemplate.execute( new DefaultRedisScript\u0026lt;\u0026gt;(luaScript, Long.class), Arrays.asList(orderKey, stockKey), userId.toString() ); log.debug(\u0026#34;回滚结果: {}\u0026#34;, result); } ","date":"2025-06-01T00:00:00Z","permalink":"https://sixiyida.github.io/p/%E7%82%B9%E8%AF%84%E9%A1%B9%E7%9B%AE%E4%BC%98%E5%8C%96/","title":"点评项目优化"},{"content":"@Configuration和@Component @Configuration自身也是一个Bean，默认启用 CGLIB 代理（proxyBeanMethods=true）。当配置类中的 @Bean 方法相互调用时，Spring 会拦截调用并返回容器中的单例 Bean，而非重新创建，可直接注入方法参数的Bean。\n1 2 3 4 5 6 7 @Configuration public class Config { @Bean public A a() { return new A(); } @Bean public B b() { return new B(a()); } // 注入容器中的单例A } @Component无代理机制。方法间调用视为普通 Java 方法，每次调用 @Bean 方法都会创建新实例，破坏单例， 依赖注入需要显式@Autowired：\n1 2 3 4 5 6 7 @Component public class ComponentConfig { @Bean public A a() { return new A(); } @Bean public B b() { return new B(a()); } // 每次调用a()创建新实例！ } @PathVariable 1 2 3 4 @GetMapping(\u0026#34;/{id}\u0026#34;) public Result queryBlogById(@PathVariable(\u0026#34;id\u0026#34;) Long id) { } 将url的值绑定至方法参数中。\n","date":"2025-05-30T00:00:00Z","permalink":"https://sixiyida.github.io/p/spring%E7%9B%B8%E5%85%B3/","title":"Spring相关"},{"content":"为什么需要消息队列？ 在异步任务，如生产者-消费者模型中，两者的运行速度并不相同，使用消息队列可以做一个缓冲，减小系统压力。\nRedis消息队列 1. 基于List Redis的list数据结构是一个双向链表，利用LPUSH和RPOP实现，若需要阻塞，使用BRPOP实现阻塞队列效果\n缺陷：每次取出消息直接从队列中移除，造成\n无法避免消息丢失：移除后如果宕机，则消息丢失。 无法有多消费者：只能消费一次并移除，无法多次消费。 2. 基于Pub/Sub 类似ROS：\n1 2 3 SUBSCRIBE channel [channel] PUBLISH channel msg PSUBSCRIBE pattern [pattern] // 订阅匹配pattern的所有频道 缺陷：每次取出消息直接从队列中移除，造成\n不支持数据持久化：数据不在Redis（内存）中保存。 无法避免消息丢失：如上。 消息堆积有上限，超出时丢失：只在消费者处缓存，有上限。 3. 基于Stream Stream是一种为消息队列设计的数据类型。\n基本添加/读取消息 1 XADD users * name jack age 21 // 向user发{name = jack, age = 21} 1 XREAD COUNT 1 BLOCK 2000 STREAMS users $ // 读users最新的1个消息，无消息阻塞2秒 消费者组 特点：\n消息分流：队列中消息分流而不是重复消费，加快速度。 消息表示：记录最后一个被处理的消息，宕机后也能恢复。 消息确认：消息被获取后存入pending-list，必须要消费者使用XACK确认消息，才会移除。 1 2 3 4 5 6 7 8 9 10 11 XGROUP CREATE mqName groupName ID [MKSTREAM] // ID(0):第一个消息/ID($):最后一个消息 // 为mqName创建名为groupName的消费者组 XGROUP DESTROY mqName groupName XGROUP CREATECONSUMER mqName groupName consumerName XGROUP DELCONSUMER mqName groupName consumerName XREADGROUP GROUP group consumer [COUNT count] [BLOCK milliseconds] [NOACK] STREAMS mqName [mqName ...] ID [ID ...] //ID为获取消息起始id //\u0026#34;\u0026gt;\u0026#34; : 从未消费消息开始 //“数字”: 从pending-list中第一个消息开始 RocketMQ NameServer-Broker NameServer 是 轻量级的服务注册与发现中心，类似于分布式系统中的“电话簿”或“目录服务”。\nBroker 是消息队列中实际存储、转发消息的核心角色。它是生产者和消费者直接打交道的节点，真正处理消息的存储、查询、投递等操作。\n","date":"2025-05-28T00:00:00Z","permalink":"https://sixiyida.github.io/p/message-queue/","title":"Message Queue"},{"content":"锁 行级锁 **行级锁：**在select for update等场景，即当前读（另一种是快照读MVCC）场景使用。\n包括Record Lock, Gap Lock 和 Next-key Lock(前两种的合并)\n包括X(Exclusive)和S(share)两种\nGap Lock是只锁相邻两条记录之间的()，NK-lock是锁(]\nGap Lock的X和S型是一样的，都可以重复获取，NK-lock要看右区间的记录锁是否互斥，无限除外。\n怎么加？（MySQL8.0.26, 可重复读） 对索引加，基本单位是nk-lock，不同情况可能出现退化为前两种\n主键索引等值查询：\n记录存在-\u0026gt;退化为记录\n记录不存在-\u0026gt;退化为间隙锁\n1 select * from performance_schema.data_locks //查加了什么锁 如果MODE是GAP， LOCK_DATA是右区间界。\n主键索引范围查询：\n大于：不退化\n大于等于：如果等于存在，则左边退化为记录锁，不存在则不退化\n小于：最右侧退化为间隙锁\n小于等于：若等于存在，则不退化，不存在则最右侧退化为间隙锁\n**注：**记录锁属于记录，在GAP锁中是属于LOCK_DATA，右区间界的记录。\n二级索引（非唯一）等值查询：\n记录不存在：二级索引上GAPLOCK，对于左右端点，能否插入要看二级索引B+树下一条记录有无GAPLOCK\n记录不存在的特殊情况：如果是超过了最大id，是next-keyLock\n注：二级索引GAPLOCK的LOCK_DATA包含两个值，二级索引和回表的主键索引\n记录存在：对二级索引匹配的记录加nk锁，对不匹配的第一个nk锁退化为间隙锁，且在主键索引加记录锁。\n对于端点是否能插入，和要看二级索引B+树下一条记录有无LOCK\n在不匹配的第一个索引加nk锁的目的：防止幻读（id \u0026gt; lock_id）的情况\n二级索引（非唯一）范围查询：不退化，二级的nk和主键的记录锁都加\n如果不走索引全表扫描，则所有记录全部加nk锁，全锁，是事故\n解决方案：将sql_safe_updates设置为1，此时必须使用where+索引 / limit\n当前读的语句：update、delete、select for update，会加意向锁和行锁\n死锁的形成 例子：如果两个事务都获取了间隔锁，且希望插入对方间隔，则尝试获取插入意向锁（和间隔锁互斥），环路等待导致死锁。\ninsert语句加行级锁 **记录之间有间隙锁：**加插入意向锁\n注：mysql的锁是先生成锁结构，锁此时是等待状态，再获取锁，如果不能获取则阻塞。\n**唯一键（主键或唯一二级索引）冲突：**失败后加S型锁\n主键：加S记录锁\n唯一二级索引：加S型NK锁\n例子：在select for update中，尝试加X型锁，和S型冲突，所以失败。\n并发insert导致的唯一键冲突\n第一个insert但事务没提交时，构造隐式锁。\n第二个insert时，隐式锁变成X型锁，和第二个insert想要获取的S型nk锁冲突\n避免死锁的方法 设置事务等待回滚时间：超时回滚\n1 innodb_lock_wait_timeout = 50 // default 开启主动死锁检测：主动回滚\n1 innodb_deadlock_detect = on 日志 保证ACID特性：Atomic, Consisitency, isolation, duration\nundo log 注：对于增删改语句，innodb会隐式启动事务。\n特殊处理：delete只在记录上打标记，真正删除由purge线程完成\nupdate非主键列：直接update，且在undolog中记录update之前的值\nupdate主键列：先删再插\nundolog的存储形式：由roll_pointer指针形成链表穿起来\nbufferpool 指的是innodb引擎中的内存bufferpool。\n类似于pagecache，由后台线程实现脏页写回机制。\n内存结构：首先申请连续的内存空间，接着按照16kb大小划分出缓存页。\n包括数据页、索引页、undo页、插入缓存页、自适应哈希索引、锁信息等。\nredolog **redolog的作用：**对修改实现持久化。\nWAL技术(write-ahead logging)：在写入磁盘之前先写入redolog。\n每对Bufferpool进行修改就写入redolog，包括undolog的修改\nredolog和undolog对比：\nredolog是记录修改后，保证持久化\nundolog是记录修改前，保证原子化\n写入数据和写入redolog对比：\nredolog：是顺序写入，高效\n数据：是随机写入，低效\nredolog也有buffer，落盘时机：\nmysql正常关闭，buffer空间超过一半，每一秒写回一次。\ninnodb_flush_log_at_trx_commit参数：提交事务时的行为\n0：不写回，后台线程每隔一秒用write()和fsync()\n1：直接持久化到磁盘\n2：写入文件（pagecache）由操作系统写回，后台线程每隔一秒用fsync()\nredolog存储方式：两个redolog文件循环存储类似于环形队列。\n有个tail和head，在tail处写，持久化bufferpool进入数据后更新head。\nbinlog Server层的日志， 用于备份恢复、主从复制。三种格式类型：\nSTATEMENT：记录SQL语句逻辑操作\nROW：记录行数据最终修改情况\nMIXED：根据情况使用STATEMENT或者ROW\n使用追加写，写满文件就创建新文件继续写，全量日志。\n主从复制 主库server层直接写入binlog，后台log dump线程异步将binlog日志发给从库，从库relaylog记录binlog，后台线程异步执行relaylog。\n**从库的数量选择：**对主库的资源消耗、网络带宽。\n其他模型：\n同步模型：要所有从库relaylog记录完毕后返回成功，主库再返回客户端。没法用\n异步模型：默认模型，主库宕机就gg\n半同步：一部分库返回成功即可。\nbinlog也有cache，每个线程各一个。\n持久化的时机：\nbinlog_cache_size：超过这个大小就写入\nsync_binlog：\n0：只write，操作系统控制写回\n1：write+fsync\nn：write，累积n个以后fsync\n注：binlog在语句执行完成后在记录。事务提交时候才持久化。\n两阶段提交 问题：如果redolog和binlog一个完成一个不完成，则会出现主从不一致的问题。\n内部XA事务：在事务提交后开启，由binlog协调。\n将redolog写入拆为prepare和commit，中间插入binlog持久化。\nprepare：将内部XID写入redolog并持久化，将状态设置为prepare。\ncommit：将内部XID写入binlog并持久化，接着将redolog设置为commit。\n崩溃时，redolog处于prepare状态，检查binlog中有无XA事务的id，有则提交事务，无则回滚。\n**问题：**性能差\n磁盘IO次数高\n在多事务下，不能保证两者提交顺序一致，需要加锁以保证提交的原子性\n上述问题：binlog组提交机制\n分为flush(write)、sync(fsync)、commit阶段，每个阶段都有队列，用锁保证事务写入顺序。\nredolog的组提交机制\n将redolog刷盘延迟到flush阶段中\nBufferPool default = 128MB\neach page 16kb\n结构：控制块1到n，接着page1到n\n注：查询时候直接将innodb的整个页加载至bufferpool中，然后在bufferpool中通过页目录定位记录\nFREE链表：管理空闲页，节点是控制块，头结点包括链表头尾地址和控制块数量。\nFLUSH链表：管理空闲页，节点是控制块，头结点包括链表头尾地址和控制块数量。\n如何管理bufferpool：\n传统LRU问题：\n**预读失效：**预读时会把相邻的数据页一并加载，为了减少磁盘IO，如果这些没有被访问，且淘汰末尾页，则降低缓存命中率。\n**解决方法：**划分LRU的优先级，前面是YOUNG，后面是OLD，预读先加入OLD，真正访问才加入YOUNG区域。\n**缓存污染：**当扫描大量数据，会淘汰大量热数据，导致命中率下降。\n**解决方法：**提高加入YOUNG的门槛，记录第一次OLD被访问的时间，如果后续访问时间超过第一次1s，则放入young区域。\n**Linux的做法：**第二次的时候将才升级到active，比MYSQL简单。\n","date":"2025-05-28T00:00:00Z","permalink":"https://sixiyida.github.io/p/mysql/","title":"MySQL"},{"content":"为什么需要分布式锁？ 在单JVM环境中，对于一人一单的场景，可以使用互斥锁实现。但是在负载均衡的集群场景中，需要全局锁，即分布式锁。\n常见的分布式锁实现方式：MySQL、Redis、Zookeeper。\nMySQL分布式锁实现方式：\n1.利用唯一索引，插入唯一键值成功则获取锁，释放锁则直接删除该记录。\n2.利用MySQL排他锁（SELECT FOR UPDATE），提交事务时释放锁。\nRedis分布式锁 加锁 1 SET lock thread1 NX EX 10 1 Boolean success = stringRedisTemplate.opsForValue().setIfAbsent(KEY_PREFIX + name, threadId + \u0026#34;\u0026#34;, timeoutSec, TimeUnit.SECONDS); 解锁 1 DEL lock 1 stringRedisTemplate.delete(KEY_PREFIX + name); 误删问题 由于可能出现线程阻塞超时自动释放，且锁在当前线程恢复之前被其他线程获取，该线程恢复之后如果直接释放锁，会释放其他线程获取的分布式锁，出现混乱。\n解决方法：\n判断锁所有权，再删除。问题：当判断所有权之后如果线程阻塞，同样会出现上述问题。 将1中操作变成原子的，使用Redis提供的Lua脚本。 1 2 3 4 if (redis.call(\u0026#39;get\u0026#39;, KEYS[1]) == ARGV[1]) then return redis.call(\u0026#39;del\u0026#39;, KEYS[1]) end return 0 1 2 3 4 5 stringRedisTemplate.execute( UNLOCK_SCRIPT, Collections.singletonList(KEY_PREFIX + name), threadId ); 基于setnx实现的分布式锁的问题 不可重入：同线程无法多次获取同一把锁，可能会导致同线程不同方法相互依赖导致死锁。 不可重试：获取锁失败没有重试机制 超时释放：执行时间长可能导致锁意外自动超时释放。 主从一致性：加锁后主节点宕机，从节点未同步，导致重复获取锁。 Redisson 基于Redis实现的分布式工具。\nStep0：Maven添加依赖\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.redisson\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;redisson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.22.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; **Step1：**注入RedissonClient\n1 2 3 4 5 6 7 8 9 10 11 @Configuration public class RedissonConfig { @Bean public RedissonClient redissonClient(){ Config config = new Config(); config.useSingleServer().setAddress(\u0026#34;redis://localhost:6379\u0026#34;).setPassword(\u0026#34;password\u0026#34;); return Redisson.create(config); } } **Step2：**使用工具\n1 RLock lock = redissonClient.getLock(RedisConstants.ORDER_LOCK_KEY + userId); Redisson分布式锁原理 基于Lua脚本的可重入 利用hash结构，记录线程id和引用次数。\n加锁：判断是否为当前线程id，如果是，则引用计数+1，重置锁有效期。\n解锁：判断是否为当前线程id，如果不是，不用处理；如果是，则引用计数-1并重置锁有效期。最后判断如果引用计数为0，则释放锁。\n可重试 在解锁时使用信号量/Pub，通知解锁。\n加锁失败后若有剩余等待时间，收到解锁信号后，异步重试。\n锁续期 加锁成功后启动后台线程Watchdog，每10秒检查锁是否被持有，若持有则续期为30秒。\nMultiLock 1 Rlock lock = redissonClient.getMulitLock(lock1, lock2, ...); 原理：\n获取锁：遍历获取 + 失败回滚\n建立锁List，遍历获取锁，遍历时分配每个锁的等待时间。\n若出现获取失败，则释放所有已经获取的锁，并返回失败。\n如果所有锁获取成功则返回成功。\n解锁：遍历释放 + 异常容忍\n遍历所有锁并逐一释放（无论是否属于当前线程）。\n即使某个锁释放失败（如锁已超时），仍继续释放其他锁，最大限度避免死锁。\n","date":"2025-05-28T00:00:00Z","permalink":"https://sixiyida.github.io/p/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","title":"Redis分布式锁"},{"content":"静态代码块初始化 1 2 3 4 5 static { UNLOCK_SCRIPT = new DefaultRedisScript\u0026lt;\u0026gt;(); UNLOCK_SCRIPT.setLocation(new ClassPathResource(\u0026#34;unlock.lua\u0026#34;)); UNLOCK_SCRIPT.setResultType(Long.class); } 在类首次加载时执行一次，如通过new创建对象、访问静态成员或反射加载类时触发\n多个静态代码块按定义顺序依次执行\n可以进行复杂逻辑初始化\n非静态成员变量初始化 在对象创建时完成，顺序为声明赋值 → 初始化块 → 构造函数，每种与代码书写顺序一致。\nSpringBoot中的classpath 一句话总结：classpath 等价于 main/java + main/resources + 第三方jar包的根目录。\n1 UNLOCK_SCRIPT.setLocation(new ClassPathResource(\u0026#34;unlock.lua\u0026#34;)); ClassPathResource对应main/resources目录下文件。\nAOP的内部调用问题 在使用AOP的场景中，如@Transactional，如果使用this指针调用内部方法，会绕过代理导致AOP失效。\n解决方法：\n使用AopContext.currentProxy()直接获取当前代理对象，原理是通过 ThreadLocal 存储当前线程的代理对象。 缺陷：在多线程场景下，如果子线程调用父线程的事务函数，由于ThreadLocal不互通，导致无法获取代理对象，事务失效。\n缺陷的解决方法：直接在主线程中将获取的代理对象传给子线程任务。\n直接使用@Autowired将自身注入。 **缺陷：**循环依赖风险，三级缓存性能低。\nRESTful API：PUT 更新或创建指定位置的资源。客户端需提供完整的资源数据，服务器会完全替换目标 URI 对应的资源。若资源不存在，则新建资源。\n与POST对比：\n特性 PUT POST 幂等性 ✅ 是（多次请求结果一致） ❌ 否（可能产生多个资源） URI 含义 资源唯一标识（如 /users/123） 资源集合（如 /users） 数据完整性 必须提供完整资源 可提交部分数据 典型响应码 200 OK（更新）或 201 Created（新建） 201 Created（新建资源） @Resource和@Autowired对比 @Resource流程\n指定name → 按名称查找 → 失败抛异常\n未指定name → 先按字段名匹配 → 失败则按类型匹配\n指定type → 按类型唯一匹配 → 多匹配抛异常\n@Autowired 流程\n按类型查找 → 找到唯一 Bean → 注入成功\n找到多个同类型 Bean → 需结合 @Qualifier(\u0026quot;beanName\u0026quot;) 指定名称\n无匹配且→ 注入required=false → 注入 null\no instanceof Node node的用法（Java 16+） 等于以下代码：\n1 2 3 if (o instanceof Node) { Node node = (Node) o; } record（Java 16+） 1 public record Person(String name, int age) {} 自动生成内容：\n全参构造器（如Person(String name, int age)） 字段访问器（如name()、age()，而非传统getName()） equals()、hashCode()、toString()方法 所有字段默认为final，实例化后不可修改\nthis() 调用其他构造函数 1 2 3 4 5 6 public record Edge(String sourceId, List\u0026lt;EdgeValue\u0026gt; targets) { // 构造函数 public Edge(String sourceId, EdgeValue target) { this(sourceId, List.of(target)); } } PECS原则 Producer Extends, Consumer Super.\n1 private static List\u0026lt;? extend K\u0026gt; produce() 原因：PE可以保证获取的至少是一个K，这样获取出来的可以直接用K来接，是类型安全的。\n1 private static consume(List\u0026lt;? super U\u0026gt;, U) 原因：CS可以保证接收消费对象的容器装的是其父类对象，可以保证传入的对象可以被向上转型，是类型安全的。\n自定义Collector Collector接口定义了5个核心方法，需全部实现：\nsupplier() 创建结果容器（如ArrayList::new），用于存储中间结果\naccumulator() 定义如何将元素添加到容器（如List::add），处理单个元素的累加逻辑\ncombiner() 合并并行流的子结果（如合并两个List：list1.addAll(list2)），需保证线程安全\nfinisher() 将中间容器转换为最终结果（如StringBuilder::toString），可进行最终转换或过滤\ncharacteristics() 返回收集器特性的Set，影响性能优化：\nCONCURRENT：支持多线程并发操作容器（需线程安全）\nUNORDERED：结果与元素顺序无关（如Set）\nIDENTITY_FINISH：跳过finisher()，直接返回中间容器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 private static \u0026lt;T, K, U\u0026gt; Collector\u0026lt;T, ?, Map\u0026lt;K, U\u0026gt;\u0026gt; toMapRemovingNulls(Function\u0026lt;? super T, ? extends K\u0026gt; keyMapper, Function\u0026lt;? super T, ? extends U\u0026gt; valueMapper, BinaryOperator\u0026lt;U\u0026gt; mergeFunction) { return Collector.of(HashMap::new, (map, element) -\u0026gt; { K key = keyMapper.apply(element); U value = valueMapper.apply(element); if (value == null) { map.remove(key); } else { map.merge(key, value, mergeFunction); } }, (map1, map2) -\u0026gt; { map2.forEach((key, value) -\u0026gt; { if (value != null) { map1.merge(key, value, mergeFunction); } }); return map1; }, Collector.Characteristics.UNORDERED); } Optional对象 将可能为 null 的对象包装在 Optional 容器中，强制开发者显式处理空值场景。\n1 Optional\u0026lt;String\u0026gt; name = Optional.ofNullable(getName()); 提供 map(), flatMap(), filter() 等方法，支持以函数式风格处理值：\n1 2 3 4 5 // 链式获取嵌套属性（避免多层判空） String province = Optional.ofNullable(user) .map(User::getAddress) // 若user非空，提取地址 .map(Address::getProvince) // 若地址非空，提取省份 .orElse(\u0026#34;未知地区\u0026#34;); // 若为空，返回默认值 深拷贝的三种方法 实现clone接口，要求引用属性全部实现clonable接口，递归调用。 直接序列化然后反序列化，要求引用属性全部实现serializable接口。 手动递归复制。 ","date":"2025-05-28T00:00:00Z","permalink":"https://sixiyida.github.io/p/%E6%97%A5%E5%B8%B8%E9%97%AE%E9%A2%98%E9%9B%86/","title":"日常问题集"},{"content":"线段树 核心思想：分治\n节点上维护[l, r]的某个值，左儿子节点维护[l, mid]，右儿子节点维护[mid + 1, r]。\n例题：LeetCode3479\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 class SegmentTree{ vector\u0026lt;int\u0026gt; mx; void maintain(int o){ mx[o] = max(mx[o * 2], mx[o * 2 + 1]); } void build(const vector\u0026lt;int\u0026gt; \u0026amp; a, int o, int l, int r) { if (l == r) { mx[o] = a[l]; return; } int m = (l + r) / 2; build(a, o * 2, l, m); build(a, o * 2 + 1, m + 1, r); maintain(o); //更新的关键操作 } public: SegmentTree(const vector\u0026lt;int\u0026gt; \u0026amp; a) { size_t n = a.size(); mx.resize(2 \u0026lt;\u0026lt; bit_width(n - 1));//? build(a, 1, 0, n - 1); } int findFirstAndUpdate(int o, int l, int r, int x) { if (mx[o] \u0026lt; x) { return -1; } if (l == r) { mx[o] = -1; return l; } int m = (l + r) /2; int i = findFirstAndUpdate(o * 2, l, m, x); if (i \u0026lt; 0) i = findFirstAndUpdate(o * 2 + 1, m + 1, r, x); maintain(o); return i; } }; Lazy线段树 为什么lazy？ ​\t待节点区间完全在需要更新的区间内时，则不继续向下更新，而是标为lazy标记，待下一次需要更新到子节点的时候，再把这个标记向下传递。\n例题：LeetCode2569\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 class LazySegmentTree{ private: vector\u0026lt;int\u0026gt; cnt; vector\u0026lt;int\u0026gt; todo; void maintain(int o) { cnt[o] = cnt[o * 2] + cnt[o * 2 + 1]; } void build(const vector\u0026lt;int\u0026gt; \u0026amp; a, int o, int l, int r) { if (l == r) { cnt[o] = a[l]; return; } int mid = (l + r) / 2; build(a, o * 2, l, mid); build(a, o * 2 + 1, mid + 1, r); maintain(o); } void reverse(int o, int l, int r) { cnt[o] = r - l + 1 - cnt[o]; todo[o] = !todo[o]; } public: LazySegmentTree(const vector\u0026lt;int\u0026gt; \u0026amp; a) { int n = a.size(); cnt.resize(4 * n); todo.resize(4 * n); build(a, 1, 0, n - 1); } void update(int o, int l, int r, int L, int R) { if (L \u0026lt;= l \u0026amp;\u0026amp; r \u0026lt;= R) { //cout \u0026lt;\u0026lt; l \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; r \u0026lt;\u0026lt; endl; reverse(o, l, r); return; } int m = (l + r) / 2; if (todo[o]) { reverse(o * 2, l, m); reverse(o * 2 + 1, m + 1, r); todo[o] = false; } if (m \u0026gt;= L) { update(o * 2, l, m, L, R); } if (m \u0026lt; R) { // m + 1 \u0026lt;= R update(o * 2 + 1, m + 1, r, L, R); } maintain(o); } int getRootVal() { return cnt[1]; } }; KMP算法 核心思想：主串指针不动，子串动。子串从next[sub_ptr]的位置启动，next的含义是从[0, fail_sub_ptr]的子串中，相同的最长真前后缀长度。\n","date":"2025-04-28T00:00:00Z","permalink":"https://sixiyida.github.io/p/algorithms/","title":"Algorithms"}]