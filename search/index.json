[{"content":"@Configuration和@Component @Configuration自身也是一个Bean，默认启用 CGLIB 代理（proxyBeanMethods=true）。当配置类中的 @Bean 方法相互调用时，Spring 会拦截调用并返回容器中的单例 Bean，而非重新创建，可直接注入方法参数的Bean。\n1 2 3 4 5 6 7 @Configuration public class Config { @Bean public A a() { return new A(); } @Bean public B b() { return new B(a()); } // 注入容器中的单例A } @Component无代理机制。方法间调用视为普通 Java 方法，每次调用 @Bean 方法都会创建新实例，破坏单例， 依赖注入需要显式@Autowired：\n1 2 3 4 5 6 7 @Component public class ComponentConfig { @Bean public A a() { return new A(); } @Bean public B b() { return new B(a()); } // 每次调用a()创建新实例！ } ","date":"2025-05-30T00:00:00Z","permalink":"https://sixiyida.github.io/p/spring%E7%9B%B8%E5%85%B3/","title":"Spring相关"},{"content":"为什么需要消息队列？ 在异步任务，如生产者-消费者模型中，两者的运行速度并不相同，使用消息队列可以做一个缓冲，减小系统压力。\nRedis消息队列 1. 基于List Redis的list数据结构是一个双向链表，利用LPUSH和RPOP实现，若需要阻塞，使用BRPOP实现阻塞队列效果\n缺陷：每次取出消息直接从队列中移除，造成\n无法避免消息丢失：移除后如果宕机，则消息丢失。 无法有多消费者：只能消费一次并移除，无法多次消费。 2. 基于Pub/Sub 类似ROS：\n1 2 3 SUBSCRIBE channel [channel] PUBLISH channel msg PSUBSCRIBE pattern [pattern] // 订阅匹配pattern的所有频道 缺陷：每次取出消息直接从队列中移除，造成\n不支持数据持久化：数据不在Redis（内存）中保存。 无法避免消息丢失：如上。 消息堆积有上限，超出时丢失：只在消费者处缓存，有上限。 3. 基于Stream Stream是一种为消息队列设计的数据类型。\n基本添加/读取消息 1 XADD users * name jack age 21 // 向user发{name = jack, age = 21} 1 XREAD COUNT 1 BLOCK 2000 STREAMS users $ // 读users最新的1个消息，无消息阻塞2秒 消费者组 特点：\n消息分流：队列中消息分流而不是重复消费，加快速度。 消息表示：记录最后一个被处理的消息，宕机后也能恢复。 消息确认：消息被获取后存入pending-list，必须要消费者使用XACK确认消息，才会移除。 1 2 3 4 5 6 7 8 9 10 11 XGROUP CREATE mqName groupName ID [MKSTREAM] // ID(0):第一个消息/ID($):最后一个消息 // 为mqName创建名为groupName的消费者组 XGROUP DESTROY mqName groupName XGROUP CREATECONSUMER mqName groupName consumerName XGROUP DELCONSUMER mqName groupName consumerName XREADGROUP GROUP group consumer [COUNT count] [BLOCK milliseconds] [NOACK] STREAMS mqName [mqName ...] ID [ID ...] //ID为获取消息起始id //\u0026#34;\u0026gt;\u0026#34; : 从未消费消息开始 //“数字”: 从pending-list中第一个消息开始 ","date":"2025-05-28T00:00:00Z","permalink":"https://sixiyida.github.io/p/message-queue/","title":"Message Queue"},{"content":"锁 行级锁 **行级锁：**在select for update等场景，即当前读（另一种是快照读MVCC）场景使用。\n包括Record Lock, Gap Lock 和 Next-key Lock(前两种的合并)\n包括X(Exclusive)和S(share)两种\nGap Lock是只锁相邻两条记录之间的()，NK-lock是锁(]\nGap Lock的X和S型是一样的，都可以重复获取，NK-lock要看右区间的记录锁是否互斥，无限除外。\n怎么加？（MySQL8.0.26, 可重复读） 对索引加，基本单位是nk-lock，不同情况可能出现退化为前两种\n主键索引等值查询：\n记录存在-\u0026gt;退化为记录\n记录不存在-\u0026gt;退化为间隙锁\n1 select * from performance_schema.data_locks //查加了什么锁 如果MODE是GAP， LOCK_DATA是右区间界。\n主键索引范围查询：\n大于：不退化\n大于等于：如果等于存在，则左边退化为记录锁，不存在则不退化\n小于：最右侧退化为间隙锁\n小于等于：若等于存在，则不退化，不存在则最右侧退化为间隙锁\n**注：**记录锁属于记录，在GAP锁中是属于LOCK_DATA，右区间界的记录。\n二级索引（非唯一）等值查询：\n记录不存在：二级索引上GAPLOCK，对于左右端点，能否插入要看二级索引B+树下一条记录有无GAPLOCK\n记录不存在的特殊情况：如果是超过了最大id，是next-keyLock\n注：二级索引GAPLOCK的LOCK_DATA包含两个值，二级索引和回表的主键索引\n记录存在：对二级索引匹配的记录加nk锁，对不匹配的第一个nk锁退化为间隙锁，且在主键索引加记录锁。\n对于端点是否能插入，和要看二级索引B+树下一条记录有无LOCK\n在不匹配的第一个索引加nk锁的目的：防止幻读（id \u0026gt; lock_id）的情况\n二级索引（非唯一）范围查询：不退化，二级的nk和主键的记录锁都加\n如果不走索引全表扫描，则所有记录全部加nk锁，全锁，是事故\n解决方案：将sql_safe_updates设置为1，此时必须使用where+索引 / limit\n当前读的语句：update、delete、select for update，会加意向锁和行锁\n死锁的形成 例子：如果两个事务都获取了间隔锁，且希望插入对方间隔，则尝试获取插入意向锁（和间隔锁互斥），环路等待导致死锁。\ninsert语句加行级锁 **记录之间有间隙锁：**加插入意向锁\n注：mysql的锁是先生成锁结构，锁此时是等待状态，再获取锁，如果不能获取则阻塞。\n**唯一键（主键或唯一二级索引）冲突：**失败后加S型锁\n主键：加S记录锁\n唯一二级索引：加S型NK锁\n例子：在select for update中，尝试加X型锁，和S型冲突，所以失败。\n并发insert导致的唯一键冲突\n第一个insert但事务没提交时，构造隐式锁。\n第二个insert时，隐式锁变成X型锁，和第二个insert想要获取的S型nk锁冲突\n避免死锁的方法 设置事务等待回滚时间：超时回滚\n1 innodb_lock_wait_timeout = 50 // default 开启主动死锁检测：主动回滚\n1 innodb_deadlock_detect = on 日志 保证ACID特性：Atomic, Consisitency, isolation, duration\nundo log 注：对于增删改语句，innodb会隐式启动事务。\n特殊处理：delete只在记录上打标记，真正删除由purge线程完成\nupdate非主键列：直接update，且在undolog中记录update之前的值\nupdate主键列：先删再插\nundolog的存储形式：由roll_pointer指针形成链表穿起来\nbufferpool 指的是innodb引擎中的内存bufferpool。\n类似于pagecache，由后台线程实现脏页写回机制。\n内存结构：首先申请连续的内存空间，接着按照16kb大小划分出缓存页。\n包括数据页、索引页、undo页、插入缓存页、自适应哈希索引、锁信息等。\nredolog **redolog的作用：**对修改实现持久化。\nWAL技术(write-ahead logging)：在写入磁盘之前先写入redolog。\n每对Bufferpool进行修改就写入redolog，包括undolog的修改\nredolog和undolog对比：\nredolog是记录修改后，保证持久化\nundolog是记录修改前，保证原子化\n写入数据和写入redolog对比：\nredolog：是顺序写入，高效\n数据：是随机写入，低效\nredolog也有buffer，落盘时机：\nmysql正常关闭，buffer空间超过一半，每一秒写回一次。\ninnodb_flush_log_at_trx_commit参数：提交事务时的行为\n0：不写回，后台线程每隔一秒用write()和fsync()\n1：直接持久化到磁盘\n2：写入文件（pagecache）由操作系统写回，后台线程每隔一秒用fsync()\nredolog存储方式：两个redolog文件循环存储类似于环形队列。\n有个tail和head，在tail处写，持久化bufferpool进入数据后更新head。\nbinlog Server层的日志， 用于备份恢复、主从复制。三种格式类型：\nSTATEMENT：记录SQL语句逻辑操作\nROW：记录行数据最终修改情况\nMIXED：根据情况使用STATEMENT或者ROW\n使用追加写，写满文件就创建新文件继续写，全量日志。\n主从复制 主库server层直接写入binlog，后台log dump线程异步将binlog日志发给从库，从库relaylog记录binlog，后台线程异步执行relaylog。\n**从库的数量选择：**对主库的资源消耗、网络带宽。\n其他模型：\n同步模型：要所有从库relaylog记录完毕后返回成功，主库再返回客户端。没法用\n异步模型：默认模型，主库宕机就gg\n半同步：一部分库返回成功即可。\nbinlog也有cache，每个线程各一个。\n持久化的时机：\nbinlog_cache_size：超过这个大小就写入\nsync_binlog：\n0：只write，操作系统控制写回\n1：write+fsync\nn：write，累积n个以后fsync\n注：binlog在语句执行完成后在记录。事务提交时候才持久化。\n两阶段提交 问题：如果redolog和binlog一个完成一个不完成，则会出现主从不一致的问题。\n内部XA事务：在事务提交后开启，由binlog协调。\n将redolog写入拆为prepare和commit，中间插入binlog持久化。\nprepare：将内部XID写入redolog并持久化，将状态设置为prepare。\ncommit：将内部XID写入binlog并持久化，接着将redolog设置为commit。\n崩溃时，redolog处于prepare状态，检查binlog中有无XA事务的id，有则提交事务，无则回滚。\n**问题：**性能差\n磁盘IO次数高\n在多事务下，不能保证两者提交顺序一致，需要加锁以保证提交的原子性\n上述问题：binlog组提交机制\n分为flush(write)、sync(fsync)、commit阶段，每个阶段都有队列，用锁保证事务写入顺序。\nredolog的组提交机制\n将redolog刷盘延迟到flush阶段中\nBufferPool default = 128MB\neach page 16kb\n结构：控制块1到n，接着page1到n\n注：查询时候直接将innodb的整个页加载至bufferpool中，然后在bufferpool中通过页目录定位记录\nFREE链表：管理空闲页，节点是控制块，头结点包括链表头尾地址和控制块数量。\nFLUSH链表：管理空闲页，节点是控制块，头结点包括链表头尾地址和控制块数量。\n如何管理bufferpool：\n传统LRU问题：\n**预读失效：**预读时会把相邻的数据页一并加载，为了减少磁盘IO，如果这些没有被访问，且淘汰末尾页，则降低缓存命中率。\n**解决方法：**划分LRU的优先级，前面是YOUNG，后面是OLD，预读先加入OLD，真正访问才加入YOUNG区域。\n**缓存污染：**当扫描大量数据，会淘汰大量热数据，导致命中率下降。\n**解决方法：**提高加入YOUNG的门槛，记录第一次OLD被访问的时间，如果后续访问时间超过第一次1s，则放入young区域。\n**Linux的做法：**第二次的时候将才升级到active，比MYSQL简单。\n","date":"2025-05-28T00:00:00Z","permalink":"https://sixiyida.github.io/p/mysql/","title":"MySQL"},{"content":"为什么需要分布式锁？ 在单JVM环境中，对于一人一单的场景，可以使用互斥锁实现。但是在负载均衡的集群场景中，需要全局锁，即分布式锁。\n常见的分布式锁实现方式：MySQL、Redis、Zookeeper。\nMySQL分布式锁实现方式：\n1.利用唯一索引，插入唯一键值成功则获取锁，释放锁则直接删除该记录。\n2.利用MySQL排他锁（SELECT FOR UPDATE），提交事务时释放锁。\nRedis分布式锁 加锁 1 SET lock thread1 NX EX 10 1 Boolean success = stringRedisTemplate.opsForValue().setIfAbsent(KEY_PREFIX + name, threadId + \u0026#34;\u0026#34;, timeoutSec, TimeUnit.SECONDS); 解锁 1 DEL lock 1 stringRedisTemplate.delete(KEY_PREFIX + name); 误删问题 由于可能出现线程阻塞超时自动释放，且锁在当前线程恢复之前被其他线程获取，该线程恢复之后如果直接释放锁，会释放其他线程获取的分布式锁，出现混乱。\n解决方法：\n判断锁所有权，再删除。问题：当判断所有权之后如果线程阻塞，同样会出现上述问题。 将1中操作变成原子的，使用Redis提供的Lua脚本。 1 2 3 4 if (redis.call(\u0026#39;get\u0026#39;, KEYS[1]) == ARGV[1]) then return redis.call(\u0026#39;del\u0026#39;, KEYS[1]) end return 0 1 2 3 4 5 stringRedisTemplate.execute( UNLOCK_SCRIPT, Collections.singletonList(KEY_PREFIX + name), threadId ); 基于setnx实现的分布式锁的问题 不可重入：同线程无法多次获取同一把锁，可能会导致同线程不同方法相互依赖导致死锁。 不可重试：获取锁失败没有重试机制 超时释放：执行时间长可能导致锁意外自动超时释放。 主从一致性：加锁后主节点宕机，从节点未同步，导致重复获取锁。 Redisson 基于Redis实现的分布式工具。\nStep0：Maven添加依赖\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.redisson\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;redisson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.22.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; **Step1：**注入RedissonClient\n1 2 3 4 5 6 7 8 9 10 11 @Configuration public class RedissonConfig { @Bean public RedissonClient redissonClient(){ Config config = new Config(); config.useSingleServer().setAddress(\u0026#34;redis://localhost:6379\u0026#34;).setPassword(\u0026#34;password\u0026#34;); return Redisson.create(config); } } **Step2：**使用工具\n1 RLock lock = redissonClient.getLock(RedisConstants.ORDER_LOCK_KEY + userId); Redisson分布式锁原理 基于Lua脚本的可重入 利用hash结构，记录线程id和引用次数。\n加锁：判断是否为当前线程id，如果是，则引用计数+1，重置锁有效期。\n解锁：判断是否为当前线程id，如果不是，不用处理；如果是，则引用计数-1并重置锁有效期。最后判断如果引用计数为0，则释放锁。\n可重试 在解锁时使用信号量/Pub，通知解锁。\n加锁失败后若有剩余等待时间，收到解锁信号后，异步重试。\n锁续期 加锁成功后启动后台线程Watchdog，每10秒检查锁是否被持有，若持有则续期为30秒。\nMultiLock 1 Rlock lock = redissonClient.getMulitLock(lock1, lock2, ...); 原理：\n获取锁：遍历获取 + 失败回滚\n建立锁List，遍历获取锁，遍历时分配每个锁的等待时间。\n若出现获取失败，则释放所有已经获取的锁，并返回失败。\n如果所有锁获取成功则返回成功。\n解锁：遍历释放 + 异常容忍\n遍历所有锁并逐一释放（无论是否属于当前线程）。\n即使某个锁释放失败（如锁已超时），仍继续释放其他锁，最大限度避免死锁。\n","date":"2025-05-28T00:00:00Z","permalink":"https://sixiyida.github.io/p/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","title":"Redis分布式锁"},{"content":"静态代码块初始化 1 2 3 4 5 static { UNLOCK_SCRIPT = new DefaultRedisScript\u0026lt;\u0026gt;(); UNLOCK_SCRIPT.setLocation(new ClassPathResource(\u0026#34;unlock.lua\u0026#34;)); UNLOCK_SCRIPT.setResultType(Long.class); } 在类首次加载时执行一次，如通过new创建对象、访问静态成员或反射加载类时触发\n多个静态代码块按定义顺序依次执行\n可以进行复杂逻辑初始化\n非静态成员变量初始化 在对象创建时完成，顺序为声明赋值 → 初始化块 → 构造函数，每种与代码书写顺序一致。\nSpringBoot中的classpath 一句话总结：classpath 等价于 main/java + main/resources + 第三方jar包的根目录。\n1 UNLOCK_SCRIPT.setLocation(new ClassPathResource(\u0026#34;unlock.lua\u0026#34;)); ClassPathResource对应main/resources目录下文件。\nAOP的内部调用问题 在使用AOP的场景中，如@Transactional，如果使用this指针调用内部方法，会绕过代理导致AOP失效。\n解决方法：\n使用AopContext.currentProxy()直接获取当前代理对象，原理是通过 ThreadLocal 存储当前线程的代理对象。 缺陷：在多线程场景下，如果子线程调用父线程的事务函数，由于ThreadLocal不互通，导致无法获取代理对象，事务失效。\n缺陷的解决方法：直接在主线程中将获取的代理对象传给子线程任务。\n直接使用@Autowired将自身注入。 **缺陷：**循环依赖风险，三级缓存性能低。\n","date":"2025-05-28T00:00:00Z","permalink":"https://sixiyida.github.io/p/%E6%97%A5%E5%B8%B8%E9%97%AE%E9%A2%98%E9%9B%86/","title":"日常问题集"},{"content":"线段树 核心思想：分治\n节点上维护[l, r]的某个值，左儿子节点维护[l, mid]，右儿子节点维护[mid + 1, r]。\n例题：LeetCode3479\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 class SegmentTree{ vector\u0026lt;int\u0026gt; mx; void maintain(int o){ mx[o] = max(mx[o * 2], mx[o * 2 + 1]); } void build(const vector\u0026lt;int\u0026gt; \u0026amp; a, int o, int l, int r) { if (l == r) { mx[o] = a[l]; return; } int m = (l + r) / 2; build(a, o * 2, l, m); build(a, o * 2 + 1, m + 1, r); maintain(o); //更新的关键操作 } public: SegmentTree(const vector\u0026lt;int\u0026gt; \u0026amp; a) { size_t n = a.size(); mx.resize(2 \u0026lt;\u0026lt; bit_width(n - 1));//? build(a, 1, 0, n - 1); } int findFirstAndUpdate(int o, int l, int r, int x) { if (mx[o] \u0026lt; x) { return -1; } if (l == r) { mx[o] = -1; return l; } int m = (l + r) /2; int i = findFirstAndUpdate(o * 2, l, m, x); if (i \u0026lt; 0) i = findFirstAndUpdate(o * 2 + 1, m + 1, r, x); maintain(o); return i; } }; Lazy线段树 为什么lazy？ ​\t待节点区间完全在需要更新的区间内时，则不继续向下更新，而是标为lazy标记，待下一次需要更新到子节点的时候，再把这个标记向下传递。\n例题：LeetCode2569\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 class LazySegmentTree{ private: vector\u0026lt;int\u0026gt; cnt; vector\u0026lt;int\u0026gt; todo; void maintain(int o) { cnt[o] = cnt[o * 2] + cnt[o * 2 + 1]; } void build(const vector\u0026lt;int\u0026gt; \u0026amp; a, int o, int l, int r) { if (l == r) { cnt[o] = a[l]; return; } int mid = (l + r) / 2; build(a, o * 2, l, mid); build(a, o * 2 + 1, mid + 1, r); maintain(o); } void reverse(int o, int l, int r) { cnt[o] = r - l + 1 - cnt[o]; todo[o] = !todo[o]; } public: LazySegmentTree(const vector\u0026lt;int\u0026gt; \u0026amp; a) { int n = a.size(); cnt.resize(4 * n); todo.resize(4 * n); build(a, 1, 0, n - 1); } void update(int o, int l, int r, int L, int R) { if (L \u0026lt;= l \u0026amp;\u0026amp; r \u0026lt;= R) { //cout \u0026lt;\u0026lt; l \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; r \u0026lt;\u0026lt; endl; reverse(o, l, r); return; } int m = (l + r) / 2; if (todo[o]) { reverse(o * 2, l, m); reverse(o * 2 + 1, m + 1, r); todo[o] = false; } if (m \u0026gt;= L) { update(o * 2, l, m, L, R); } if (m \u0026lt; R) { // m + 1 \u0026lt;= R update(o * 2 + 1, m + 1, r, L, R); } maintain(o); } int getRootVal() { return cnt[1]; } }; KMP算法 核心思想：主串指针不动，子串动。子串从next[sub_ptr]的位置启动，next的含义是从[0, fail_sub_ptr]的子串中，相同的最长真前后缀长度。\n","date":"2025-04-28T00:00:00Z","permalink":"https://sixiyida.github.io/p/algorithms/","title":"Algorithms"}]