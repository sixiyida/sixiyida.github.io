[{"content":"\nList ArrayList LinkedList Vector CopyOnWriteArrayList 类似C++的Vector，略 类似C++的List，略 同步ArrayList 写时复制，读无锁，提升并发性能 遍历时修改 用foreach不能修改，容易出现问题。\n用迭代器/for遍历，可以修改，迭代器修改要使用迭代器的set方法。\n对COWA，可以修改，因为在副本上修改。\nArrayList多线程访问下可能出现的问题 以多线程add元素为例。\n竞争扩容导致部分值设置为null。 竞争导致不扩容，导致越界访问。 覆盖同一位置的值。 扩容操作 类似C++中Vector，只是在Java中扩容倍数是1.5倍，而Vector是两倍。\nCOAW的线程安全 读时无锁，写时获取互斥锁并复制。\nMAP HashMap LinkedHashMap TreeMap HashTable ConcurrentHashMap unordered_map + 红黑树链地址法 双向链表维护底层，迭代顺序和插入顺序一致。 map 加大锁的HashMap 元素级锁的HashMap 遍历方法 For-each+entrySet/keySet 迭代器 foreach方法 StreamAPI HashMap竞争问题 JDK1.7之前 Entry散链死循环问题：\n由于头插法（在链表头部插入），当线程T1、T2同时扩容时，可能会出现以下情况：\nT2扩容后反转链表为B-\u0026gt;A，但是T1仍然操纵旧链表的头节点A，且认为A的next是B，导致AB之间相互指向。\n数据丢失问题：\n类似于List的扩容null问题。\nJDK1.8之后 散链改成了红黑树结构，只存在数据覆盖问题。 Put流程 前面hash-\u0026gt;CAS跳过，后续是：检查散链大小（8）-\u0026gt;转红黑树？-\u0026gt;检查负载因子-\u0026gt;扩容两倍？\n注意：key可以为null，当为null时候令hashCode为0\nHashMap用String做Key的原因 String不可变，保证Key稳定性。\n对重写hashCode()和equals()的限制 equals是hashCode相等的充分不必要条件。\nHashMap扩容是两倍的原因 新hash值=旧哈希值+新hash值最高位代表数值（0或者是旧容量）。\nConcurrentHashMap原理 1.8以后：当容器为空/散链为空，用CAS初始化；当不为空，对散链头节点加互斥锁，锁粒度减小，并发量上升。\n","date":"2025-06-24T00:00:00Z","permalink":"https://sixiyida.github.io/p/%E5%85%AB%E8%82%A1%E6%96%87%E4%B9%8Bjava%E9%9B%86%E5%90%88/","title":"八股文之Java集合"},{"content":"深拷贝的三种方法 实现clone接口，要求引用属性全部实现clonable接口，递归调用。 直接序列化然后反序列化，要求引用属性全部实现serializable接口。 手动递归复制。 反射的应用场景 加载数据库驱动，动态加载驱动类。 IOC容器自动装配，根据类名动态加载实例。（这个在spring八股里面细说） 注解 本质上是一种继承自Annotation的特殊接口，在定义注解时候，编译器会将其转换为接口并生成字节码。\n根据作用范围分类：\n源码级别注解 类文件级别注解（在.class中但是运行不可见） 运行时（在.class中运行可见） 注解的解析 所有可以被注解修饰的元素都实现了AnnotatedElement接口，底层依赖本地方法，JVM在加载类的时候会解析.class中的注解信息存储在内存中，并创建注解代理对象获取注解属性值。\n作用域 类、方法、属性、构造函数、局部变量。\n异常 Error：严重问题，程序无法处理，无法捕捉。 RuntimeException：运行时的问题，如非法内存访问。 非运行时异常：编译时候的问题，如类文件不存在等。 Try-Catch 注意：finally中的return会覆盖try中的。\nLambda表达式和匿名内部类 匿名内部类：\n1 2 3 4 new Runnable(){ @Override public void run(){} } lambda表达式：\n1 () -\u0026gt; {} //等于重写函数式接口唯一方法 异步编程 Future 表示异步计算的结果，只能阻塞或者轮询获取，不支持回调方法。\n回调地狱：指的是当异步操作需要顺序执行的时候，需要将每个操作的回调函数嵌套在上一个工作的回调中，形成深层嵌套。\nCompletableFuture 更为简洁，可读性更好。\n可以通过函数式编程思想对异步调用进行编排。\n（例子待补充）\n单例模式实现 双重检查锁定：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class SingleTon { // volatile 关键字修饰变量 防止指令重排序 private static volatile SingleTon instance = null; private SingleTon(){} public static SingleTon getInstance(){ if(instance == null){ synchronized(SingleTon.class){ if(instance == null){ instance = new SingleTon(); } } } return instance; } } **第一重检查：**优化性能，否则每次都进入方法级加锁同步。\n**第二重检查：**解决竞争问题。\n与C++对比：不支持局部静态变量。\n代理模式和适配器模式 代理模式 略。\n适配器模式 指将旧类适配新接口的新类。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 目标接口（新接口） interface PaymentProcessor { void processPayment(double amount); } // 适配者（旧类） class OldPaymentSystem { void makePayment(double amount) { System.out.println(\u0026#34;旧支付系统扣款\u0026#34;); } } // 适配器 class PaymentAdapter implements PaymentProcessor { private OldPaymentSystem oldSystem; @Override public void processPayment(double amount) { oldSystem.makePayment(amount); // 调用旧类方法 } } 对比 维度 代理模式 适配器模式 核心目标 控制对对象的访问，添加额外功能 解决接口不兼容问题，无功能增强。 角色关系 代理与目标对象实现相同接口 适配器实现目标接口，但包装适配者。 功能增强 可添加逻辑（如日志、权限） 仅转换接口，不增强功能。 应用场景 权限控制、延迟加载、远程调用 旧系统整合、第三方库兼容。 实现关键 代理持有目标对象引用 适配器持有适配者对象引用。 主要区别：就是目的不同，一个增强功能，一个转换适配。\nI/O BIO/NIO/AIO BIO 同步阻塞IO，传统java.io包。\nNIO Java1.4引入，同步非阻塞IO，包含IO多路复用，经典NIO框架是Netty，实现了Reactor和Proactor模式。\nAIO Java1.7引入，异步IO，对内存访问也是异步的。\nNative方法 类似于C++动态库加载函数 ，步骤有以下几步：\n**生成JNI头文件：**使用javah工具从你的Java类生成C/C++的头文件，这个头文件包含了所有native方法的原型。\n**编写本地代码：**使用C/C++编写本地方法的实现，并确保方法签名与生成的头文件中的原型匹配。\n**编译本地代码：**将C/C++代码编译成动态链接库（DLL，在Windows上），共享库（SO，在Linux上）。\n**加载本地库：**在Java程序中，使用System.loadLibrary()方法来加载你编译好的本地库，这样JVM就能找到并调用native方法的实现了。\n","date":"2025-06-20T00:00:00Z","permalink":"https://sixiyida.github.io/p/%E5%85%AB%E8%82%A1%E6%96%87%E4%B9%8Bjava%E5%9F%BA%E7%A1%80/","title":"八股文之Java基础"},{"content":"spring-ai-alibaba-graph-core 源码阅读 1 StateGraph 1.1 基础结构 1 2 3 4 5 6 7 8 9 10 public class StateGraph { // 核心数据结构 final Nodes nodes = new Nodes(); // 存储所有节点 final Edges edges = new Edges(); // 存储所有边 // 特殊节点常量 public static final String END = \u0026#34;__END__\u0026#34;; // 结束节点 public static final String START = \u0026#34;__START__\u0026#34;; // 起始节点 public static final String ERROR = \u0026#34;__ERROR__\u0026#34;; // 错误节点 } 1.2 构造方法 1 public StateGraph(String name, KeyStrategyFactory keyStrategyFactory, PlainTextStateSerializer stateSerializer) 参数必选KeyStrategyFactory，其他可选，序列化默认JacksonSerializer()。\n1.3 节点管理 节点具体实现请见2\n1 2 3 4 5 6 7 8 public static class Nodes { public final Set\u0026lt;Node\u0026gt; elements; // 节点集合 // 节点操作方法 public boolean anyMatchById(String id) // 检查节点是否存在 public List\u0026lt;SubStateGraphNode\u0026gt; onlySubStateGraphNodes() // 获取子图节点 public List\u0026lt;Node\u0026gt; exceptSubStateGraphNodes() // 获取非子图节点 } 1.4 边管理 1 2 3 4 5 6 7 public static class Edges { public final List\u0026lt;Edge\u0026gt; elements; // 边集合 // 边操作方法 public Optional\u0026lt;Edge\u0026gt; edgeBySourceId(String sourceId) // 根据源节点查找边 public List\u0026lt;Edge\u0026gt; edgesByTargetId(String targetId) // 根据目标节点查找边 } 1.5 添加节点 1 2 3 4 5 6 // 添加普通节点 public StateGraph addNode(String id, AsyncNodeAction action) // 添加带配置的节点 public StateGraph addNode(String id, AsyncNodeActionWithConfig actionWithConfig) // 添加子图节点 public StateGraph addNode(String id, StateGraph subGraph) 1.6 添加边 1 2 3 4 // 添加普通边 public StateGraph addEdge(String sourceId, String targetId) // 添加条件边 public StateGraph addConditionalEdges(String sourceId, AsyncCommandAction condition, Map\u0026lt;String, String\u0026gt; mappings) 1.7 图验证、编译和可视化 1 2 3 4 5 6 // 验证图的正确性 void validateGraph() throws GraphStateException // 编译图 public CompiledGraph compile(CompileConfig config) throws GraphStateException // 可视化 public GraphRepresentation getGraph(GraphRepresentation.Type type, String title) 1.8 序列化器 1 2 3 static class JacksonSerializer extends JacksonStateSerializer static class GsonSerializer extends GsonStateSerializer 1.9 状态管理 1 2 3 4 // 状态工厂 private OverAllStateFactory overAllStateFactory; // 键策略工厂 private KeyStrategyFactory keyStrategyFactory; 2 Node 2.1 Node基础节点 1 2 3 4 5 6 7 8 9 public class Node { private final String id; // 节点唯一标识 private final ActionFactory actionFactory; // 动作工厂 // 动作工厂接口 public interface ActionFactory { AsyncNodeActionWithConfig apply(CompileConfig config) throws GraphStateException; } } 2.2 ParalellNode 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class ParallelNode extends Node { public static final String PARALLEL_PREFIX = \u0026#34;__PARALLEL__\u0026#34;; // 并行动作实现 record AsyncParallelNodeAction( List\u0026lt;AsyncNodeActionWithConfig\u0026gt; actions, // 并行执行的动作列表 Map\u0026lt;String, KeyStrategy\u0026gt; channels // 通道策略 ) implements AsyncNodeActionWithConfig { // 并行执行所有动作 public CompletableFuture\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; apply(OverAllState state, RunnableConfig config) { // 使用 CompletableFuture 实现并行执行 } } } 待补充\n2.3 子图节点 2.3.1 子图节点接口 1 2 3 4 5 6 7 public interface SubGraphNode { String PREFIX_FORMAT = \u0026#34;%s-%s\u0026#34;; // 节点ID格式化模板 String id(); // 获取节点ID StateGraph subGraph(); // 获取子图 String formatId(String nodeId); // 格式化节点ID } 2.3.2 状态图子图节点 1 2 3 4 5 6 7 8 public class SubStateGraphNode extends Node implements SubGraphNode { private final StateGraph subGraph; // 子图 // 格式化节点ID public String formatId(String nodeId) { return SubGraphNode.formatId(id(), nodeId); } } 2.3.3 编译后的子图节点 1 2 3 4 5 6 7 8 public class SubCompiledGraphNode extends Node implements SubGraphNode { private final CompiledGraph subGraph; // 编译后的子图 public SubCompiledGraphNode(String id, CompiledGraph subGraph) { super(id, (config) -\u0026gt; new SubCompiledGraphNodeAction(subGraph)); this.subGraph = subGraph; } } 3 Edge 3.1 基础边Edge 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public record Edge(String sourceId, List\u0026lt;EdgeValue\u0026gt; targets) { // 构造函数 public Edge(String sourceId, EdgeValue target) { this(sourceId, List.of(target)); } // 判断是否为并行边 public boolean isParallel() { return targets.size() \u0026gt; 1; } // 验证边的有效性 public void validate(StateGraph.Nodes nodes) throws GraphStateException { // 验证源节点存在 // 验证目标节点存在 // 验证并行边的目标不重复 } } 3.2 EdgeCondition 1 2 3 4 5 6 public record EdgeCondition( AsyncCommandAction action, // 异步命令动作 Map\u0026lt;String, String\u0026gt; mappings // 条件映射 ) { // 条件执行逻辑 } 3.3 EdgeValue 1 2 3 4 5 6 7 8 9 10 11 public record EdgeValue(String id, EdgeCondition value) { // 简单边值（只有ID） public EdgeValue(String id) { this(id, null); } // 条件边值（只有条件） public EdgeValue(EdgeCondition value) { this(null, value); } } 4 OverAllState OverAllState 是状态管理的核心，它贯穿整个图的执行过程。\n所有的 Action 都需要依赖状态来执行和传递数据。\n4.1 核心数据结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public final class OverAllState implements Serializable { // 状态数据存储 private final Map\u0026lt;String, Object\u0026gt; data; // 键策略映射 private final Map\u0026lt;String, KeyStrategy\u0026gt; keyStrategies; // 恢复标志 private Boolean resume; // 人工反馈 private HumanFeedback humanFeedback; // 中断消息 private String interruptMessage; } 4.2 状态控制 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public void cover(OverAllState overAllState){ // 替换所有数据 } public OverAllState input(Map\u0026lt;String, Object\u0026gt; input) { // input是null或空直接返回 // 使用keyStrategies操作key对应value Map\u0026lt;String, KeyStrategy\u0026gt; keyStrategies = keyStrategies(); input.keySet().stream().filter(key -\u0026gt; keyStrategies.containsKey(key)).forEach(key -\u0026gt; { this.data.put(key, keyStrategies.get(key).apply(value(key, null), input.get(key))); }); return this; } public Map\u0026lt;String, Object\u0026gt; updateState(Map\u0026lt;String, Object\u0026gt; partialState) { // 用partialState更新状态，和input一样 } public static Map\u0026lt;String, Object\u0026gt; updateState(Map\u0026lt;String, Object\u0026gt; state, Map\u0026lt;String, Object\u0026gt; partialState, Map\u0026lt;String, KeyStrategy\u0026gt; keyStrategies){ // 同上 } private static Map\u0026lt;String, Object\u0026gt; updatePartialStateFromSchema(Map\u0026lt;String, Object\u0026gt; state, Map\u0026lt;String, Object\u0026gt; partialState, Map\u0026lt;String, KeyStrategy\u0026gt; keyStrategies){ // 返回更新后的partialState但不更新状态 } 4.3 策略控制 1 2 3 4 5 6 // 注册键策略 public OverAllState registerKeyAndStrategy(String key, KeyStrategy strategy) public OverAllState registerKeyAndStrategy(Map\u0026lt;String, KeyStrategy\u0026gt; keyStrategies) // 检查策略 public boolean containStrategy(String key) 5 Action 提供了Node、Edge、Command的同异步action接口，其中同步action可以转换为异步。\n1 2 3 4 5 6 7 8 9 10 // DeepResearch中的节点 public class BackgroundInvestigationNode implements NodeAction { @Override public Map\u0026lt;String, Object\u0026gt; apply(OverAllState state) throws Exception { //... return resultMap; } } Command待完善\n6 CompiledGraph 6.1 核心属性 1 2 3 4 5 6 7 public final StateGraph stateGraph; // 状态图 private final Map\u0026lt;String, KeyStrategy\u0026gt; keyStrategyMap; // 键策略映射 final Map\u0026lt;String, AsyncNodeActionWithConfig\u0026gt; nodes; // 节点映射 final Map\u0026lt;String, EdgeValue\u0026gt; edges; // 边映射 private final ProcessedNodesEdgesAndConfig processedData; // 处理后的节点和边配置 private int maxIterations = 25; // 最大迭代次数 public final CompileConfig compileConfig; // 编译配置 6.1.1 CompileConfig 6.1.1.1 核心属性 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class CompileConfig { // 检查点保存器配置 private SaverConfig saverConfig = new SaverConfig().register(MEMORY, new MemorySaver()); // 待阅读 // 生命周期监听器队列 private Deque\u0026lt;GraphLifecycleListener\u0026gt; lifecycleListeners = new LinkedBlockingDeque\u0026lt;\u0026gt;(25); // 中断点配置 private Set\u0026lt;String\u0026gt; interruptsBefore = Set.of(); // 节点执行前中断 private Set\u0026lt;String\u0026gt; interruptsAfter = Set.of(); // 节点执行后中断 // 线程释放标志 private boolean releaseThread = false; } ","date":"2025-06-06T00:00:00Z","permalink":"https://sixiyida.github.io/p/spring-ai-alibaba-graph-core-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/","title":"spring-ai-alibaba-graph-core 源码阅读"},{"content":"1. Deep Research Executor节点并行 1.1 问题描述 ​\t当前架构中，Research Team节点后的负责执行plan的Executors (Researcher/Coder) 是串行执行的，每一步都需要等待上一个step执行完毕，耗费大量时间。经测试，一个5step的plan耗时需要4分钟，占据了整个执行流程的70%。\n​\t测试观察发现，ResearcherNode的step基本没有上下文依赖，每个step相对独立，所以可以异步并行执行，增加速度。CoderNode在获取了ResearcherNode的上下文后，也可以异步并行执行。\n1.2 修改策略 ​\t并行实现有两种方案：\n​\t（1）直接在ResearcherTeam中，异步动态创建nodeaction并执行，即有多少个Step就创建多少个ExecutorNode，一次即可完成整个step，并在ResearcherNode连一条自旋边，阻塞线程以等待。\n​\t（2）利用Graph库提供的并行节点，即创建一个节点，异步执行nodeaction，这样利用了已有的能力，维护性较好。\n1.3 具体实现 ​\t两种方案都需要依赖在step中进行状态控制，即三种状态：assigned、processing、completed。并且附上给节点分配的id。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Data public static class Step { @JsonProperty(\u0026#34;need_web_search\u0026#34;) private boolean needWebSearch; private String title; private String description; @JsonProperty(\u0026#34;step_type\u0026#34;) private StepType stepType; private String executionRes; private String executionStatus; } 1.3.1 方案1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 step.setExecutionStatus(assignedStatus); CompletableFuture.runAsync(() -\u0026gt; { try { if (step.getStepType() == Plan.StepType.RESEARCH) { logger.info(\u0026#34;Executing research step {}: {}\u0026#34;, stepIndex, step.getTitle()); // 为每个研究步骤创建新的Agent ChatClient researchAgent = applicationContext.getBean(\u0026#34;researchAgent\u0026#34;, ChatClient.class); ResearcherNode researcherNode = new ResearcherNode(researchAgent, executorNodeId); researcherNode.apply(state); } else { logger.info(\u0026#34;Executing processing step {}: {}\u0026#34;, stepIndex, step.getTitle()); // 为每个处理步骤创建新的Agent ChatClient coderAgent = applicationContext.getBean(\u0026#34;coderAgent\u0026#34;, ChatClient.class); CoderNode coderNode = new CoderNode(coderAgent, executorNodeId); coderNode.apply(state); } } catch (Exception e) { logger.error(\u0026#34;Error executing step {}: {}\u0026#34;, stepIndex, step.getTitle(), e); } }, executorService); 以上为核心代码，比较简单粗暴。即ResearcherTeamNode直接创建新节点，并且等待。\n1.3.2 方案2 方案2是最终采纳的方案。阅读Graph发现当前graph实现有以下限制：\n（1）子图节点不能包含有并行节点\n（2）并行节点必须是总分总的结构，并且会在汇总节点等待所有异步任务执行完毕。\n（3）并行节点总分总结构中所有边不能是conditional。\n（4）不支持并行流式处理。\n为绕开/解决限制，采取以下方案：\n对于（1），直接不使用子图节点，在大图中进行结构修改。\n对于（3），由于当前researcherTeamNode需要到reporterNode或者executorNode，故并行节点不能是researcherTeamNode，需要单独创建一个ParallelExecutorNode来给ExecutorNode分配任务。\n对于（2），采取researcherTeamNode -\u0026gt; ParallelExecutorNode -\u0026gt; ExecutorNodes -\u0026gt; researcherTeamNode的环形结构，在第二次进入researcherTeamNode的时候等待。\n对于（4），分析并修改Graph Core代码。\n1.3.2.1 ParallelExecutorNode 主要任务：分配step给后续节点。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 /* * Copyright 2025 the original author or authors. * * Licensed under the Apache License, Version 2.0 (the \u0026#34;License\u0026#34;); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * https://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \u0026#34;AS IS\u0026#34; BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.alibaba.cloud.ai.example.deepresearch.node; import com.alibaba.cloud.ai.example.deepresearch.model.ParallelEnum; import com.alibaba.cloud.ai.example.deepresearch.model.dto.Plan; import com.alibaba.cloud.ai.example.deepresearch.util.StateUtil; import com.alibaba.cloud.ai.example.deepresearch.config.DeepResearchProperties; import com.alibaba.cloud.ai.graph.OverAllState; import com.alibaba.cloud.ai.graph.action.NodeAction; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.util.CollectionUtils; import org.springframework.util.StringUtils; import java.util.Map; /** * @author sixiyida * @since 2025/6/12 */ public class ParallelExecutorNode implements NodeAction { private static final Logger logger = LoggerFactory.getLogger(ParallelExecutorNode.class); private final Map\u0026lt;String, Integer\u0026gt; parallelNodeCount; public ParallelExecutorNode(DeepResearchProperties properties) { this.parallelNodeCount = properties.getParallelNodeCount(); } @Override public Map\u0026lt;String, Object\u0026gt; apply(OverAllState state) throws Exception { long currResearcher = 0; long currCoder = 0; Plan curPlan = StateUtil.getPlan(state); for (Plan.Step step : curPlan.getSteps()) { // 跳过不需要处理的步骤 if (StringUtils.hasText(step.getExecutionRes()) || StringUtils.hasText(step.getExecutionStatus())) { continue; } Plan.StepType stepType = step.getStepType(); switch (stepType) { case PROCESSING: if (areAllResearchStepsCompleted(curPlan)) { step.setExecutionStatus(assignRole(stepType, currCoder)); currCoder = (currCoder + 1) % parallelNodeCount.get(ParallelEnum.RESEARCHER.getValue()); } logger.info(\u0026#34;Waiting for remaining research steps executed\u0026#34;); break; case RESEARCH: step.setExecutionStatus(assignRole(stepType, currResearcher)); currResearcher = (currResearcher + 1) % parallelNodeCount.get(ParallelEnum.CODER.getValue()); break; // 处理其他可能的StepType default: logger.debug(\u0026#34;Unhandled step type: {}\u0026#34;, stepType); } } return Map.of(); } private String assignRole(Plan.StepType type, long executorId) { String role = type == Plan.StepType.PROCESSING ? ParallelEnum.CODER.getValue() : ParallelEnum.RESEARCHER.getValue(); return StateUtil.EXECUTION_STATUS_ASSIGNED_PREFIX + role + \u0026#34;_\u0026#34; + executorId; } private boolean areAllResearchStepsCompleted(Plan plan) { if (CollectionUtils.isEmpty(plan.getSteps())) { return true; } return plan.getSteps() .stream() .filter(step -\u0026gt; step.getStepType() == Plan.StepType.RESEARCH) .allMatch(step -\u0026gt; step.getExecutionStatus().startsWith(StateUtil.EXECUTION_STATUS_COMPLETED_PREFIX)); } } 1.3.2.2 ResearcherNode 主要任务：执行step，流式返回，更新状态。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 /* * Copyright 2025 the original author or authors. * * Licensed under the Apache License, Version 2.0 (the \u0026#34;License\u0026#34;); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * https://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \u0026#34;AS IS\u0026#34; BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.alibaba.cloud.ai.example.deepresearch.node; import com.alibaba.cloud.ai.example.deepresearch.model.dto.Plan; import com.alibaba.cloud.ai.example.deepresearch.util.StateUtil; import com.alibaba.cloud.ai.graph.OverAllState; import com.alibaba.cloud.ai.graph.action.NodeAction; import com.alibaba.cloud.ai.graph.streaming.StreamingChatGenerator; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.ai.chat.client.ChatClient; import org.springframework.ai.chat.messages.Message; import org.springframework.ai.chat.messages.UserMessage; import org.springframework.util.StringUtils; import java.util.ArrayList; import java.util.HashMap; import java.util.List; import java.util.Map; import java.util.Objects; /** * @author sixiyida * @since 2025/6/14 11:17 */ public class ResearcherNode implements NodeAction { private static final Logger logger = LoggerFactory.getLogger(ResearcherNode.class); private final ChatClient researchAgent; private final String executorNodeId; private final String nodeName; public ResearcherNode(ChatClient researchAgent) { this(researchAgent, \u0026#34;0\u0026#34;); } public ResearcherNode(ChatClient researchAgent, String executorNodeId) { this.researchAgent = researchAgent; this.executorNodeId = executorNodeId; this.nodeName = \u0026#34;researcher_\u0026#34; + executorNodeId; } @Override public Map\u0026lt;String, Object\u0026gt; apply(OverAllState state) throws Exception { logger.info(\u0026#34;researcher node {} is running.\u0026#34;, executorNodeId); Plan currentPlan = StateUtil.getPlan(state); List\u0026lt;String\u0026gt; observations = StateUtil.getMessagesByType(state, \u0026#34;observations\u0026#34;); Map\u0026lt;String, Object\u0026gt; updated = new HashMap\u0026lt;\u0026gt;(); Plan.Step assignedStep = null; for (Plan.Step step : currentPlan.getSteps()) { if (Plan.StepType.RESEARCH.equals(step.getStepType()) \u0026amp;\u0026amp; !StringUtils.hasText(step.getExecutionRes()) \u0026amp;\u0026amp; StringUtils.hasText(step.getExecutionStatus()) \u0026amp;\u0026amp; step.getExecutionStatus().equals(StateUtil.EXECUTION_STATUS_ASSIGNED_PREFIX + nodeName)) { assignedStep = step; break; } } // 如果没有找到分配的步骤，直接返回 if (assignedStep == null) { logger.info(\u0026#34;No remaining steps to be executed by {}\u0026#34;, nodeName); return updated; } // 标记步骤为正在执行 assignedStep.setExecutionStatus(StateUtil.EXECUTION_STATUS_PROCESSING_PREFIX + nodeName); // 添加任务消息 List\u0026lt;Message\u0026gt; messages = new ArrayList\u0026lt;\u0026gt;(); Message taskMessage = new UserMessage(String.format(\u0026#34;# Current Task\\n\\n##title\\n\\n%s\\n\\n##description\\n\\n%s\u0026#34;, assignedStep.getTitle(), assignedStep.getDescription())); messages.add(taskMessage); // 添加研究者特有的引用提醒 Message citationMessage = new UserMessage( \u0026#34;IMPORTANT: DO NOT include inline citations in the text. Instead, track all sources and include a References section at the end using link reference format. Include an empty line between each citation for better readability. Use this format for each reference:\\n- [Source Title](URL)\\n\\n- [Another Source](URL)\u0026#34;); messages.add(citationMessage); logger.debug(\u0026#34;researcher Node messages: {}\u0026#34;, messages); // 调用agent var streamResult = researchAgent.prompt().messages(messages).stream().chatResponse(); Plan.Step finalAssignedStep = assignedStep; logger.info(\u0026#34;ResearcherNode {} starting streaming with key: {}\u0026#34;, executorNodeId, \u0026#34;researcher_llm_stream_\u0026#34; + executorNodeId); var generator = StreamingChatGenerator.builder() .startingNode(\u0026#34;researcher_llm_stream_\u0026#34; + executorNodeId) .startingState(state) .mapResult(response -\u0026gt; { finalAssignedStep.setExecutionStatus(StateUtil.EXECUTION_STATUS_COMPLETED_PREFIX + executorNodeId); String researchContent = response.getResult().getOutput().getText(); finalAssignedStep.setExecutionRes(Objects.requireNonNull(researchContent)); logger.info(\u0026#34;{} completed, content: {}\u0026#34;, nodeName, researchContent); observations.add(researchContent); updated.put(\u0026#34;observations\u0026#34;, observations); updated.put(\u0026#34;researcher_content_\u0026#34; + executorNodeId, List.of(researchContent)); return updated; }) .build(streamResult); updated.put(\u0026#34;researcher_content_\u0026#34; + executorNodeId, generator); return updated; } } 1.3.2.3 CoderNode 同上，跳过。\n1.4 Graph Core修改 主要问题：不支持并行流式处理。\n1.4.1 调用链路分析 我们来看看目前的流式返回是如何实现的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 var generator = StreamingChatGenerator.builder() .startingNode(\u0026#34;researcher_llm_stream_\u0026#34; + executorNodeId) .startingState(state) .mapResult(response -\u0026gt; { finalAssignedStep.setExecutionStatus(StateUtil.EXECUTION_STATUS_COMPLETED_PREFIX + executorNodeId); String researchContent = response.getResult().getOutput().getText(); finalAssignedStep.setExecutionRes(Objects.requireNonNull(researchContent)); logger.info(\u0026#34;{} completed, content: {}\u0026#34;, nodeName, researchContent); observations.add(researchContent); updated.put(\u0026#34;observations\u0026#34;, observations); updated.put(\u0026#34;researcher_content_\u0026#34; + executorNodeId, List.of(researchContent)); return updated; }) .build(streamResult); updated.put(\u0026#34;researcher_content_\u0026#34; + executorNodeId, generator); 以上代码来自researcherNode，返回一个Map后，我们来看是在哪里执行的。\n1.4.1.1 入口接口 1 2 3 4 5 6 7 8 9 10 11 @RequestMapping(value = \u0026#34;/chat/stream\u0026#34;, method = RequestMethod.POST, produces = MediaType.TEXT_EVENT_STREAM_VALUE) public Flux\u0026lt;ServerSentEvent\u0026lt;String\u0026gt;\u0026gt; chatStream(@RequestBody(required = false) ChatRequest chatRequest) throws GraphRunnerException { //... else { ChatRequestProcess.initializeObjectMap(chatRequest, objectMap); logger.info(\u0026#34;init inputs: {}\u0026#34;, objectMap); AsyncGenerator\u0026lt;NodeOutput\u0026gt; resultFuture = compiledGraph.stream(objectMap, runnableConfig); graphProcess.processStream(resultFuture, sink); } } 这是一个Controller接口，可以看到，图是从这个方法进去的compiledGraph.stream(objectMap, runnableConfig);。\n我们来看看具体实现：\n1 2 3 4 5 public AsyncGenerator\u0026lt;NodeOutput\u0026gt; stream(Map\u0026lt;String, Object\u0026gt; inputs, RunnableConfig config) throws GraphRunnerException { Objects.requireNonNull(config, \u0026#34;config cannot be null\u0026#34;); final AsyncNodeGenerator\u0026lt;NodeOutput\u0026gt; generator = new AsyncNodeGenerator\u0026lt;\u0026gt;(stateCreate(inputs), config); return new AsyncGenerator.WithEmbed\u0026lt;\u0026gt;(generator); } 这个地方返回了一个AsyncGenerator.WithEmbed，这玩意是什么呢？\n简而言之，这个东西是一个允许其他的AsyncGenerator在其执行过程中执行的包装类。\n执行流程是：\n从堆栈顶部获取当前生成器\n调用当前生成器的next()方法获取结果\n如果结果表示生成器已完成：\n清除之前的返回值（如果有）\n将结果推入返回值堆栈\n执行完成回调（如果有）\n如果这是最后一个生成器，返回结果\n否则，弹出当前生成器，递归调用next()继续处理下一个生成器\n如果结果包含一个嵌入生成器： 检查嵌套深度（目前不支持递归嵌套）\n将嵌入生成器推入堆栈\n递归调用next()处理嵌入生成器\n否则，直接返回结果 看看具体实现：\n1 2 protected final Deque\u0026lt;Embed\u0026lt;E\u0026gt;\u0026gt; generatorsStack = new ArrayDeque\u0026lt;\u0026gt;(2); private final Deque\u0026lt;Data\u0026lt;E\u0026gt;\u0026gt; returnValueStack = new ArrayDeque\u0026lt;\u0026gt;(2); 首先核心数据结构是利用这两个双端队列维护返回值和生成器栈。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @Override public Data\u0026lt;E\u0026gt; next() { if (generatorsStack.isEmpty()) { // GUARD throw new IllegalStateException(\u0026#34;no generator found!\u0026#34;); } final Embed\u0026lt;E\u0026gt; embed = generatorsStack.peek(); final Data\u0026lt;E\u0026gt; result = embed.generator.next(); if (result.isDone()) { clearPreviousReturnsValuesIfAny(); returnValueStack.push(result); if (embed.onCompletion != null) { try { embed.onCompletion.accept(result.resultValue); } catch (Exception e) { return Data.error(e); } } if (isLastGenerator()) { return result; } generatorsStack.pop(); return next(); } if (result.embed != null) { if (generatorsStack.size() \u0026gt;= 2) { return Data.error(new UnsupportedOperationException( \u0026#34;Currently recursive nested generators are not supported!\u0026#34;)); } generatorsStack.push(result.embed); return next(); } return result; } 这个方法是核心方法，递归地处理了嵌入的生成器。\n1.4.1.2 状态流转 然后我们来看看AsyncNodeGenerator的实现：\n核心方法是next，其实现了状态图流转。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 @Override public Data\u0026lt;o\u0026gt; next() { try { // 检查最大迭代次数 if (++iteration \u0026gt; maxIterations) { return Data.error(new IllegalStateException( format(\u0026#34;Maximum number of iterations (%d) reached!\u0026#34;, maxIterations))); } // 检查是否已结束 if (nextNodeId == null \u0026amp;\u0026amp; currentNodeId == null) { return releaseThread().map(Data::\u0026lt;o\u0026gt;done).orElseGet(() -\u0026gt; Data.done(currentState)); } // 是否从嵌入恢复 if (resumedFromEmbed) { final CompletableFuture\u0026lt;o\u0026gt; future = getNodeOutput(); resumedFromEmbed = false; return Data.of(future); } // 处理START节点 if (START.equals(currentNodeId)) { doListeners(START, null); var nextNodeCommand = getEntryPoint(currentState, config); nextNodeId = nextNodeCommand.gotoNode(); currentState = nextNodeCommand.update(); var cp = addCheckpoint(config, START, currentState, nextNodeId); var output = (cp.isPresent() \u0026amp;\u0026amp; config.streamMode() == StreamMode.SNAPSHOTS) ? buildStateSnapshot(cp.get()) : buildNodeOutput(currentNodeId); currentNodeId = nextNodeId; return Data.of(output); } // 处理END节点 if (END.equals(nextNodeId)) { nextNodeId = null; currentNodeId = null; doListeners(END, null); return Data.of(buildNodeOutput(END)); } // 检查中断条件 if (shouldInterruptAfter(currentNodeId, nextNodeId)) { return Data.done(currentNodeId); } if (shouldInterruptBefore(nextNodeId, currentNodeId)) { return Data.done(currentNodeId); } // 更新当前节点ID currentNodeId = nextNodeId; // 获取当前节点对应的动作 var action = nodes.get(currentNodeId); if (action == null) throw RunnableErrors.missingNode.exception(currentNodeId); // 执行节点动作 return evaluateAction(action, this.overAllState).get(); } catch (Exception e) { doListeners(ERROR, e); log.error(e.getMessage(), e); return Data.error(e); } } 其中evaluateAction执行了nodeAction，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 private Command nextNodeId(String nodeId, OverAllState overAllState, Map\u0026lt;String, Object\u0026gt; state, RunnableConfig config) throws Exception { EdgeValue route = edges.get(nodeId); if (route == null) { throw RunnableErrors.missingEdge.exception(nodeId); } // 如果边有固定的目标ID if (route.id() != null) { return new Command(route.id(), state); } // 如果边有条件逻辑 if (route.value() != null) { // 执行边的条件动作 var command = route.value().action().apply(overAllState, config).get(); var newRoute = command.gotoNode(); // 根据条件结果查找映射的目标节点 String result = route.value().mappings().get(newRoute); if (result == null) { throw RunnableErrors.missingNodeInEdgeMapping.exception(nodeId, newRoute); } // 更新状态 var currentState = OverAllState.updateState(state, command.update(), keyStrategyMap); overAllState.updateState(command.update()); return new Command(result, currentState); } throw RunnableErrors.executionError.exception(format(\u0026#34;invalid edge value for nodeId: [%s] !\u0026#34;, nodeId)); } 下一个节点由nextNodeId方法决定：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 private Command nextNodeId(String nodeId, OverAllState overAllState, Map\u0026lt;String, Object\u0026gt; state, RunnableConfig config) throws Exception { EdgeValue route = edges.get(nodeId); if (route == null) { throw RunnableErrors.missingEdge.exception(nodeId); } // 如果边有固定的目标ID if (route.id() != null) { return new Command(route.id(), state); } // 如果边有条件逻辑 if (route.value() != null) { // 执行边的条件动作 var command = route.value().action().apply(overAllState, config).get(); var newRoute = command.gotoNode(); // 根据条件结果查找映射的目标节点 String result = route.value().mappings().get(newRoute); if (result == null) { throw RunnableErrors.missingNodeInEdgeMapping.exception(nodeId, newRoute); } // 更新状态 var currentState = OverAllState.updateState(state, command.update(), keyStrategyMap); overAllState.updateState(command.update()); return new Command(result, currentState); } throw RunnableErrors.executionError.exception(format(\u0026#34;invalid edge value for nodeId: [%s] !\u0026#34;, nodeId)); } ","date":"2025-06-06T00:00:00Z","permalink":"https://sixiyida.github.io/p/spring-ai-alibaba%E7%BB%B4%E6%8A%A4%E8%AE%B0%E5%BD%95/","title":"spring-ai-alibaba维护记录"},{"content":"分库分表和分页 1. 分表（Table Sharding） 定义：将单张数据表按特定规则（如哈希、范围）拆分为多个结构相同的小表，存储在同一数据库或不同数据库中\n目的：解决单表数据量过大导致的查询性能下降（如索引膨胀、磁盘I/O瓶颈）\n适用场景：单表数据超千万级，但数据库实例资源未达瓶颈\n2. 分库（Database Sharding） 定义：将整个数据库按业务或数据维度拆分为多个独立的数据库实例，每个实例存储部分数据\n目的：解决单库连接数不足、磁盘空间不足、写并发压力大等问题\n适用场景：单库QPS过高、连接数耗尽或需故障隔离\n3. 分片（Sharding） 定义：分库+分表的组合策略，将数据按规则（如哈希、范围）分布到多个数据库节点（分片），每个节点包含部分库和表。\n目的：实现真正的水平扩展，支持海量数据与高并发\n适用场景：超大规模数据（TB/PB级）、需全局负载均衡\n核心区别总结 维度 分表 分库 分片 拆分对象 单张表 整个数据库实例 库+表组合的分布式节点 主要目标 解决单表性能瓶颈 解决单库资源瓶颈 全局水平扩展与高可用 数据分布 表内数据拆分 库间数据隔离 跨节点数据分片 典型场景 大表查询优化 高并发写入/连接数不足 超大规模系统（如社交平台） ","date":"2025-06-02T00:00:00Z","permalink":"https://sixiyida.github.io/p/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/","title":"系统设计"},{"content":"0. 前言 花了5天时间是跟着做完了黑马点评项目。虽说是烂大街项目之一，但我还是学到了不少东西。这个项目让我第一次看到了后端的全貌。这篇文章会记录我优化这个项目的过程，涉及中间件、功能拓展、LLM的引入等。\n1. 引入消息队列中间件 在项目的秒杀业务中，优惠券下单和数据持久化至数据库利用Redis Stream实现的消息队列解耦，优势主要在：\n简化下单流程，提高系统响应速度。 提高并发量和鲁棒性，防止数据库击穿。 1.1 为什么引入消息队列中间件？ 持久化：Redis Stream依赖AOF/RDB持久化，主从切换时异步复制可能导致数据丢失；消息队列中间件，如RocketMQ，同步刷盘+多副本（RAFT协议），提供金融级可靠性。\n消息积压：\n能力 Redis Stream 专业消息队列 存储介质 内存（成本高） 磁盘（成本低） 积压容忍度 需设置MAXLEN截断旧消息 支持TB级堆积（如Kafka） 内存风险 可能触发OOM（需手动扩内存） 磁盘空间自动扩容无压力 运维与生态：专业消息队列工具链更完善。\n高级功能：消息队列中间件引入了延迟队列、死信路由等企业级特性。\n1.2 引入哪一种？ 三种中间件对比：\n能力维度 RabbitMQ Kafka RocketMQ 吞吐量 万级 TPS 百万级 TPS 十万级 TPS 延迟 微秒级 毫秒级（批处理设计） 毫秒级 事务支持 轻量级事务（同步阻塞） 支持（≥0.11 版本） 分布式事务消息 顺序性保障 单队列有序 分区内有序 队列/分区严格有序 可靠性机制 镜像队列+持久化 多副本+ISR 同步刷盘+多副本+RAFT 协议 秒杀核心优势 削峰填谷、异步解耦 超高吞吐、日志流处理 高并发+强一致性+低延迟 结论：选择RocketMQ，秒杀场景在需要高吞吐量的同时，需要强一致性和可靠性。同时RocketMQ支撑阿里多次双十一活动，非常无敌，必须喽他。\n1.3 引入RocketMQ 1.3.1 部署RocketMQ 由于本人太穷，服务器只有2核2G，但又不想妥协用轻量级的MQ，为验证项目逻辑，在本地Windows环境部署RocketMQ。\n下载跳过。\n配置环境变量：\n1 2 %ROCKETMQ_HOME% = ...\\rocketmq-all-5.3.3-bin-release %NAMESRV_ADDR% = localhost:9876 启动NameServer和Broker：\n1 2 3 cd %ROCKETMQ_HOME% bin/mqnamesrv bin/mqbroker -n localhost:9876 测试生产消费：\n1 2 bin/tools org.apache.rocketmq.example.quickstart.Producer bin/tools org.apache.rocketmq.example.quickstart.Consumer 1.3.2 引入Java客户端依赖 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.rocketmq\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;rocketmq-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 1.3.3 修改applications.yml 1 2 3 4 5 rocketmq: name-server: http://localhost:9876 producer: group: ${spring.application.name} send-message-timeout: 3000 1.4 架构更新 目前架构：\n主线程：Lua(Redis校验下单资格 -\u0026gt; 创建订单至Redis) -\u0026gt; 向异步线程阻塞队列提交订单\n子线程：异步线程获取分布式锁 -\u0026gt; 持久化至数据库(Transactional) -\u0026gt; 解锁\n其中分布式锁的设计是原本在多台Tomcat下，会导致重复下单问题。但现在Redis由于是串行化的，无论多少台Tomcat都不会出现并发问题，且MQ也将创建订单的消息串行化了，故分布式锁可以取消。\n更新后架构：\n主线程：Lua(Redis校验下单资格 -\u0026gt; 创建订单至Redis) -\u0026gt; 向MQ生产订单消息\n子线程：消费MQ消息 -\u0026gt; 持久化至数据库(Transactional)\n需要注意的是，在秒杀场景下，用户不应该为DB的错误买单，而且分布式事务违背了异步下单提高性能的初衷。故如果DB更新失败，不应该回滚Redis，而是应该重试DB更新操作。\n1.5 RocketMQ分布式事务逻辑 1.6 代码实现 1.6.1 MQ配置类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @Configuration public class RocketMQConfig { @Value(\u0026#34;${rocketmq.name-server}\u0026#34;) private String nameServer; // 事务消息生产者 @Bean(initMethod = \u0026#34;start\u0026#34;, destroyMethod = \u0026#34;shutdown\u0026#34;) public TransactionMQProducer transactionProducer() { TransactionMQProducer producer = new TransactionMQProducer(\u0026#34;voucher_order_group\u0026#34;); producer.setNamesrvAddr(nameServer); producer.setTransactionListener(transactionListener()); // 绑定事务监听器 return producer; } // 事务监听器实现 @Bean public TransactionListener transactionListener() { return new VoucherOrderTransactionListener(); } } 简单，跳过。\n1.6.2 订单事务监听器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @Component public class VoucherOrderTransactionListener implements TransactionListener { @Lazy @Resource private VoucherOrderServiceImpl voucherOrderService; // 执行本地事务（订单创建） @Override public LocalTransactionState executeLocalTransaction(Message msg, Object arg) { try { VoucherOrder order = JSON.parseObject(msg.getBody(), VoucherOrder.class); voucherOrderService.createVoucherOrder(order); // 调用订单创建方法 return LocalTransactionState.COMMIT_MESSAGE; } catch (Exception e) { voucherOrderService.rollbackRedis(order.getVoucherId(), order.getUserId()); // 非数据库操作导致的回滚 return LocalTransactionState.ROLLBACK_MESSAGE; } } // 事务回查（防止本地事务未提交） @Override public LocalTransactionState checkLocalTransaction(MessageExt msg) { String orderId = msg.getKeys(); VoucherOrder order = voucherOrderService.getById(orderId); return order != null ? LocalTransactionState.COMMIT_MESSAGE : LocalTransactionState.ROLLBACK_MESSAGE; } } 这里几个关键点：\n@Lazy：由于Service中注入了transactionProducer，而其依赖配置类中创建的TransactionListener，故产生循环依赖，需要使用懒加载打破循环依赖。\n回滚：如注释。\n1.6.3 修改秒杀下单逻辑 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 @Resource private TransactionMQProducer transactionProducer; @Override public Result seckillVoucher(Long voucherId) { Long userId = UserHolder.getUser().getId(); Long result = stringRedisTemplate.execute( SECKILL_SCRIPT, Collections.emptyList(), voucherId.toString(), userId.toString() ); int r = result.intValue(); if (r != 0) { return Result.fail(r == 1 ? \u0026#34;库存不足\u0026#34; : \u0026#34;不能重复下单\u0026#34;); } // 保存order VoucherOrder order = new VoucherOrder(); order.setId(redisIdWorker.nextId(\u0026#34;order\u0026#34;)); order.setUserId(UserHolder.getUser().getId()); order.setVoucherId(voucherId); // 构造消息 Message msg = new Message(\u0026#34;voucher_order_topic\u0026#34;, JSON.toJSONBytes(order)); msg.setKeys(order.getId().toString()); try { transactionProducer.sendMessageInTransaction(msg, null); } catch (MQClientException e) { log.error(\u0026#34;MQ错误\u0026#34;); } return Result.ok(order.getId()); } @Transactional public void createVoucherOrder(VoucherOrder voucherOrder) { Long userId = voucherOrder.getUserId(); Long voucherId = voucherOrder.getVoucherId(); boolean success = seckillVoucherService.update() .setSql(\u0026#34;stock = stock - 1\u0026#34;) .eq(\u0026#34;voucher_id\u0026#34;, voucherId) .gt(\u0026#34;stock\u0026#34;, 0) // CAS乐观锁 .update(); if (!success) { // 数据库操作失败 // 1. 删除购买记录 String key = RedisConstants.SECKILL_ORDER_KEY + voucherId; stringRedisTemplate.opsForSet().remove(key, userId.toString()); // 2. 恢复预扣库存 stringRedisTemplate.opsForValue() .increment(RedisConstants.SECKILL_STOCK_KEY + voucherId, 1); throw new RuntimeException(\u0026#34;数据库扣减失败\u0026#34;); } save(voucherOrder); } //幂等Redis回滚 public void rollbackRedis(Long voucherId, Long userId) { String luaScript = \u0026#34;local orderKey = KEYS[1] \u0026#34; + \u0026#34;local stockKey = KEYS[2] \u0026#34; + \u0026#34;local userId = ARGV[1] \u0026#34; + // 只回滚存在的订单记录 \u0026#34;if redis.call(\u0026#39;sismember\u0026#39;, orderKey, userId) == 1 then \u0026#34; + \u0026#34; redis.call(\u0026#39;srem\u0026#39;, orderKey, userId) \u0026#34; + \u0026#34; redis.call(\u0026#39;incr\u0026#39;, stockKey) \u0026#34; + // 库存+1 \u0026#34; return 1 \u0026#34; + \u0026#34;else \u0026#34; + \u0026#34; return 0 \u0026#34; + // 已处理或无记录 \u0026#34;end\u0026#34;; String orderKey = RedisConstants.SECKILL_ORDER_KEY + voucherId; String stockKey = RedisConstants.SECKILL_STOCK_KEY + voucherId; // 执行Lua脚本 Long result = stringRedisTemplate.execute( new DefaultRedisScript\u0026lt;\u0026gt;(luaScript, Long.class), Arrays.asList(orderKey, stockKey), userId.toString() ); log.debug(\u0026#34;回滚结果: {}\u0026#34;, result); } ","date":"2025-06-01T00:00:00Z","permalink":"https://sixiyida.github.io/p/%E7%82%B9%E8%AF%84%E9%A1%B9%E7%9B%AE%E4%BC%98%E5%8C%96/","title":"点评项目优化"},{"content":"@Configuration和@Component @Configuration自身也是一个Bean，默认启用 CGLIB 代理（proxyBeanMethods=true）。当配置类中的 @Bean 方法相互调用时，Spring 会拦截调用并返回容器中的单例 Bean，而非重新创建，可直接注入方法参数的Bean。\n1 2 3 4 5 6 7 @Configuration public class Config { @Bean public A a() { return new A(); } @Bean public B b() { return new B(a()); } // 注入容器中的单例A } @Component无代理机制。方法间调用视为普通 Java 方法，每次调用 @Bean 方法都会创建新实例，破坏单例， 依赖注入需要显式@Autowired：\n1 2 3 4 5 6 7 @Component public class ComponentConfig { @Bean public A a() { return new A(); } @Bean public B b() { return new B(a()); } // 每次调用a()创建新实例！ } @PathVariable 1 2 3 4 @GetMapping(\u0026#34;/{id}\u0026#34;) public Result queryBlogById(@PathVariable(\u0026#34;id\u0026#34;) Long id) { } 将url的值绑定至方法参数中。\n","date":"2025-05-30T00:00:00Z","permalink":"https://sixiyida.github.io/p/spring%E7%9B%B8%E5%85%B3/","title":"Spring相关"},{"content":"为什么需要消息队列？ 在异步任务，如生产者-消费者模型中，两者的运行速度并不相同，使用消息队列可以做一个缓冲，减小系统压力。\nRedis消息队列 1. 基于List Redis的list数据结构是一个双向链表，利用LPUSH和RPOP实现，若需要阻塞，使用BRPOP实现阻塞队列效果\n缺陷：每次取出消息直接从队列中移除，造成\n无法避免消息丢失：移除后如果宕机，则消息丢失。 无法有多消费者：只能消费一次并移除，无法多次消费。 2. 基于Pub/Sub 类似ROS：\n1 2 3 SUBSCRIBE channel [channel] PUBLISH channel msg PSUBSCRIBE pattern [pattern] // 订阅匹配pattern的所有频道 缺陷：每次取出消息直接从队列中移除，造成\n不支持数据持久化：数据不在Redis（内存）中保存。 无法避免消息丢失：如上。 消息堆积有上限，超出时丢失：只在消费者处缓存，有上限。 3. 基于Stream Stream是一种为消息队列设计的数据类型。\n基本添加/读取消息 1 XADD users * name jack age 21 // 向user发{name = jack, age = 21} 1 XREAD COUNT 1 BLOCK 2000 STREAMS users $ // 读users最新的1个消息，无消息阻塞2秒 消费者组 特点：\n消息分流：队列中消息分流而不是重复消费，加快速度。 消息表示：记录最后一个被处理的消息，宕机后也能恢复。 消息确认：消息被获取后存入pending-list，必须要消费者使用XACK确认消息，才会移除。 1 2 3 4 5 6 7 8 9 10 11 XGROUP CREATE mqName groupName ID [MKSTREAM] // ID(0):第一个消息/ID($):最后一个消息 // 为mqName创建名为groupName的消费者组 XGROUP DESTROY mqName groupName XGROUP CREATECONSUMER mqName groupName consumerName XGROUP DELCONSUMER mqName groupName consumerName XREADGROUP GROUP group consumer [COUNT count] [BLOCK milliseconds] [NOACK] STREAMS mqName [mqName ...] ID [ID ...] //ID为获取消息起始id //\u0026#34;\u0026gt;\u0026#34; : 从未消费消息开始 //“数字”: 从pending-list中第一个消息开始 RocketMQ NameServer-Broker NameServer 是 轻量级的服务注册与发现中心，类似于分布式系统中的“电话簿”或“目录服务”。\nBroker 是消息队列中实际存储、转发消息的核心角色。它是生产者和消费者直接打交道的节点，真正处理消息的存储、查询、投递等操作。\n","date":"2025-05-28T00:00:00Z","permalink":"https://sixiyida.github.io/p/message-queue/","title":"Message Queue"},{"content":"锁 行级锁 **行级锁：**在select for update等场景，即当前读（另一种是快照读MVCC）场景使用。\n包括Record Lock, Gap Lock 和 Next-key Lock(前两种的合并)\n包括X(Exclusive)和S(share)两种\nGap Lock是只锁相邻两条记录之间的()，NK-lock是锁(]\nGap Lock的X和S型是一样的，都可以重复获取，NK-lock要看右区间的记录锁是否互斥，无限除外。\n怎么加？（MySQL8.0.26, 可重复读） 对索引加，基本单位是nk-lock，不同情况可能出现退化为前两种\n主键索引等值查询：\n记录存在-\u0026gt;退化为记录\n记录不存在-\u0026gt;退化为间隙锁\n1 select * from performance_schema.data_locks //查加了什么锁 如果MODE是GAP， LOCK_DATA是右区间界。\n主键索引范围查询：\n大于：不退化\n大于等于：如果等于存在，则左边退化为记录锁，不存在则不退化\n小于：最右侧退化为间隙锁\n小于等于：若等于存在，则不退化，不存在则最右侧退化为间隙锁\n**注：**记录锁属于记录，在GAP锁中是属于LOCK_DATA，右区间界的记录。\n二级索引（非唯一）等值查询：\n记录不存在：二级索引上GAPLOCK，对于左右端点，能否插入要看二级索引B+树下一条记录有无GAPLOCK\n记录不存在的特殊情况：如果是超过了最大id，是next-keyLock\n注：二级索引GAPLOCK的LOCK_DATA包含两个值，二级索引和回表的主键索引\n记录存在：对二级索引匹配的记录加nk锁，对不匹配的第一个nk锁退化为间隙锁，且在主键索引加记录锁。\n对于端点是否能插入，和要看二级索引B+树下一条记录有无LOCK\n在不匹配的第一个索引加nk锁的目的：防止幻读（id \u0026gt; lock_id）的情况\n二级索引（非唯一）范围查询：不退化，二级的nk和主键的记录锁都加\n如果不走索引全表扫描，则所有记录全部加nk锁，全锁，是事故\n解决方案：将sql_safe_updates设置为1，此时必须使用where+索引 / limit\n当前读的语句：update、delete、select for update，会加意向锁和行锁\n死锁的形成 例子：如果两个事务都获取了间隔锁，且希望插入对方间隔，则尝试获取插入意向锁（和间隔锁互斥），环路等待导致死锁。\ninsert语句加行级锁 **记录之间有间隙锁：**加插入意向锁\n注：mysql的锁是先生成锁结构，锁此时是等待状态，再获取锁，如果不能获取则阻塞。\n**唯一键（主键或唯一二级索引）冲突：**失败后加S型锁\n主键：加S记录锁\n唯一二级索引：加S型NK锁\n例子：在select for update中，尝试加X型锁，和S型冲突，所以失败。\n并发insert导致的唯一键冲突\n第一个insert但事务没提交时，构造隐式锁。\n第二个insert时，隐式锁变成X型锁，和第二个insert想要获取的S型nk锁冲突\n避免死锁的方法 设置事务等待回滚时间：超时回滚\n1 innodb_lock_wait_timeout = 50 // default 开启主动死锁检测：主动回滚\n1 innodb_deadlock_detect = on 日志 保证ACID特性：Atomic, Consisitency, isolation, duration\nundo log 注：对于增删改语句，innodb会隐式启动事务。\n特殊处理：delete只在记录上打标记，真正删除由purge线程完成\nupdate非主键列：直接update，且在undolog中记录update之前的值\nupdate主键列：先删再插\nundolog的存储形式：由roll_pointer指针形成链表穿起来\nbufferpool 指的是innodb引擎中的内存bufferpool。\n类似于pagecache，由后台线程实现脏页写回机制。\n内存结构：首先申请连续的内存空间，接着按照16kb大小划分出缓存页。\n包括数据页、索引页、undo页、插入缓存页、自适应哈希索引、锁信息等。\nredolog **redolog的作用：**对修改实现持久化。\nWAL技术(write-ahead logging)：在写入磁盘之前先写入redolog。\n每对Bufferpool进行修改就写入redolog，包括undolog的修改\nredolog和undolog对比：\nredolog是记录修改后，保证持久化\nundolog是记录修改前，保证原子化\n写入数据和写入redolog对比：\nredolog：是顺序写入，高效\n数据：是随机写入，低效\nredolog也有buffer，落盘时机：\nmysql正常关闭，buffer空间超过一半，每一秒写回一次。\ninnodb_flush_log_at_trx_commit参数：提交事务时的行为\n0：不写回，后台线程每隔一秒用write()和fsync()\n1：直接持久化到磁盘\n2：写入文件（pagecache）由操作系统写回，后台线程每隔一秒用fsync()\nredolog存储方式：两个redolog文件循环存储类似于环形队列。\n有个tail和head，在tail处写，持久化bufferpool进入数据后更新head。\nbinlog Server层的日志， 用于备份恢复、主从复制。三种格式类型：\nSTATEMENT：记录SQL语句逻辑操作\nROW：记录行数据最终修改情况\nMIXED：根据情况使用STATEMENT或者ROW\n使用追加写，写满文件就创建新文件继续写，全量日志。\n主从复制 主库server层直接写入binlog，后台log dump线程异步将binlog日志发给从库，从库relaylog记录binlog，后台线程异步执行relaylog。\n**从库的数量选择：**对主库的资源消耗、网络带宽。\n其他模型：\n同步模型：要所有从库relaylog记录完毕后返回成功，主库再返回客户端。没法用\n异步模型：默认模型，主库宕机就gg\n半同步：一部分库返回成功即可。\nbinlog也有cache，每个线程各一个。\n持久化的时机：\nbinlog_cache_size：超过这个大小就写入\nsync_binlog：\n0：只write，操作系统控制写回\n1：write+fsync\nn：write，累积n个以后fsync\n注：binlog在语句执行完成后在记录。事务提交时候才持久化。\n两阶段提交 问题：如果redolog和binlog一个完成一个不完成，则会出现主从不一致的问题。\n内部XA事务：在事务提交后开启，由binlog协调。\n将redolog写入拆为prepare和commit，中间插入binlog持久化。\nprepare：将内部XID写入redolog并持久化，将状态设置为prepare。\ncommit：将内部XID写入binlog并持久化，接着将redolog设置为commit。\n崩溃时，redolog处于prepare状态，检查binlog中有无XA事务的id，有则提交事务，无则回滚。\n**问题：**性能差\n磁盘IO次数高\n在多事务下，不能保证两者提交顺序一致，需要加锁以保证提交的原子性\n上述问题：binlog组提交机制\n分为flush(write)、sync(fsync)、commit阶段，每个阶段都有队列，用锁保证事务写入顺序。\nredolog的组提交机制\n将redolog刷盘延迟到flush阶段中\nBufferPool default = 128MB\neach page 16kb\n结构：控制块1到n，接着page1到n\n注：查询时候直接将innodb的整个页加载至bufferpool中，然后在bufferpool中通过页目录定位记录\nFREE链表：管理空闲页，节点是控制块，头结点包括链表头尾地址和控制块数量。\nFLUSH链表：管理空闲页，节点是控制块，头结点包括链表头尾地址和控制块数量。\n如何管理bufferpool：\n传统LRU问题：\n**预读失效：**预读时会把相邻的数据页一并加载，为了减少磁盘IO，如果这些没有被访问，且淘汰末尾页，则降低缓存命中率。\n**解决方法：**划分LRU的优先级，前面是YOUNG，后面是OLD，预读先加入OLD，真正访问才加入YOUNG区域。\n**缓存污染：**当扫描大量数据，会淘汰大量热数据，导致命中率下降。\n**解决方法：**提高加入YOUNG的门槛，记录第一次OLD被访问的时间，如果后续访问时间超过第一次1s，则放入young区域。\n**Linux的做法：**第二次的时候将才升级到active，比MYSQL简单。\n","date":"2025-05-28T00:00:00Z","permalink":"https://sixiyida.github.io/p/mysql/","title":"MySQL"},{"content":"为什么需要分布式锁？ 在单JVM环境中，对于一人一单的场景，可以使用互斥锁实现。但是在负载均衡的集群场景中，需要全局锁，即分布式锁。\n常见的分布式锁实现方式：MySQL、Redis、Zookeeper。\nMySQL分布式锁实现方式：\n1.利用唯一索引，插入唯一键值成功则获取锁，释放锁则直接删除该记录。\n2.利用MySQL排他锁（SELECT FOR UPDATE），提交事务时释放锁。\nRedis分布式锁 加锁 1 SET lock thread1 NX EX 10 1 Boolean success = stringRedisTemplate.opsForValue().setIfAbsent(KEY_PREFIX + name, threadId + \u0026#34;\u0026#34;, timeoutSec, TimeUnit.SECONDS); 解锁 1 DEL lock 1 stringRedisTemplate.delete(KEY_PREFIX + name); 误删问题 由于可能出现线程阻塞超时自动释放，且锁在当前线程恢复之前被其他线程获取，该线程恢复之后如果直接释放锁，会释放其他线程获取的分布式锁，出现混乱。\n解决方法：\n判断锁所有权，再删除。问题：当判断所有权之后如果线程阻塞，同样会出现上述问题。 将1中操作变成原子的，使用Redis提供的Lua脚本。 1 2 3 4 if (redis.call(\u0026#39;get\u0026#39;, KEYS[1]) == ARGV[1]) then return redis.call(\u0026#39;del\u0026#39;, KEYS[1]) end return 0 1 2 3 4 5 stringRedisTemplate.execute( UNLOCK_SCRIPT, Collections.singletonList(KEY_PREFIX + name), threadId ); 基于setnx实现的分布式锁的问题 不可重入：同线程无法多次获取同一把锁，可能会导致同线程不同方法相互依赖导致死锁。 不可重试：获取锁失败没有重试机制 超时释放：执行时间长可能导致锁意外自动超时释放。 主从一致性：加锁后主节点宕机，从节点未同步，导致重复获取锁。 Redisson 基于Redis实现的分布式工具。\nStep0：Maven添加依赖\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.redisson\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;redisson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.22.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; **Step1：**注入RedissonClient\n1 2 3 4 5 6 7 8 9 10 11 @Configuration public class RedissonConfig { @Bean public RedissonClient redissonClient(){ Config config = new Config(); config.useSingleServer().setAddress(\u0026#34;redis://localhost:6379\u0026#34;).setPassword(\u0026#34;password\u0026#34;); return Redisson.create(config); } } **Step2：**使用工具\n1 RLock lock = redissonClient.getLock(RedisConstants.ORDER_LOCK_KEY + userId); Redisson分布式锁原理 基于Lua脚本的可重入 利用hash结构，记录线程id和引用次数。\n加锁：判断是否为当前线程id，如果是，则引用计数+1，重置锁有效期。\n解锁：判断是否为当前线程id，如果不是，不用处理；如果是，则引用计数-1并重置锁有效期。最后判断如果引用计数为0，则释放锁。\n可重试 在解锁时使用信号量/Pub，通知解锁。\n加锁失败后若有剩余等待时间，收到解锁信号后，异步重试。\n锁续期 加锁成功后启动后台线程Watchdog，每10秒检查锁是否被持有，若持有则续期为30秒。\nMultiLock 1 Rlock lock = redissonClient.getMulitLock(lock1, lock2, ...); 原理：\n获取锁：遍历获取 + 失败回滚\n建立锁List，遍历获取锁，遍历时分配每个锁的等待时间。\n若出现获取失败，则释放所有已经获取的锁，并返回失败。\n如果所有锁获取成功则返回成功。\n解锁：遍历释放 + 异常容忍\n遍历所有锁并逐一释放（无论是否属于当前线程）。\n即使某个锁释放失败（如锁已超时），仍继续释放其他锁，最大限度避免死锁。\n","date":"2025-05-28T00:00:00Z","permalink":"https://sixiyida.github.io/p/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","title":"Redis分布式锁"},{"content":"静态代码块初始化 1 2 3 4 5 static { UNLOCK_SCRIPT = new DefaultRedisScript\u0026lt;\u0026gt;(); UNLOCK_SCRIPT.setLocation(new ClassPathResource(\u0026#34;unlock.lua\u0026#34;)); UNLOCK_SCRIPT.setResultType(Long.class); } 在类首次加载时执行一次，如通过new创建对象、访问静态成员或反射加载类时触发\n多个静态代码块按定义顺序依次执行\n可以进行复杂逻辑初始化\n非静态成员变量初始化 在对象创建时完成，顺序为声明赋值 → 初始化块 → 构造函数，每种与代码书写顺序一致。\nSpringBoot中的classpath 一句话总结：classpath 等价于 main/java + main/resources + 第三方jar包的根目录。\n1 UNLOCK_SCRIPT.setLocation(new ClassPathResource(\u0026#34;unlock.lua\u0026#34;)); ClassPathResource对应main/resources目录下文件。\nAOP的内部调用问题 在使用AOP的场景中，如@Transactional，如果使用this指针调用内部方法，会绕过代理导致AOP失效。\n解决方法：\n使用AopContext.currentProxy()直接获取当前代理对象，原理是通过 ThreadLocal 存储当前线程的代理对象。 缺陷：在多线程场景下，如果子线程调用父线程的事务函数，由于ThreadLocal不互通，导致无法获取代理对象，事务失效。\n缺陷的解决方法：直接在主线程中将获取的代理对象传给子线程任务。\n直接使用@Autowired将自身注入。 **缺陷：**循环依赖风险，三级缓存性能低。\nRESTful API：PUT 更新或创建指定位置的资源。客户端需提供完整的资源数据，服务器会完全替换目标 URI 对应的资源。若资源不存在，则新建资源。\n与POST对比：\n特性 PUT POST 幂等性 ✅ 是（多次请求结果一致） ❌ 否（可能产生多个资源） URI 含义 资源唯一标识（如 /users/123） 资源集合（如 /users） 数据完整性 必须提供完整资源 可提交部分数据 典型响应码 200 OK（更新）或 201 Created（新建） 201 Created（新建资源） @Resource和@Autowired对比 @Resource流程\n指定name → 按名称查找 → 失败抛异常\n未指定name → 先按字段名匹配 → 失败则按类型匹配\n指定type → 按类型唯一匹配 → 多匹配抛异常\n@Autowired 流程\n按类型查找 → 找到唯一 Bean → 注入成功\n找到多个同类型 Bean → 需结合 @Qualifier(\u0026quot;beanName\u0026quot;) 指定名称\n无匹配且→ 注入required=false → 注入 null\no instanceof Node node的用法（Java 16+） 等于以下代码：\n1 2 3 if (o instanceof Node) { Node node = (Node) o; } record（Java 16+） 1 public record Person(String name, int age) {} 自动生成内容：\n全参构造器（如Person(String name, int age)） 字段访问器（如name()、age()，而非传统getName()） equals()、hashCode()、toString()方法 所有字段默认为final，实例化后不可修改\nthis() 调用其他构造函数 1 2 3 4 5 6 public record Edge(String sourceId, List\u0026lt;EdgeValue\u0026gt; targets) { // 构造函数 public Edge(String sourceId, EdgeValue target) { this(sourceId, List.of(target)); } } PECS原则 Producer Extends, Consumer Super.\n1 private static List\u0026lt;? extend K\u0026gt; produce() 原因：PE可以保证获取的至少是一个K，这样获取出来的可以直接用K来接，是类型安全的。\n1 private static consume(List\u0026lt;? super U\u0026gt;, U) 原因：CS可以保证接收消费对象的容器装的是其父类对象，可以保证传入的对象可以被向上转型，是类型安全的。\n自定义Collector Collector接口定义了5个核心方法，需全部实现：\nsupplier() 创建结果容器（如ArrayList::new），用于存储中间结果\naccumulator() 定义如何将元素添加到容器（如List::add），处理单个元素的累加逻辑\ncombiner() 合并并行流的子结果（如合并两个List：list1.addAll(list2)），需保证线程安全\nfinisher() 将中间容器转换为最终结果（如StringBuilder::toString），可进行最终转换或过滤\ncharacteristics() 返回收集器特性的Set，影响性能优化：\nCONCURRENT：支持多线程并发操作容器（需线程安全）\nUNORDERED：结果与元素顺序无关（如Set）\nIDENTITY_FINISH：跳过finisher()，直接返回中间容器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 private static \u0026lt;T, K, U\u0026gt; Collector\u0026lt;T, ?, Map\u0026lt;K, U\u0026gt;\u0026gt; toMapRemovingNulls(Function\u0026lt;? super T, ? extends K\u0026gt; keyMapper, Function\u0026lt;? super T, ? extends U\u0026gt; valueMapper, BinaryOperator\u0026lt;U\u0026gt; mergeFunction) { return Collector.of(HashMap::new, (map, element) -\u0026gt; { K key = keyMapper.apply(element); U value = valueMapper.apply(element); if (value == null) { map.remove(key); } else { map.merge(key, value, mergeFunction); } }, (map1, map2) -\u0026gt; { map2.forEach((key, value) -\u0026gt; { if (value != null) { map1.merge(key, value, mergeFunction); } }); return map1; }, Collector.Characteristics.UNORDERED); } Optional对象 将可能为 null 的对象包装在 Optional 容器中，强制开发者显式处理空值场景。\n1 Optional\u0026lt;String\u0026gt; name = Optional.ofNullable(getName()); 提供 map(), flatMap(), filter() 等方法，支持以函数式风格处理值：\n1 2 3 4 5 // 链式获取嵌套属性（避免多层判空） String province = Optional.ofNullable(user) .map(User::getAddress) // 若user非空，提取地址 .map(Address::getProvince) // 若地址非空，提取省份 .orElse(\u0026#34;未知地区\u0026#34;); // 若为空，返回默认值 深拷贝的三种方法 实现clone接口，要求引用属性全部实现clonable接口，递归调用。 直接序列化然后反序列化，要求引用属性全部实现serializable接口。 手动递归复制。 ","date":"2025-05-28T00:00:00Z","permalink":"https://sixiyida.github.io/p/%E6%97%A5%E5%B8%B8%E9%97%AE%E9%A2%98%E9%9B%86/","title":"日常问题集"},{"content":"线段树 核心思想：分治\n节点上维护[l, r]的某个值，左儿子节点维护[l, mid]，右儿子节点维护[mid + 1, r]。\n例题：LeetCode3479\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 class SegmentTree{ vector\u0026lt;int\u0026gt; mx; void maintain(int o){ mx[o] = max(mx[o * 2], mx[o * 2 + 1]); } void build(const vector\u0026lt;int\u0026gt; \u0026amp; a, int o, int l, int r) { if (l == r) { mx[o] = a[l]; return; } int m = (l + r) / 2; build(a, o * 2, l, m); build(a, o * 2 + 1, m + 1, r); maintain(o); //更新的关键操作 } public: SegmentTree(const vector\u0026lt;int\u0026gt; \u0026amp; a) { size_t n = a.size(); mx.resize(2 \u0026lt;\u0026lt; bit_width(n - 1));//? build(a, 1, 0, n - 1); } int findFirstAndUpdate(int o, int l, int r, int x) { if (mx[o] \u0026lt; x) { return -1; } if (l == r) { mx[o] = -1; return l; } int m = (l + r) /2; int i = findFirstAndUpdate(o * 2, l, m, x); if (i \u0026lt; 0) i = findFirstAndUpdate(o * 2 + 1, m + 1, r, x); maintain(o); return i; } }; Lazy线段树 为什么lazy？ ​\t待节点区间完全在需要更新的区间内时，则不继续向下更新，而是标为lazy标记，待下一次需要更新到子节点的时候，再把这个标记向下传递。\n例题：LeetCode2569\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 class LazySegmentTree{ private: vector\u0026lt;int\u0026gt; cnt; vector\u0026lt;int\u0026gt; todo; void maintain(int o) { cnt[o] = cnt[o * 2] + cnt[o * 2 + 1]; } void build(const vector\u0026lt;int\u0026gt; \u0026amp; a, int o, int l, int r) { if (l == r) { cnt[o] = a[l]; return; } int mid = (l + r) / 2; build(a, o * 2, l, mid); build(a, o * 2 + 1, mid + 1, r); maintain(o); } void reverse(int o, int l, int r) { cnt[o] = r - l + 1 - cnt[o]; todo[o] = !todo[o]; } public: LazySegmentTree(const vector\u0026lt;int\u0026gt; \u0026amp; a) { int n = a.size(); cnt.resize(4 * n); todo.resize(4 * n); build(a, 1, 0, n - 1); } void update(int o, int l, int r, int L, int R) { if (L \u0026lt;= l \u0026amp;\u0026amp; r \u0026lt;= R) { //cout \u0026lt;\u0026lt; l \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; r \u0026lt;\u0026lt; endl; reverse(o, l, r); return; } int m = (l + r) / 2; if (todo[o]) { reverse(o * 2, l, m); reverse(o * 2 + 1, m + 1, r); todo[o] = false; } if (m \u0026gt;= L) { update(o * 2, l, m, L, R); } if (m \u0026lt; R) { // m + 1 \u0026lt;= R update(o * 2 + 1, m + 1, r, L, R); } maintain(o); } int getRootVal() { return cnt[1]; } }; KMP算法 核心思想：主串指针不动，子串动。子串从next[sub_ptr]的位置启动，next的含义是从[0, fail_sub_ptr]的子串中，相同的最长真前后缀长度。\n","date":"2025-04-28T00:00:00Z","permalink":"https://sixiyida.github.io/p/algorithms/","title":"Algorithms"}]