[{"content":"MCP 学习笔记 总体架构 MCP Hosts: Programs like Claude Desktop, IDEs, or AI tools that want to access data through MCP MCP Clients: Protocol clients that maintain 1:1 connections with servers MCP Servers: Lightweight programs that each expose specific capabilities through the standardized Model Context Protocol Local Data Sources: Your computer’s files, databases, and services that MCP servers can securely access Remote Services: External systems available over the internet (e.g., through APIs) that MCP servers can connect to 这里由图，会话生命周期主要有三个阶段：\n主机初始化客户端，客户端初始化session向服务端发送请求，服务端回复自有能力。 会话阶段，主要包含三种功能。 主机向客户端发起终止，客户端向服务端发起中止请求。 对于会话阶段，同样有三种事件循环：\nMCP client发起工具/资源请求，server回以响应内容。 同样的，Server可以向client发起采样请求。 Server有资源更新，可以通知client。 核心概念 Servers offer any of the following features to clients:\nResources: Context and data, for the user or the AI model to use Prompts: Templated messages and workflows for users Tools: Functions for the AI model to execute Clients may offer the following features to servers:\nSampling: Server-initiated agentic behaviors and recursive LLM interactions Roots: Server-initiated inquiries into uri or filesystem boundaries to operate in Elicitation: Server-initiated requests for additional information from users 资源（Resources） MCP支持任意类型的资源，URI按照以下格式来：\n1 [protocol]://[host]/[path] file:///home/user/documents/report.pdf postgres://database/customers/schema screen://localhost/display1 具体的请求有：Discovery和Reading，具体请求格式见：https://modelcontextprotocol.io/docs/concepts/resources#typescript\n提示词（Prompts） 提示词是Server暴露给Client，方便Client使用的东西，相当于将存在本地的Prompt放在Server，随用随取。\n提示词普遍定义如下：\n1 2 3 4 5 6 7 8 9 10 11 { name: string; // Unique identifier for the prompt description?: string; // Human-readable description arguments?: [ // Optional list of arguments { name: string; // Argument identifier description?: string; // Argument description required?: boolean; // Whether argument is required } ] } Client可以发起请求要求Server提供提示词列表，并指定名称列表请求服务器返回prompt，prompt还可以携带client的参数。\n具体请求格式见：https://modelcontextprotocol.io/docs/concepts/prompts\n工具（Tools） MCP Server中的工具的特性有：1.暴露工具列表在tools/list端点，2.暴露调用接口到tools/call端点，3. 可执行简单到复杂的任务。\nTools普遍定义如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { name: string; // Unique identifier for the tool description?: string; // Human-readable description inputSchema: { // JSON Schema for the tool\u0026#39;s parameters type: \u0026#34;object\u0026#34;, properties: { ... } // Tool-specific parameters }, annotations?: { // Optional hints about tool behavior title?: string; // Human-readable title for the tool readOnlyHint?: boolean; // If true, the tool does not modify its environment destructiveHint?: boolean; // If true, the tool may perform destructive updates idempotentHint?: boolean; // If true, repeated calls with same args have no additional effect openWorldHint?: boolean; // If true, tool interacts with external entities } } 具体请求格式见：https://modelcontextprotocol.io/docs/concepts/tools\n采样（Samples） 采样指的是，Server向Client发送请求，Client可以修改参数，并用请求中的参数调用大模型，并检查返回的结果，最后将结果返回Server的过程。\n采样请求如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 { messages: [ { role: \u0026#34;user\u0026#34; | \u0026#34;assistant\u0026#34;, content: { type: \u0026#34;text\u0026#34; | \u0026#34;image\u0026#34;, // For text: text?: string, // For images: data?: string, // base64 encoded mimeType?: string } } ], modelPreferences?: { hints?: [{ name?: string // Suggested model name/family }], costPriority?: number, // 0-1, importance of minimizing cost speedPriority?: number, // 0-1, importance of low latency intelligencePriority?: number // 0-1, importance of capabilities }, systemPrompt?: string, includeContext?: \u0026#34;none\u0026#34; | \u0026#34;thisServer\u0026#34; | \u0026#34;allServers\u0026#34;, temperature?: number, maxTokens: number, stopSequences?: string[], metadata?: Record\u0026lt;string, unknown\u0026gt; } 返回的请求的格式：\n1 2 3 4 5 6 7 8 9 10 11 { model: string, // Name of the model used stopReason?: \u0026#34;endTurn\u0026#34; | \u0026#34;stopSequence\u0026#34; | \u0026#34;maxTokens\u0026#34; | string, role: \u0026#34;user\u0026#34; | \u0026#34;assistant\u0026#34;, content: { type: \u0026#34;text\u0026#34; | \u0026#34;image\u0026#34;, text?: string, data?: string, mimeType?: string } } Roots Roots是MCP Client向MCP Server暴露资源路径的通道，它可以是任何有效的URI或者是HTTP URL，比如大模型API根地址或者是文件系统目录。\n格式：\n1 2 3 4 5 6 7 8 9 10 11 12 { \u0026#34;roots\u0026#34;: [ { \u0026#34;uri\u0026#34;: \u0026#34;file:///home/user/projects/frontend\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Frontend Repository\u0026#34; }, { \u0026#34;uri\u0026#34;: \u0026#34;https://api.example.com/v1\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;API Endpoint\u0026#34; } ] } Elicitation 直译为引出，其实就是Server向Client发送请求，要求用户/Client侧补充信息的请求。\n请求格式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 { \u0026#34;message\u0026#34;: \u0026#34;Please provide your GitHub username\u0026#34;, \u0026#34;requestedSchema\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;username\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;GitHub Username\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Your GitHub username (e.g., octocat)\u0026#34; } }, \u0026#34;required\u0026#34;: [\u0026#34;username\u0026#34;] } } 协议 JsonRPC2.0 JSON-RPC 2.0 是一种轻量级、无状态的远程过程调用（RPC）协议，使用 JSON 作为数据交换格式，专为跨语言和跨平台通信设计。\n请求对象（Request）\n1 2 3 4 5 6 { \u0026#34;jsonrpc\u0026#34;: \u0026#34;2.0\u0026#34;, // 固定版本标识 \u0026#34;method\u0026#34;: \u0026#34;subtract\u0026#34;, // 调用的方法名 \u0026#34;params\u0026#34;: [42, 23]或{\u0026#34;minuend\u0026#34;:42, \u0026#34;subtrahend\u0026#34;:23}, // 参数（数组或对象） \u0026#34;id\u0026#34;: \u0026#34;req_001\u0026#34; // 请求唯一标识（通知可省略） } 响应对象（Response）\n1 2 3 4 5 { \u0026#34;jsonrpc\u0026#34;: \u0026#34;2.0\u0026#34;, \u0026#34;result\u0026#34;: 19, // 方法返回值 \u0026#34;id\u0026#34;: \u0026#34;req_001\u0026#34; // 与请求ID一致 } HTTP vs RPC JSON-RPC 2.0\n定位：基于消息的远程过程调用（RPC）协议，关注动作执行（如调用函数deleteUser）。\n设计核心：通过结构化 JSON 消息封装方法名、参数和请求 ID，实现跨语言的服务调用，屏蔽网络细节。\n典型场景：微服务间通信、智能代理指令传递（如 MCP 中的函数调用链）。\nHTTP\n定位：应用层传输协议，关注资源操作（如DELETE /users/123）。\n设计核心：基于请求-响应模型，利用 URL 定位资源，通过 HTTP 方法（GET/POST/DELETE）操作资源状态。\n典型场景：Web 页面加载、RESTful API 设计（如公开的用户管理接口）。\nMCP为何不选用HTTP或gRPC？ 需求：1. 双向通信、2. 会话状态维持、3. 松散结构以支持动态发现工具、4. 易于调试。\nHTTP不支持1和2。\ngRPC不支持3和4。\n具体格式可以见：https://modelcontextprotocol.io/docs/concepts/transports\n内置传输机制 stdio 使用STDIO在本地标准输入输出流之间传输，这对于本地的进程之间通信非常方便。\nStreamable HTTP Streamable HTTP是可升级为SSE的基于HTTP的传输协议。在这种形态中，MCP Server必须要暴露一个支持GET和POST的端点比如说：\n1 https://example.com/mcp 对于Client到Server，所有JSON-RPC格式的message都通过HTTP POST的形式从Client送到Server。\n对于Server到Client的响应，可以选择是简单的JSON的响应，或者是建立SSE的流式响应。\n对于Server到Client的请求或者是通知，可以使用由Client请求的已经建立的SSE，或者是Client可以主动发起一个空GET请求，此时Server就会把它升级为一个SSE。至此，Server就具备了一个能够主动向Client推送信息的SSE通道。\nSSE（已经弃用） SSE在逻辑上是一个由客户端发起、由服务器同意而建立的从服务器向客户端发消息的单向管道。\n以下是一个Server向Client发起的事件：\n1 2 3 4 id:11a3eabb-f6fa-4c5a-8d9b-80ffdb040b14 event:endpoint data:/sse?sessionId=11a3eabb-f6fa-4c5a-8d9b-80ffdb040b14 \u0026lt;空行\u0026gt; 客户端收到每行后，都解析出一个字段，字段名分别为id、event和data（这三个全是SSE规定的标准字段，分别表示事件的ID、类别和数据）。收到空行后，就把前面解析出的字段们放到一起，组合成一个事件，由客户端代码中的事件处理逻辑进行处理。\n客户端往服务器发消息时仍然使用传统HTTP请求的方式。客户端发的消息都发往同一个地址，就是此处服务器返回的**/sse?sessionId=11a3eabb-f6fa-4c5a-8d9b-80ffdb040b14**。\n此时客户端会回一个POST请求，表示建立成功：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 { \u0026#34;method\u0026#34;: \u0026#34;initialize\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;76062378-0\u0026#34;, \u0026#34;jsonrpc\u0026#34;: \u0026#34;2.0\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;capabilities\u0026#34;: { \u0026#34;sampling\u0026#34;: {}, \u0026#34;roots\u0026#34;: { \u0026#34;listChanged\u0026#34;: true } }, \u0026#34;clientInfo\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;MCP 测试客户端\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34; }, \u0026#34;protocolVersion\u0026#34;: \u0026#34;2024-11-05\u0026#34; } } 此时Server只回一个状态码，因为所有信息都在SSE中传输了。\n**具体协议见：**https://modelcontextprotocol.io/specification/2025-03-26/basic/transports\nJava SDK 待更新。\n","date":"2025-07-16T00:00:00Z","permalink":"https://sixiyida.github.io/p/mcp%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"MCP学习笔记"},{"content":"Spring AI Alibaba Graph 使用指南与源码解读 深入理解Spring AI Alibaba Graph的设计思路、核心能力与最佳实践\n目录 1. 引言与概述 2. 核心架构与设计理念 3. 核心概念深度解析 4. 预定义组件与工具箱 5. 高级特性与扩展能力 6. 快速开始与实战指南 1. 引言与概述 1.1 Spring AI Alibaba Graph 概述 Spring AI Alibaba Graph 是社区核心实现之一，也是整个框架在设计理念上区别于 Spring AI 只做底层原子抽象的地方，Spring AI Alibaba 期望帮助开发者更容易的构建智能体应用。基于 Graph 开发者可以构建工作流、多智能体应用。\nSpring AI Alibaba Graph 在设计理念上借鉴 LangGraph，因此在一定程度上可以理解为是 Java 版的 LangGraph 实现，社区在此基础上增加了大量预置 Node、简化了 State 定义过程等，让开发者更容易编写对等低代码平台的工作流、多智能体等。\n1.2 核心特性与优势 相比传统的AI应用开发方式，Spring AI Alibaba Graph具有以下核心优势：\nJava生态深度集成 Spring原生支持：完整的依赖注入、配置管理、监控观测 高并发处理：Java天然的多线程优势，支持高并发场景 丰富的预置组件 15+ 预定义节点类型：QuestionClassifierNode、LlmNode、ToolNode、KnowledgeRetrievalNode等 多种Agent模式：内置React、Reflection、Supervisor等智能体模式 简化的State管理：统一的状态定义和合并策略 声明式API设计 类似LangGraph的API：Java开发者更容易上手 链式调用：简洁的流式API，代码更加优雅 条件分支：支持复杂的条件逻辑和并行处理 生产级特性 观测性支持：完整的指标收集、链路追踪 容错机制：支持检查点、状态恢复、错误处理 人机协作：Human-in-the-loop支持，支持修改状态、恢复执行 快速开始：客户评价分类系统 让我们通过一个具体示例了解Spring AI Alibaba Graph的使用方式。这个示例展示了如何构建一个客户评价分类系统：\n系统架构 1 2 3 4 5 6 7 8 graph TD A[用户输入] --\u0026gt; B[评价分类器] B --\u0026gt; C{正面/负面?} C --\u0026gt;|正面| D[记录好评] C --\u0026gt;|负面| E[问题细分器] E --\u0026gt; F[问题处理器] D --\u0026gt; G[结束] F --\u0026gt; G 核心代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 @Configuration public class CustomerServiceWorkflow { @Bean public StateGraph customerServiceGraph(ChatModel chatModel) { ChatClient chatClient = ChatClient.builder(chatModel) .defaultAdvisors(new SimpleLoggerAdvisor()) .build(); // 评价分类器 - 区分正面/负面评价 QuestionClassifierNode feedbackClassifier = QuestionClassifierNode.builder() .chatClient(chatClient) .inputTextKey(\u0026#34;input\u0026#34;) .outputKey(\u0026#34;classifier_output\u0026#34;) .categories(List.of(\u0026#34;positive feedback\u0026#34;, \u0026#34;negative feedback\u0026#34;)) .build(); // 问题细分器 - 对负面评价进行细分 QuestionClassifierNode specificQuestionClassifier = QuestionClassifierNode.builder() .chatClient(chatClient) .inputTextKey(\u0026#34;input\u0026#34;) .outputKey(\u0026#34;classifier_output\u0026#34;) .categories(List.of(\u0026#34;after-sale service\u0026#34;, \u0026#34;transportation\u0026#34;, \u0026#34;product quality\u0026#34;, \u0026#34;others\u0026#34;)) .build(); // 状态工厂定义 - 简化的状态管理 KeyStrategyFactory stateFactory = () -\u0026gt; { Map\u0026lt;String, KeyStrategy\u0026gt; strategies = new HashMap\u0026lt;\u0026gt;(); strategies.put(\u0026#34;input\u0026#34;, new ReplaceStrategy()); strategies.put(\u0026#34;classifier_output\u0026#34;, new ReplaceStrategy()); strategies.put(\u0026#34;solution\u0026#34;, new ReplaceStrategy()); return strategies; }; // 构建工作流 - 声明式API return new StateGraph(\u0026#34;客户服务评价处理\u0026#34;, stateFactory) .addNode(\u0026#34;feedback_classifier\u0026#34;, node_async(feedbackClassifier)) .addNode(\u0026#34;specific_question_classifier\u0026#34;, node_async(specificQuestionClassifier)) .addNode(\u0026#34;recorder\u0026#34;, node_async(new RecordingNode())) .addEdge(START, \u0026#34;feedback_classifier\u0026#34;) .addConditionalEdges(\u0026#34;feedback_classifier\u0026#34;, edge_async(new FeedbackQuestionDispatcher()), Map.of(\u0026#34;positive\u0026#34;, \u0026#34;recorder\u0026#34;, \u0026#34;negative\u0026#34;, \u0026#34;specific_question_classifier\u0026#34;)) .addEdge(\u0026#34;recorder\u0026#34;, END); } } 以上代码只展示了图结构（StateGraph）的构建，具体的代码实现您可以关注spring-ai-alibaba-example仓库：spring-ai-alibaba-example\n这个示例展示了Spring AI Alibaba Graph的核心特性：\n预置组件：使用QuestionClassifierNode快速实现分类功能 简化状态管理：通过KeyStrategyFactory统一管理状态 声明式API：链式调用构建复杂工作流 Spring Boot集成：通过@Configuration和@Bean完成依赖注入 2. 核心架构与设计理念 2.1 整体数据流转架构 Spring AI Alibaba Graph采用工作流模型，整个框架的数据流转遵循**\u0026ldquo;构建→编译→执行\u0026rdquo;**的三阶段模式：\n2.1.1 完整数据流转图 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 flowchart TD subgraph \u0026#34;阶段1: 构建阶段\u0026#34; A[开发者定义StateGraph] --\u0026gt; B[添加节点 addNode] B --\u0026gt; C[添加边 addEdge/addConditionalEdges] C --\u0026gt; D[定义状态策略 KeyStrategyFactory] D --\u0026gt; E[图结构验证 validateGraph] end subgraph \u0026#34;阶段2: 编译阶段\u0026#34; E --\u0026gt; F[StateGraph.compile] F --\u0026gt; G[处理子图展开] G --\u0026gt; H[检测并行边模式] H --\u0026gt; I[创建ParallelNode] I --\u0026gt; J[节点Action预处理] J --\u0026gt; K[边路由优化] K --\u0026gt; L[生成CompiledGraph] end subgraph \u0026#34;阶段3: 执行阶段\u0026#34; L --\u0026gt; M{调用方式} M --\u0026gt;|invoke| N[同步执行] M --\u0026gt;|stream| O[流式执行] N --\u0026gt; P[创建AsyncNodeGenerator] O --\u0026gt; P P --\u0026gt; Q[状态机驱动执行] Q --\u0026gt; R[节点调度与执行] R --\u0026gt; S[状态更新与合并] S --\u0026gt; T[检查点保存] T --\u0026gt; U[条件判断与路由] U --\u0026gt; V{是否结束?} V --\u0026gt;|否| R V --\u0026gt;|是| W[返回最终结果] end subgraph \u0026#34;数据载体\u0026#34; X[OverAllState\u0026lt;br/\u0026gt;全局状态管理] Y[RunnableConfig\u0026lt;br/\u0026gt;执行配置] Z[NodeOutput\u0026lt;br/\u0026gt;节点输出] end R --\u0026gt; X X --\u0026gt; S Y --\u0026gt; P Z --\u0026gt; W style A fill:#e1f5fe style L fill:#fff3e0 style W fill:#e8f5e8 2.1.2 核心执行流程详解 数据流转的核心理念：整个框架围绕OverAllState这个数据载体进行流转，每个节点都是状态的转换器，通过AsyncNodeGenerator这个状态机来驱动整个流程的执行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 sequenceDiagram participant Dev as 开发者 participant SG as StateGraph participant CG as CompiledGraph participant ANG as AsyncNodeGenerator participant Node as 节点 participant State as OverAllState Dev-\u0026gt;\u0026gt;SG: 1. 构建图结构 SG-\u0026gt;\u0026gt;SG: 2. 验证图完整性 SG-\u0026gt;\u0026gt;CG: 3. 编译优化 CG-\u0026gt;\u0026gt;CG: 4. 处理子图和并行 Dev-\u0026gt;\u0026gt;CG: 5. invoke/stream调用 CG-\u0026gt;\u0026gt;State: 6. 初始化状态 CG-\u0026gt;\u0026gt;ANG: 7. 创建执行器 loop 执行循环 ANG-\u0026gt;\u0026gt;ANG: 8. 状态机推进 ANG-\u0026gt;\u0026gt;Node: 9. 调度节点执行 Node-\u0026gt;\u0026gt;Node: 10. 业务逻辑处理 Node-\u0026gt;\u0026gt;State: 11. 状态更新 State-\u0026gt;\u0026gt;ANG: 12. 状态合并完成 ANG-\u0026gt;\u0026gt;ANG: 13. 路由下一节点 end ANG-\u0026gt;\u0026gt;CG: 14. 返回最终结果 CG-\u0026gt;\u0026gt;Dev: 15. 完成执行 2.1.3 关键数据结构流转 StateGraph → CompiledGraph转换：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 graph LR subgraph \u0026#34;StateGraph (静态定义)\u0026#34; A[节点定义\u0026lt;br/\u0026gt;Map\u0026amp;lt;String, Node\u0026amp;gt;] B[边定义\u0026lt;br/\u0026gt;Map\u0026amp;lt;String, Edge\u0026amp;gt;] C[状态策略\u0026lt;br/\u0026gt;KeyStrategyFactory] end subgraph \u0026#34;编译处理\u0026#34; D[节点预处理\u0026lt;br/\u0026gt;ActionFactory.apply] E[边路由优化\u0026lt;br/\u0026gt;EdgeValue处理] F[并行检测\u0026lt;br/\u0026gt;ParallelNode创建] G[子图展开\u0026lt;br/\u0026gt;SubGraph处理] end subgraph \u0026#34;CompiledGraph (可执行)\u0026#34; H[执行节点\u0026lt;br/\u0026gt;Map\u0026amp;lt;String, AsyncNodeActionWithConfig\u0026amp;gt;] I[路由映射\u0026lt;br/\u0026gt;Map\u0026amp;lt;String, EdgeValue\u0026amp;gt;] J[配置信息\u0026lt;br/\u0026gt;CompileConfig] end A --\u0026gt; D B --\u0026gt; E C --\u0026gt; F D --\u0026gt; H E --\u0026gt; I F --\u0026gt; G G --\u0026gt; J AsyncNodeGenerator执行机制：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 stateDiagram-v2 [*] --\u0026gt; Initialize: 创建执行器 Initialize --\u0026gt; CheckResume: 检查恢复模式 CheckResume --\u0026gt; LoadSnapshot: 恢复模式 CheckResume --\u0026gt; StartExecution: 正常启动 LoadSnapshot --\u0026gt; StartExecution: 加载完成 StartExecution --\u0026gt; ExecuteNode: 执行当前节点 ExecuteNode --\u0026gt; UpdateState: 更新状态 UpdateState --\u0026gt; SaveCheckpoint: 保存检查点 SaveCheckpoint --\u0026gt; RouteNext: 路由下一节点 RouteNext --\u0026gt; CheckEnd: 检查结束条件 CheckEnd --\u0026gt; ExecuteNode: 继续执行 CheckEnd --\u0026gt; [*]: 执行完成 ExecuteNode --\u0026gt; CheckInterrupt: 检查中断 CheckInterrupt --\u0026gt; Interrupt: 中断执行 Interrupt --\u0026gt; [*]: 等待恢复 2.2 整体架构设计 基于上述数据流转机制，Spring AI Alibaba Graph的整体架构设计具有以下特点：\n清晰的执行流程：每个节点代表一个处理步骤，边表示数据流向 灵活的条件分支：支持根据状态动态选择执行路径 并行处理能力：多个节点可以并行执行，提高处理效率 状态可追溯：完整的状态变化历史，便于调试和监控 架构核心理念：Spring AI Alibaba Graph将复杂的AI任务分解为可组合的原子操作，每个节点专注于单一职责，通过状态驱动的方式实现节点间的协调。这种设计让开发者可以像搭积木一样构建复杂的AI应用，既保证了系统的可维护性，又提供了足够的灵活性。\n2.2.1 系统架构总览 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 graph TB subgraph \u0026#34;用户层\u0026#34; U1[Spring Boot应用] U2[REST Controller] U3[业务逻辑] end subgraph \u0026#34;Spring AI Alibaba Graph核心\u0026#34; SG[StateGraph\u0026lt;br/\u0026gt;状态图定义\u0026lt;br/\u0026gt;工作流蓝图] CG[CompiledGraph\u0026lt;br/\u0026gt;编译执行器\u0026lt;br/\u0026gt;运行时引擎] OS[OverAllState\u0026lt;br/\u0026gt;全局状态\u0026lt;br/\u0026gt;数据载体] subgraph \u0026#34;节点层\u0026#34; N1[LlmNode\u0026lt;br/\u0026gt;大模型节点] N2[ToolNode\u0026lt;br/\u0026gt;工具节点] N3[QuestionClassifierNode\u0026lt;br/\u0026gt;分类节点] N4[CustomNode\u0026lt;br/\u0026gt;自定义节点] end subgraph \u0026#34;Agent层\u0026#34; A1[ReactAgent\u0026lt;br/\u0026gt;反应式Agent] A2[ReflectAgent\u0026lt;br/\u0026gt;反思Agent] A3[ReactAgentWithHuman\u0026lt;br/\u0026gt;人机协作Agent] end end subgraph \u0026#34;基础设施层\u0026#34; SC[Spring Container\u0026lt;br/\u0026gt;依赖注入] OB[Observation\u0026lt;br/\u0026gt;观测性] CP[Checkpoint\u0026lt;br/\u0026gt;检查点] SZ[Serialization\u0026lt;br/\u0026gt;序列化] end subgraph \u0026#34;外部服务\u0026#34; LLM[大语言模型\u0026lt;br/\u0026gt;DashScope/OpenAI] TOOL[外部工具\u0026lt;br/\u0026gt;API/函数] STORE[存储服务\u0026lt;br/\u0026gt;Redis/DB] end U1 --\u0026gt; U2 U2 --\u0026gt; U3 U3 --\u0026gt; SG SG --\u0026gt; CG CG --\u0026gt; OS CG --\u0026gt; N1 CG --\u0026gt; N2 CG --\u0026gt; N3 CG --\u0026gt; N4 A1 --\u0026gt; SG A2 --\u0026gt; SG A3 --\u0026gt; SG CG --\u0026gt; SC CG --\u0026gt; OB CG --\u0026gt; CP CG --\u0026gt; SZ N1 --\u0026gt; LLM N2 --\u0026gt; TOOL CP --\u0026gt; STORE SZ --\u0026gt; STORE 2.2.2 StateGraph构建流程 StateGraph是工作流的蓝图设计器，它负责定义整个工作流的结构和执行逻辑，就像建筑师绘制建筑图纸一样。通过声明式的API，开发者可以轻松定义节点、边和状态管理策略，最终编译成可执行的CompiledGraph。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 flowchart TD A[开始构建StateGraph] --\u0026gt; B[创建StateGraph实例] B --\u0026gt; C[定义KeyStrategyFactory] C --\u0026gt; D[添加节点 addNode] D --\u0026gt; E{是否还有节点?} E --\u0026gt;|是| D E --\u0026gt;|否| F[添加边 addEdge] F --\u0026gt; G{是否还有边?} G --\u0026gt;|是| H[添加条件边 addConditionalEdges] H --\u0026gt; G G --\u0026gt;|否| I[验证图结构 validateGraph] I --\u0026gt; J{验证通过?} J --\u0026gt;|否| K[抛出GraphStateException] J --\u0026gt;|是| L[编译图 compile] L --\u0026gt; M[生成CompiledGraph] M --\u0026gt; N[结束] style A fill:#e1f5fe style N fill:#e8f5e8 style K fill:#ffebee 关键设计思想：StateGraph采用了\u0026quot;先定义后执行\u0026quot;的模式，将工作流的结构定义与实际执行分离，这样可以在编译时进行各种验证和优化，确保运行时的稳定性和高效性。\n2.2.3 CompiledGraph执行流程 CompiledGraph是工作流的运行时引擎，它将StateGraph的静态定义转换为可执行的动态流程。就像将建筑图纸变成真正的建筑物一样，CompiledGraph负责协调各个组件的执行，管理状态流转，确保整个工作流按照预期运行。\nAsyncNodeGenerator是整个图流转执行的唯一状态机，它控制着工作流的每一步执行，包括节点调度、状态更新、条件判断和异常处理。这种单一状态机的设计确保了执行的一致性和可预测性。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 sequenceDiagram participant Client as 客户端 participant CG as CompiledGraph participant ANG as AsyncNodeGenerator participant Node as 节点 participant State as OverAllState Client-\u0026gt;\u0026gt;CG: invoke(inputs) CG-\u0026gt;\u0026gt;CG: stateCreate(inputs) CG-\u0026gt;\u0026gt;ANG: new AsyncNodeGenerator(state, config) loop 执行循环 ANG-\u0026gt;\u0026gt;ANG: next() ANG-\u0026gt;\u0026gt;ANG: 检查最大迭代次数 ANG-\u0026gt;\u0026gt;ANG: 检查中断条件 alt 起始节点 ANG-\u0026gt;\u0026gt;ANG: 处理START节点 ANG-\u0026gt;\u0026gt;ANG: 确定下一个节点 else 普通节点 ANG-\u0026gt;\u0026gt;Node: 执行节点动作 Node-\u0026gt;\u0026gt;State: 更新状态 State--\u0026gt;\u0026gt;ANG: 返回更新结果 ANG-\u0026gt;\u0026gt;ANG: 确定下一个节点 else 结束节点 ANG-\u0026gt;\u0026gt;ANG: 处理END节点 ANG--\u0026gt;\u0026gt;CG: 返回最终结果 end ANG-\u0026gt;\u0026gt;ANG: 添加检查点 end CG--\u0026gt;\u0026gt;Client: 返回最终状态 核心执行机制：CompiledGraph采用了基于迭代器模式的异步执行机制，每次调用next()方法都会推进工作流的执行，这种设计既支持同步调用，也支持流式处理，为不同的使用场景提供了灵活性。\n2.3 核心组件关系图 组件职责说明：\nStateGraph：工作流的架构师，负责定义整个流程的结构和规则 CompiledGraph：工作流的指挥官，负责协调和管理整个执行过程 OverAllState：工作流的记忆中心，负责存储和管理所有状态数据 Node：工作流的执行单元，每个节点专注于特定的业务逻辑 Edge：工作流的连接器，定义节点之间的转换关系和条件 AsyncNodeGenerator：工作流的执行引擎，是推动整个流程运转的核心状态机 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 classDiagram class StateGraph { +String name +Nodes nodes +Edges edges +KeyStrategyFactory keyStrategyFactory +addNode(String id, NodeAction action) +addEdge(String source, String target) +addConditionalEdges(String source, EdgeCondition condition, Map mappings) +compile(CompileConfig config) CompiledGraph +validateGraph() } class CompiledGraph { +StateGraph stateGraph +CompileConfig compileConfig +Map~String,AsyncNodeActionWithConfig~ nodes +Map~String,EdgeValue~ edges +invoke(Map input) Optional~OverAllState~ +stream(Map input) AsyncGenerator~NodeOutput~ +resume(HumanFeedback feedback) Optional~OverAllState~ } class OverAllState { +Map~String,Object~ data +Map~String,KeyStrategy~ keyStrategies +Boolean resume +HumanFeedback humanFeedback +String interruptMessage +value(String key) Optional~Object~ +updateState(Map updates) +registerKeyAndStrategy(String key, KeyStrategy strategy) } class Node { +String id +ActionFactory actionFactory +apply(CompileConfig config) AsyncNodeActionWithConfig +isParallel() boolean } class Edge { +String sourceId +EdgeValue targetValue +validate(Nodes nodes) } class AsyncNodeGenerator { +Map~String,Object~ currentState +String currentNodeId +String nextNodeId +OverAllState overAllState +RunnableConfig config +next() Data~NodeOutput~ } StateGraph --\u0026gt; CompiledGraph : compile() StateGraph --\u0026gt; Node : contains StateGraph --\u0026gt; Edge : contains CompiledGraph --\u0026gt; OverAllState : manages CompiledGraph --\u0026gt; AsyncNodeGenerator : creates Node --\u0026gt; OverAllState : processes AsyncNodeGenerator --\u0026gt; Node : executes AsyncNodeGenerator --\u0026gt; OverAllState : updates 2.4 核心设计理念 2.4.1 声明式编程模型 借鉴LangGraph的设计理念，Spring AI Alibaba Graph采用声明式编程模型，开发者只需要描述\u0026quot;做什么\u0026quot;：\n1 2 3 4 5 6 7 8 9 10 // 声明式定义工作流 StateGraph graph = new StateGraph(\u0026#34;客户服务工作流\u0026#34;, stateFactory) .addNode(\u0026#34;feedback_classifier\u0026#34;, node_async(feedbackClassifier)) .addNode(\u0026#34;specific_question_classifier\u0026#34;, node_async(specificQuestionClassifier)) .addNode(\u0026#34;recorder\u0026#34;, node_async(recorderNode)) .addEdge(START, \u0026#34;feedback_classifier\u0026#34;) .addConditionalEdges(\u0026#34;feedback_classifier\u0026#34;, edge_async(new FeedbackQuestionDispatcher()), Map.of(\u0026#34;positive\u0026#34;, \u0026#34;recorder\u0026#34;, \u0026#34;negative\u0026#34;, \u0026#34;specific_question_classifier\u0026#34;)) .addEdge(\u0026#34;recorder\u0026#34;, END); 2.4.2 状态驱动的执行模型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 flowchart LR subgraph \u0026#34;状态管理流程\u0026#34; S1[初始状态] --\u0026gt; N1[节点1执行] N1 --\u0026gt; U1[状态更新] U1 --\u0026gt; S2[新状态] S2 --\u0026gt; N2[节点2执行] N2 --\u0026gt; U2[状态更新] U2 --\u0026gt; S3[最终状态] end subgraph \u0026#34;状态结构\u0026#34; OS[OverAllState] OS --\u0026gt; D[data: Map\u0026lt;String,Object\u0026gt;] OS --\u0026gt; KS[keyStrategies: Map\u0026lt;String,KeyStrategy\u0026gt;] OS --\u0026gt; R[resume: Boolean] OS --\u0026gt; HF[humanFeedback: HumanFeedback] end subgraph \u0026#34;状态策略\u0026#34; RS[ReplaceStrategy\u0026lt;br/\u0026gt;替换策略] AS[AppendStrategy\u0026lt;br/\u0026gt;追加策略] CS[CustomStrategy\u0026lt;br/\u0026gt;自定义策略] end U1 --\u0026gt; OS U2 --\u0026gt; OS KS --\u0026gt; RS KS --\u0026gt; AS KS --\u0026gt; CS 所有的数据流转都通过OverAllState进行管理，确保状态的一致性和可追溯性：\n1 2 3 4 5 6 7 8 // 状态工厂定义 KeyStrategyFactory stateFactory = () -\u0026gt; { Map\u0026lt;String, KeyStrategy\u0026gt; strategies = new HashMap\u0026lt;\u0026gt;(); strategies.put(\u0026#34;input\u0026#34;, new ReplaceStrategy()); strategies.put(\u0026#34;classifier_output\u0026#34;, new ReplaceStrategy()); strategies.put(\u0026#34;solution\u0026#34;, new ReplaceStrategy()); return strategies; }; 2.4.3 异步优先的设计 框架优先支持异步处理，提高系统的吞吐量和响应性，同时还原生支持了节点内模型流式透传：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 graph TD subgraph \u0026#34;异步执行模型\u0026#34; A1[AsyncNodeAction] --\u0026gt; CF1[CompletableFuture] A2[AsyncNodeActionWithConfig] --\u0026gt; CF2[CompletableFuture] A3[AsyncCommandAction] --\u0026gt; CF3[CompletableFuture] CF1 --\u0026gt; ANG[AsyncNodeGenerator] CF2 --\u0026gt; ANG CF3 --\u0026gt; ANG ANG --\u0026gt; AG[AsyncGenerator] AG --\u0026gt; Stream[Stream Processing] end subgraph \u0026#34;并行处理\u0026#34; PN[ParallelNode] --\u0026gt; PA1[Action1] PN --\u0026gt; PA2[Action2] PN --\u0026gt; PA3[Action3] PA1 --\u0026gt; CF4[CompletableFuture] PA2 --\u0026gt; CF5[CompletableFuture] PA3 --\u0026gt; CF6[CompletableFuture] CF4 --\u0026gt; ALLOF[CompletableFuture.allOf] CF5 --\u0026gt; ALLOF CF6 --\u0026gt; ALLOF end 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // 异步节点定义 AsyncNodeAction asyncNode = node_async(new CustomNodeAction()); // 并行节点处理 public class ParallelNode extends Node { record AsyncParallelNodeAction( List\u0026lt;AsyncNodeActionWithConfig\u0026gt; actions, Map\u0026lt;String, KeyStrategy\u0026gt; channels ) implements AsyncNodeActionWithConfig { @Override public CompletableFuture\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; apply(OverAllState state, RunnableConfig config) { var futures = actions.stream() .map(action -\u0026gt; action.apply(state, config)) .toArray(CompletableFuture[]::new); return CompletableFuture.allOf(futures) .thenApply(v -\u0026gt; { // 合并所有结果 Map\u0026lt;String, Object\u0026gt; result = new HashMap\u0026lt;\u0026gt;(); for (CompletableFuture\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; future : futures) { result.putAll(future.join()); } return result; }); } } } 2.5 Spring生态集成 Spring AI Alibaba Graph与Spring生态深度集成，您可以轻松在您的Spring应用中引入AI模型工作流以开发智能Java应用。\n2.5.1 依赖注入架构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 graph TB subgraph \u0026#34;Spring Boot应用层\u0026#34; APP[Spring Boot Application] CTRL[REST Controller] SVC[Service Layer] end subgraph \u0026#34;Graph配置层\u0026#34; CONF[GraphConfiguration] BEAN1[@Bean StateGraph] BEAN2[@Bean CompiledGraph] BEAN3[@Bean ChatModel] end subgraph \u0026#34;Spring容器管理\u0026#34; IOC[IoC Container] DI[Dependency Injection] AOP[AOP Support] end subgraph \u0026#34;观测性集成\u0026#34; OBS[ObservationRegistry] METRICS[Metrics Collection] TRACING[Distributed Tracing] end APP --\u0026gt; CTRL CTRL --\u0026gt; SVC SVC --\u0026gt; BEAN2 CONF --\u0026gt; BEAN1 CONF --\u0026gt; BEAN2 CONF --\u0026gt; BEAN3 IOC --\u0026gt; DI DI --\u0026gt; CONF AOP --\u0026gt; OBS OBS --\u0026gt; METRICS OBS --\u0026gt; TRACING 2.5.2 依赖注入支持 以下代码演示了Spring AI Alibaba Graph是如何被IOC容器所管理的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @Configuration public class GraphConfiguration { @Bean public StateGraph workflowGraph(ChatModel chatModel) { ChatClient chatClient = ChatClient.builder(chatModel) .defaultAdvisors(new SimpleLoggerAdvisor()) .build(); // 构建图定义... return stateGraph; } @Bean public CompiledGraph compiledGraph(StateGraph stateGraph, ObservationRegistry observationRegistry) { return stateGraph.compile(CompileConfig.builder() .withLifecycleListener(new GraphObservationLifecycleListener(observationRegistry)) .build()); } } 2.5.3 观测性集成 Spring AI Alibaba Graph基于Micrometer内置了可观测支持，可以无缝集成Spring Boot可观测性。\n1 2 3 4 5 6 7 8 9 10 11 @RestController public class GraphController { public GraphController(@Qualifier(\u0026#34;workflowGraph\u0026#34;) StateGraph stateGraph, ObjectProvider\u0026lt;ObservationRegistry\u0026gt; observationRegistry) { this.compiledGraph = stateGraph.compile(CompileConfig.builder() .withLifecycleListener(new GraphObservationLifecycleListener( observationRegistry.getIfUnique(() -\u0026gt; ObservationRegistry.NOOP))) .build()); } } 3. 核心概念深度解析 3.1 StateGraph (状态图) StateGraph是整个框架的设计蓝图，它就像建筑师的设计图纸一样，定义了工作流的完整结构和执行逻辑。StateGraph采用声明式API，让开发者可以用简洁的代码描述复杂的业务流程，而不需要关心底层的执行细节。\n核心设计理念：StateGraph将复杂的工作流抽象为节点和边的组合，每个节点代表一个具体的操作，边定义了操作之间的流转关系。这种抽象让开发者可以专注于业务逻辑的设计，而不是执行机制的实现。\n3.1.1 StateGraph生命周期 1 2 3 4 5 6 7 8 9 10 11 12 stateDiagram-v2 [*] --\u0026gt; Created: new StateGraph() Created --\u0026gt; Building: 添加节点和边 Building --\u0026gt; Building: addNode() / addEdge() Building --\u0026gt; Validating: validateGraph() Validating --\u0026gt; Invalid: 验证失败 Invalid --\u0026gt; [*]: 抛出异常 Validating --\u0026gt; Valid: 验证通过 Valid --\u0026gt; Compiled: compile() Compiled --\u0026gt; Executing: invoke() / stream() Executing --\u0026gt; Completed: 执行完成 Completed --\u0026gt; [*] 3.1.2 基本构造 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class StateGraph { // 核心数据结构 final Nodes nodes = new Nodes(); // 存储所有节点 final Edges edges = new Edges(); // 存储所有边 // 特殊节点常量 public static final String END = \u0026#34;__END__\u0026#34;; public static final String START = \u0026#34;__START__\u0026#34;; public static final String ERROR = \u0026#34;__ERROR__\u0026#34;; // 状态管理 private KeyStrategyFactory keyStrategyFactory; private PlainTextStateSerializer stateSerializer; } 3.1.3 节点管理流程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 flowchart TD A[addNode调用] --\u0026gt; B{检查节点ID} B --\u0026gt;|ID为END| C[抛出异常] B --\u0026gt;|ID合法| D{检查是否重复} D --\u0026gt;|重复| E[抛出重复节点异常] D --\u0026gt;|不重复| F[创建Node对象] F --\u0026gt; G[添加到nodes集合] G --\u0026gt; H[返回StateGraph实例] subgraph \u0026#34;节点类型\u0026#34; I[普通节点\u0026lt;br/\u0026gt;AsyncNodeAction] J[带配置节点\u0026lt;br/\u0026gt;AsyncNodeActionWithConfig] K[子图节点\u0026lt;br/\u0026gt;StateGraph] L[命令节点\u0026lt;br/\u0026gt;AsyncCommandAction] end F --\u0026gt; I F --\u0026gt; J F --\u0026gt; K F --\u0026gt; L 支持的节点添加方式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // 添加普通节点 public StateGraph addNode(String id, AsyncNodeAction action) { Node node = new Node(id, (config) -\u0026gt; AsyncNodeActionWithConfig.of(action)); return addNode(id, node); } // 添加带配置的节点 public StateGraph addNode(String id, AsyncNodeActionWithConfig actionWithConfig) { Node node = new Node(id, (config) -\u0026gt; actionWithConfig); return addNode(id, node); } // 添加子图节点 public StateGraph addNode(String id, StateGraph subGraph) { subGraph.validateGraph(); // 先验证子图 var node = new SubStateGraphNode(id, subGraph); return addNode(id, node); } 3.1.4 边管理流程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 flowchart TD A[\u0026#34;addEdge调用\u0026#34;] --\u0026gt; B{\u0026#34;边类型\u0026#34;} B --\u0026gt;|静态边| C[\u0026#34;addEdge(source, target)\u0026#34;] B --\u0026gt;|条件边| D[\u0026#34;addConditionalEdges(source, condition, mappings)\u0026#34;] C --\u0026gt; E{\u0026#34;检查源节点\u0026#34;} E --\u0026gt;|源节点为END| F[\u0026#34;抛出异常\u0026#34;] E --\u0026gt;|源节点合法| G[\u0026#34;创建Edge对象\u0026#34;] G --\u0026gt; H[\u0026#34;添加到edges集合\u0026#34;] D --\u0026gt; I{\u0026#34;检查映射\u0026#34;} I --\u0026gt;|映射为空| J[\u0026#34;抛出异常\u0026#34;] I --\u0026gt;|映射有效| K[\u0026#34;创建条件边\u0026#34;] K --\u0026gt; L{\u0026#34;检查是否重复\u0026#34;} L --\u0026gt;|重复| M[\u0026#34;抛出重复边异常\u0026#34;] L --\u0026gt;|不重复| N[\u0026#34;添加到edges集合\u0026#34;] H --\u0026gt; O[\u0026#34;返回StateGraph\u0026#34;] N --\u0026gt; O 3.1.5 图验证机制 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 flowchart TD A[validateGraph开始] --\u0026gt; B[检查入口点] B --\u0026gt; C{START边是否存在?} C --\u0026gt;|否| D[抛出缺少入口点异常] C --\u0026gt;|是| E[验证START边] E --\u0026gt; F[验证所有节点] F --\u0026gt; G[验证所有边] G --\u0026gt; H{所有验证通过?} H --\u0026gt;|否| I[抛出GraphStateException] H --\u0026gt;|是| J[验证成功] subgraph \u0026#34;边验证逻辑\u0026#34; K[检查源节点存在性] L[检查目标节点存在性] M[检查条件边映射] end G --\u0026gt; K G --\u0026gt; L G --\u0026gt; M 3.2 OverAllState (全局状态) OverAllState是工作流的数据中枢，它就像工作流的记忆系统一样，负责在各个节点之间传递和管理状态数据。OverAllState不仅存储数据，还定义了数据的合并策略，确保不同节点产生的数据能够正确地整合在一起。\n设计巧思：OverAllState采用了策略模式来处理状态更新，不同的数据类型可以采用不同的合并策略（如替换、追加、合并等），这种设计让状态管理变得非常灵活，能够适应各种复杂的业务场景。\n3.2.1 状态管理架构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 classDiagram class OverAllState { -Map~String,Object~ data -Map~String,KeyStrategy~ keyStrategies -Boolean resume -HumanFeedback humanFeedback -String interruptMessage +value(String key) Optional~Object~ +updateState(Map updates) +registerKeyAndStrategy(String key, KeyStrategy strategy) +snapShot() Optional~OverAllState~ +withResume() +withHumanFeedback(HumanFeedback feedback) } class KeyStrategy { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; +apply(Object oldValue, Object newValue) Object } class ReplaceStrategy { +apply(Object oldValue, Object newValue) Object } class AppendStrategy { +apply(Object oldValue, Object newValue) Object } class HumanFeedback { +boolean approved +String feedback +Map~String,Object~ additionalData } OverAllState --\u0026gt; KeyStrategy OverAllState --\u0026gt; HumanFeedback KeyStrategy \u0026lt;|-- ReplaceStrategy KeyStrategy \u0026lt;|-- AppendStrategy 3.2.2 状态更新流程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 sequenceDiagram participant Node as 节点 participant State as OverAllState participant Strategy as KeyStrategy Node-\u0026gt;\u0026gt;State: 返回更新Map State-\u0026gt;\u0026gt;State: updateState(updates) loop 遍历每个更新项 State-\u0026gt;\u0026gt;State: 获取key对应的策略 State-\u0026gt;\u0026gt;Strategy: apply(oldValue, newValue) Strategy--\u0026gt;\u0026gt;State: 返回合并后的值 State-\u0026gt;\u0026gt;State: 更新data中的值 end State--\u0026gt;\u0026gt;Node: 状态更新完成 3.2.3 状态策略详解 策略模式架构：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 classDiagram class KeyStrategy { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; +apply(Object oldValue, Object newValue) Object } class ReplaceStrategy { +apply(Object oldValue, Object newValue) Object } class AppendStrategy { +apply(Object oldValue, Object newValue) Object } KeyStrategy \u0026lt;|-- ReplaceStrategy KeyStrategy \u0026lt;|-- AppendStrategy 内置策略实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 // 替换策略 - 新值覆盖旧值 public class ReplaceStrategy implements KeyStrategy { @Override public Object apply(Object oldValue, Object newValue) { return newValue; } } // 追加策略 - 新值追加到列表，支持复杂的列表操作 public class AppendStrategy implements KeyStrategy { @Override public Object apply(Object oldValue, Object newValue) { if (newValue == null) { return oldValue; } // 处理Optional类型 if (oldValue instanceof Optional\u0026lt;?\u0026gt; oldValueOptional) { oldValue = oldValueOptional.orElse(null); } boolean oldValueIsList = oldValue instanceof List\u0026lt;?\u0026gt;; // 处理移除操作 if (oldValueIsList \u0026amp;\u0026amp; newValue instanceof AppenderChannel.RemoveIdentifier\u0026lt;?\u0026gt;) { var result = new ArrayList\u0026lt;\u0026gt;((List\u0026lt;Object\u0026gt;) oldValue); removeFromList(result, (AppenderChannel.RemoveIdentifier) newValue); return unmodifiableList(result); } // 处理新值为集合的情况 List\u0026lt;Object\u0026gt; list = null; if (newValue instanceof List) { list = new ArrayList\u0026lt;\u0026gt;((List\u0026lt;?\u0026gt;) newValue); } else if (newValue.getClass().isArray()) { list = Arrays.asList((Object[]) newValue); } else if (newValue instanceof Collection) { list = new ArrayList\u0026lt;\u0026gt;((Collection\u0026lt;?\u0026gt;) newValue); } // 合并逻辑 if (oldValueIsList) { List\u0026lt;Object\u0026gt; oldList = (List\u0026lt;Object\u0026gt;) oldValue; if (list != null) { if (list.isEmpty()) { return oldValue; } // 合并并去重 var result = evaluateRemoval(oldList, list); return Stream.concat(result.oldValues().stream(), result.newValues().stream()) .distinct() .collect(Collectors.toList()); } else { oldList.add(newValue); } return oldList; } else { ArrayList\u0026lt;Object\u0026gt; arrayResult = new ArrayList\u0026lt;\u0026gt;(); if (list != null) { arrayResult.addAll(list); } else { arrayResult.add(newValue); } return arrayResult; } } } 自定义策略示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 // 自定义Map合并策略 public class MapMergeStrategy implements KeyStrategy { @Override public Object apply(Object oldValue, Object newValue) { if (oldValue instanceof Map \u0026amp;\u0026amp; newValue instanceof Map) { Map\u0026lt;String, Object\u0026gt; merged = new HashMap\u0026lt;\u0026gt;((Map) oldValue); merged.putAll((Map) newValue); return merged; } return newValue; // 默认替换 } } // 自定义字符串连接策略 public class StringConcatStrategy implements KeyStrategy { private final String separator; public StringConcatStrategy(String separator) { this.separator = separator; } @Override public Object apply(Object oldValue, Object newValue) { if (oldValue instanceof String \u0026amp;\u0026amp; newValue instanceof String) { return oldValue + separator + newValue; } return newValue; } } 策略工厂模式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public class StrategyFactory { public static KeyStrategyFactory createDefaultFactory() { return () -\u0026gt; { Map\u0026lt;String, KeyStrategy\u0026gt; strategies = new HashMap\u0026lt;\u0026gt;(); strategies.put(\u0026#34;messages\u0026#34;, new AppendStrategy()); strategies.put(\u0026#34;input\u0026#34;, new ReplaceStrategy()); strategies.put(\u0026#34;output\u0026#34;, new ReplaceStrategy()); return strategies; }; } public static KeyStrategyFactory createCustomFactory(Map\u0026lt;String, KeyStrategy\u0026gt; customStrategies) { return () -\u0026gt; { Map\u0026lt;String, KeyStrategy\u0026gt; strategies = new HashMap\u0026lt;\u0026gt;(); // 添加默认策略 strategies.put(\u0026#34;messages\u0026#34;, new AppendStrategy()); strategies.put(\u0026#34;input\u0026#34;, new ReplaceStrategy()); // 覆盖自定义策略 strategies.putAll(customStrategies); return strategies; }; } } 3.3 Node (节点) Node是工作流的功能模块，每个节点就像一个专门的工作站，负责执行特定的业务逻辑。Node的设计遵循单一职责原则，每个节点只关注一件事情，这样既保证了代码的可维护性，也提高了节点的可复用性。\n执行特性：Node支持同步和异步两种执行模式，还支持并行执行多个子任务。这种灵活的执行机制让Node既能处理简单的数据转换，也能处理复杂的外部服务调用，满足各种性能要求。\n3.3.1 节点执行流程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 flowchart TD A[节点开始执行] --\u0026gt; B[获取ActionFactory] B --\u0026gt; C[应用CompileConfig] C --\u0026gt; D[创建AsyncNodeActionWithConfig] D --\u0026gt; E[调用apply方法] E --\u0026gt; F[传入OverAllState和RunnableConfig] F --\u0026gt; G[执行业务逻辑] G --\u0026gt; H[返回CompletableFuture] H --\u0026gt; I{是否包含AsyncGenerator?} I --\u0026gt;|是| J[处理流式输出] I --\u0026gt;|否| K[直接返回结果] J --\u0026gt; L[状态更新] K --\u0026gt; L L --\u0026gt; M[节点执行完成] subgraph \u0026#34;节点类型\u0026#34; N1[LlmNode\u0026lt;br/\u0026gt;大模型调用] N2[ToolNode\u0026lt;br/\u0026gt;工具调用] N3[QuestionClassifierNode\u0026lt;br/\u0026gt;文本分类] N4[ParallelNode\u0026lt;br/\u0026gt;并行执行] N5[SubGraphNode\u0026lt;br/\u0026gt;子图节点] end D --\u0026gt; N1 D --\u0026gt; N2 D --\u0026gt; N3 D --\u0026gt; N4 D --\u0026gt; N5 3.3.2 节点类型层次结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 classDiagram class Node { +String id +ActionFactory actionFactory +apply(CompileConfig config) AsyncNodeActionWithConfig +isParallel() boolean +withIdUpdated(Function newId) Node } class ParallelNode { +String PARALLEL_PREFIX +List~AsyncNodeActionWithConfig~ actions +Map~String,KeyStrategy~ channels +isParallel() boolean } class SubStateGraphNode { +String id +StateGraph subGraph +formatId(String nodeId) String } class SubCompiledGraphNode { +String id +CompiledGraph subGraph +formatId(String nodeId) String } class CommandNode { +String id +AsyncCommandAction action +Map~String,String~ mappings } Node \u0026lt;|-- ParallelNode Node \u0026lt;|-- SubStateGraphNode Node \u0026lt;|-- SubCompiledGraphNode Node \u0026lt;|-- CommandNode 3.3.3 并行节点处理机制 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 sequenceDiagram participant PNode as ParallelNode participant Action1 as Action1 participant Action2 as Action2 participant Action3 as Action3 participant CF as CompletableFuture PNode-\u0026gt;\u0026gt;Action1: apply(state, config) PNode-\u0026gt;\u0026gt;Action2: apply(state, config) PNode-\u0026gt;\u0026gt;Action3: apply(state, config) Action1--\u0026gt;\u0026gt;CF: CompletableFuture1 Action2--\u0026gt;\u0026gt;CF: CompletableFuture2 Action3--\u0026gt;\u0026gt;CF: CompletableFuture3 CF-\u0026gt;\u0026gt;CF: CompletableFuture.allOf() CF-\u0026gt;\u0026gt;PNode: 所有任务完成 PNode-\u0026gt;\u0026gt;PNode: 合并结果 PNode--\u0026gt;\u0026gt;PNode: 返回合并后的状态 3.4 Edge (边) Edge是工作流的路由器，它决定了数据在节点之间的流转路径。Edge不仅仅是简单的连接线，它还包含了复杂的条件判断逻辑，能够根据当前状态动态决定下一步的执行路径。\n智能路由：Edge支持静态路由和动态路由两种模式。静态边提供固定的转换路径，而条件边则可以根据状态内容进行智能判断，这种设计让工作流具备了强大的条件分支能力，能够处理各种复杂的业务逻辑。\n3.4.1 边的类型与结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 classDiagram class Edge { +String sourceId +EdgeValue targetValue +validate(Nodes nodes) +List~EdgeValue~ targets() } class EdgeValue { \u0026lt;\u0026lt;sealed interface\u0026gt;\u0026gt; +String id() +EdgeCondition value() } class EdgeValue_Const { +String value } class EdgeValue_Condition { +EdgeCondition condition +Map~String,String~ mappings } class EdgeCondition { +AsyncCommandAction action +Map~String,String~ mappings +apply(OverAllState state, RunnableConfig config) CompletableFuture~Command~ } Edge --\u0026gt; EdgeValue EdgeValue \u0026lt;|-- EdgeValue_Const EdgeValue \u0026lt;|-- EdgeValue_Condition EdgeValue_Condition --\u0026gt; EdgeCondition 3.4.2 条件边路由流程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 flowchart TD A[到达条件边] --\u0026gt; B[获取EdgeCondition] B --\u0026gt; C[执行condition.apply] C --\u0026gt; D[获取Command结果] D --\u0026gt; E[提取gotoNode值] E --\u0026gt; F[在mappings中查找] F --\u0026gt; G{找到映射?} G --\u0026gt;|是| H[返回目标节点ID] G --\u0026gt;|否| I[抛出映射缺失异常] H --\u0026gt; J[跳转到目标节点] subgraph \u0026#34;条件评估示例\u0026#34; K[FeedbackQuestionDispatcher] K --\u0026gt; L[分析classifier_output] L --\u0026gt; M{包含positive?} M --\u0026gt;|是| N[返回positive] M --\u0026gt;|否| O[返回negative] end C --\u0026gt; K 3.4.3 边验证机制 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 public class Edge { public void validate(Nodes nodes) throws GraphStateException { // 验证源节点存在 if (!nodes.anyMatchById(sourceId)) { throw Errors.missingNodeInEdgeMapping.exception(sourceId); } // 验证目标节点 for (EdgeValue target : targets()) { if (target.id() != null) { // 静态边：直接验证目标节点 if (!nodes.anyMatchById(target.id()) \u0026amp;\u0026amp; !END.equals(target.id())) { throw Errors.missingNodeInEdgeMapping.exception(target.id()); } } else if (target.value() != null) { // 条件边：验证映射中的所有目标节点 for (String targetNodeId : target.value().mappings().values()) { if (!nodes.anyMatchById(targetNodeId) \u0026amp;\u0026amp; !END.equals(targetNodeId)) { throw Errors.missingNodeInEdgeMapping.exception(targetNodeId); } } } } } } 3.5 CompiledGraph (编译图) CompiledGraph是工作流的执行引擎，它将StateGraph的静态定义转换为高效的运行时代码。就像将高级语言编译成机器码一样，CompiledGraph对工作流进行了各种优化，包括节点预处理、边路由优化、状态管理策略等。\n运行时优化：CompiledGraph在编译过程中会进行多种优化，如节点依赖分析、并行执行规划、状态访问优化等，这些优化确保了工作流在运行时的高效性和稳定性。\n3.5.1 编译过程详解 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 flowchart TD A[StateGraph.compile] --\u0026gt; B[创建CompiledGraph] B --\u0026gt; C[处理节点和边] C --\u0026gt; D[检查中断配置] D --\u0026gt; E[创建节点映射] E --\u0026gt; F[创建边映射] F --\u0026gt; G[处理子图节点] G --\u0026gt; H[生成最终CompiledGraph] subgraph \u0026#34;ProcessedNodesEdgesAndConfig\u0026#34; I[处理普通节点] J[处理子图节点] K[处理并行节点] L[处理中断配置] end C --\u0026gt; I C --\u0026gt; J C --\u0026gt; K C --\u0026gt; L 3.5.2 AsyncNodeGenerator执行机制 AsyncNodeGenerator是工作流执行的核心状态机，它负责推动整个工作流的运行。AsyncNodeGenerator采用了基于迭代器的设计模式，每次调用next()方法都会执行一个步骤，这种设计既支持同步执行，也支持异步流式处理。\n执行控制：AsyncNodeGenerator内置了完善的执行控制机制，包括最大迭代次数检查、中断条件处理、错误恢复等，确保工作流在各种情况下都能稳定运行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 stateDiagram-v2 [*] --\u0026gt; Initializing: 创建AsyncNodeGenerator Initializing --\u0026gt; CheckingResume: 检查是否恢复模式 CheckingResume --\u0026gt; Resuming: 恢复模式 CheckingResume --\u0026gt; Starting: 正常启动 Resuming --\u0026gt; LoadingCheckpoint: 加载检查点 LoadingCheckpoint --\u0026gt; RestoringState: 恢复状态 RestoringState --\u0026gt; Ready: 准备执行 Starting --\u0026gt; InitializingState: 初始化状态 InitializingState --\u0026gt; Ready: 准备执行 Ready --\u0026gt; Executing: 开始执行 Executing --\u0026gt; CheckingIteration: 检查迭代次数 CheckingIteration --\u0026gt; MaxIterationReached: 达到最大迭代 CheckingIteration --\u0026gt; CheckingInterrupt: 检查中断 CheckingInterrupt --\u0026gt; Interrupted: 中断执行 CheckingInterrupt --\u0026gt; ExecutingNode: 执行节点 ExecutingNode --\u0026gt; UpdatingState: 更新状态 UpdatingState --\u0026gt; SavingCheckpoint: 保存检查点 SavingCheckpoint --\u0026gt; DeterminingNext: 确定下一节点 DeterminingNext --\u0026gt; CheckingEnd: 检查是否结束 CheckingEnd --\u0026gt; Completed: 执行完成 CheckingEnd --\u0026gt; Executing: 继续执行 MaxIterationReached --\u0026gt; [*] Interrupted --\u0026gt; [*] Completed --\u0026gt; [*] 3.5.3 状态流转核心逻辑 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 public class AsyncNodeGenerator\u0026lt;Output extends NodeOutput\u0026gt; implements AsyncGenerator\u0026lt;Output\u0026gt; { @Override public Data\u0026lt;Output\u0026gt; next() { try { // 1. 检查最大迭代次数 if (++iteration \u0026gt; maxIterations) { return Data.error(new IllegalStateException( format(\u0026#34;Maximum number of iterations (%d) reached!\u0026#34;, maxIterations))); } // 2. 检查是否结束 if (nextNodeId == null \u0026amp;\u0026amp; currentNodeId == null) { return releaseThread().map(Data::\u0026lt;Output\u0026gt;done) .orElseGet(() -\u0026gt; Data.done(currentState)); } // 3. 处理START节点 if (START.equals(currentNodeId)) { doListeners(START, null); var nextNodeCommand = getEntryPoint(currentState, config); nextNodeId = nextNodeCommand.gotoNode(); currentState = nextNodeCommand.update(); var cp = addCheckpoint(config, START, currentState, nextNodeId); var output = (cp.isPresent() \u0026amp;\u0026amp; config.streamMode() == StreamMode.SNAPSHOTS) ? buildStateSnapshot(cp.get()) : buildNodeOutput(currentNodeId); currentNodeId = nextNodeId; return Data.of(output); } // 4. 处理END节点 if (END.equals(nextNodeId)) { nextNodeId = null; currentNodeId = null; doListeners(END, null); return Data.of(buildNodeOutput(END)); } // 5. 检查中断条件 if (shouldInterruptAfter(currentNodeId, nextNodeId)) { return Data.done(currentNodeId); } if (shouldInterruptBefore(nextNodeId, currentNodeId)) { return Data.done(currentNodeId); } // 6. 执行节点 currentNodeId = nextNodeId; var action = nodes.get(currentNodeId); return Data.of(evaluateAction(action, overAllState)); } catch (Exception e) { return Data.error(e); } } } 4. 预定义组件与工具箱 4.1 预定义节点类型 Spring AI Alibaba Graph提供了丰富的预定义节点工具箱，这些节点就像乐高积木一样，开发者可以通过组合这些预定义节点快速构建复杂的AI应用。每个预定义节点都经过了精心设计和优化，不仅功能强大，而且易于使用。\n设计理念：预定义节点的设计遵循了\u0026quot;开箱即用\u0026quot;的原则，开发者只需要提供必要的配置参数，就能立即使用这些节点的强大功能，大大降低了AI应用的开发门槛。\n4.1.1 节点分类架构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 graph TB subgraph \u0026#34;预定义节点体系\u0026#34; A[NodeAction接口] A --\u0026gt; B[LlmNode\u0026lt;br/\u0026gt;大模型节点] A --\u0026gt; C[ToolNode\u0026lt;br/\u0026gt;工具节点] A --\u0026gt; D[QuestionClassifierNode\u0026lt;br/\u0026gt;分类节点] A --\u0026gt; E[KnowledgeRetrievalNode\u0026lt;br/\u0026gt;检索节点] A --\u0026gt; F[ParameterParsingNode\u0026lt;br/\u0026gt;参数解析节点] A --\u0026gt; G[McpNode\u0026lt;br/\u0026gt;MCP协议节点] A --\u0026gt; H[AnswerNode\u0026lt;br/\u0026gt;答案生成节点] A --\u0026gt; I[ListOperatorNode\u0026lt;br/\u0026gt;列表操作节点] A --\u0026gt; J[CodeExecutorNode\u0026lt;br/\u0026gt;代码执行节点] end subgraph \u0026#34;节点特性\u0026#34; K[Builder模式构建] L[状态驱动] M[异步支持] N[流式处理] O[错误处理] end B --\u0026gt; K C --\u0026gt; L D --\u0026gt; M E --\u0026gt; N F --\u0026gt; O 4.1.2 QuestionClassifierNode - 智能分类节点 QuestionClassifierNode是工作流的智能分拣员，它能够理解文本内容并将其归类到预定义的类别中。这个节点内置了少样本学习机制，即使没有大量训练数据，也能实现准确的分类效果。\n核心优势：QuestionClassifierNode采用了提示工程的最佳实践，通过精心设计的提示词模板和少样本示例，让大语言模型能够准确理解分类任务的要求，实现高质量的文本分类。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 flowchart TD A[QuestionClassifierNode执行] --\u0026gt; B[从状态获取输入文本] B --\u0026gt; C[构建分类提示词] C --\u0026gt; D[添加少样本示例] D --\u0026gt; E[调用ChatClient] E --\u0026gt; F[解析分类结果] F --\u0026gt; G[更新状态] G --\u0026gt; H[返回分类结果] subgraph \u0026#34;提示词构建\u0026#34; I[系统提示词模板] J[分类类别列表] K[分类指令] L[少样本示例] end C --\u0026gt; I C --\u0026gt; J C --\u0026gt; K C --\u0026gt; L subgraph \u0026#34;输出格式\u0026#34; M[JSON格式] M --\u0026gt; N[keywords: 关键词列表] M --\u0026gt; O[category_name: 分类名称] end F --\u0026gt; M 应用场景：QuestionClassifierNode特别适合客服系统的问题分类、内容审核的类型判断、邮件的自动分拣等场景，能够显著提高业务处理的自动化程度。\n1 2 3 4 5 6 7 8 9 QuestionClassifierNode classifier = QuestionClassifierNode.builder() .chatClient(chatClient) .inputTextKey(\u0026#34;input\u0026#34;) .outputKey(\u0026#34;classifier_output\u0026#34;) .categories(List.of(\u0026#34;positive feedback\u0026#34;, \u0026#34;negative feedback\u0026#34;)) .classificationInstructions(List.of( \u0026#34;Try to understand the user\u0026#39;s feeling when giving feedback.\u0026#34; )) .build(); 核心实现原理：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 @Override public Map\u0026lt;String, Object\u0026gt; apply(OverAllState state) throws Exception { // 1. 从状态获取输入文本 if (StringUtils.hasLength(inputTextKey)) { this.inputText = (String) state.value(inputTextKey).orElse(this.inputText); } // 2. 构建少样本学习消息 List\u0026lt;Message\u0026gt; messages = new ArrayList\u0026lt;\u0026gt;(); messages.add(new UserMessage(QUESTION_CLASSIFIER_USER_PROMPT_1)); messages.add(new AssistantMessage(QUESTION_CLASSIFIER_ASSISTANT_PROMPT_1)); messages.add(new UserMessage(QUESTION_CLASSIFIER_USER_PROMPT_2)); messages.add(new AssistantMessage(QUESTION_CLASSIFIER_ASSISTANT_PROMPT_2)); // 3. 调用大模型进行分类 ChatResponse response = chatClient.prompt() .system(systemPromptTemplate.render(Map.of( \u0026#34;inputText\u0026#34;, inputText, \u0026#34;categories\u0026#34;, categories, \u0026#34;classificationInstructions\u0026#34;, classificationInstructions))) .user(inputText) .messages(messages) .call() .chatResponse(); // 4. 返回分类结果 Map\u0026lt;String, Object\u0026gt; updatedState = new HashMap\u0026lt;\u0026gt;(); updatedState.put(outputKey, response.getResult().getOutput().getText()); return updatedState; } 4.1.3 LlmNode - 大模型调用节点 LlmNode是工作流的智能大脑，它封装了与大语言模型的所有交互逻辑，让开发者可以轻松地在工作流中使用AI的强大能力。LlmNode不仅支持简单的文本生成，还支持复杂的对话管理和流式输出。\n智能特性：LlmNode内置了提示词模板引擎，支持动态参数替换，还能管理完整的对话历史，这些特性让它能够处理各种复杂的AI交互场景。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 flowchart TD A[LlmNode执行] --\u0026gt; B[初始化节点状态] B --\u0026gt; C{是否流式模式?} C --\u0026gt;|是| D[创建流式响应] C --\u0026gt;|否| E[创建同步响应] D --\u0026gt; F[构建StreamingChatGenerator] F --\u0026gt; G[返回AsyncGenerator] E --\u0026gt; H[调用ChatClient] H --\u0026gt; I[获取响应结果] I --\u0026gt; J[更新消息状态] G --\u0026gt; K[流式输出处理] J --\u0026gt; L[同步结果返回] subgraph \u0026#34;状态初始化\u0026#34; M[userPromptKey → userPrompt] N[systemPromptKey → systemPrompt] O[paramsKey → params] P[messagesKey → messages] end B --\u0026gt; M B --\u0026gt; N B --\u0026gt; O B --\u0026gt; P subgraph \u0026#34;模板渲染\u0026#34; Q[PromptTemplate.render] Q --\u0026gt; R[参数替换] end M --\u0026gt; Q 流式处理优势：LlmNode原生支持流式输出，这意味着用户可以实时看到AI的生成过程，而不需要等待完整的响应，大大提升了用户体验。\n1 2 3 4 5 6 7 8 LlmNode llmNode = LlmNode.builder() .chatClient(chatClient) .systemPromptTemplate(\u0026#34;You are a helpful assistant.\u0026#34;) .userPromptTemplate(\u0026#34;Please process: {input}\u0026#34;) .messagesKey(\u0026#34;messages\u0026#34;) .outputKey(\u0026#34;llm_response\u0026#34;) .stream(true) // 启用流式输出 .build(); 核心特性：\n模板支持：支持系统提示词和用户提示词模板 消息历史：支持消息历史管理 流式输出：原生支持流式处理 参数渲染：支持动态参数替换 4.1.4 ToolNode - 工具调用节点 ToolNode是工作流的万能工具箱，它让AI能够调用外部工具和API，极大地扩展了AI的能力边界。ToolNode不仅能执行单个工具调用，还能并行执行多个工具，显著提高了处理效率。\n核心价值：ToolNode将AI从纯文本生成扩展到了实际的行动能力，让AI能够查询数据库、调用API、执行计算等，真正实现了AI Agent的概念。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 sequenceDiagram participant TN as ToolNode participant State as OverAllState participant AM as AssistantMessage participant TC as ToolCallback participant TR as ToolResponse TN-\u0026gt;\u0026gt;State: 获取llm_response或messages State--\u0026gt;\u0026gt;TN: 返回AssistantMessage TN-\u0026gt;\u0026gt;AM: 检查是否有工具调用 AM--\u0026gt;\u0026gt;TN: 返回ToolCall列表 loop 遍历每个ToolCall TN-\u0026gt;\u0026gt;TC: 执行工具调用 TC--\u0026gt;\u0026gt;TN: 返回工具结果 end TN-\u0026gt;\u0026gt;TR: 构建ToolResponseMessage TR--\u0026gt;\u0026gt;State: 更新messages状态 灵活性设计：ToolNode支持各种类型的工具调用，从简单的函数调用到复杂的API集成，都能轻松处理，这种灵活性让AI应用能够适应各种业务场景。\n1 2 3 4 5 ToolNode toolNode = ToolNode.builder() .toolCallbacks(toolCallbacks) .llmResponseKey(\u0026#34;llm_response\u0026#34;) .outputKey(\u0026#34;tool_response\u0026#34;) .build(); 执行机制：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @Override public Map\u0026lt;String, Object\u0026gt; apply(OverAllState state) throws Exception { // 1. 获取助手消息（包含工具调用） this.assistantMessage = (AssistantMessage) state.value(this.llmResponseKey) .orElseGet(() -\u0026gt; { List\u0026lt;Message\u0026gt; messages = (List\u0026lt;Message\u0026gt;) state.value(\u0026#34;messages\u0026#34;).orElseThrow(); return messages.get(messages.size() - 1); }); // 2. 执行工具调用 ToolResponseMessage toolResponseMessage = executeFunction(assistantMessage, state); // 3. 返回工具响应 Map\u0026lt;String, Object\u0026gt; updatedState = new HashMap\u0026lt;\u0026gt;(); updatedState.put(\u0026#34;messages\u0026#34;, toolResponseMessage); if (StringUtils.hasLength(this.outputKey)) { updatedState.put(this.outputKey, toolResponseMessage); } return updatedState; } 4.1.5 KnowledgeRetrievalNode - 知识检索节点 KnowledgeRetrievalNode是工作流的知识专家，它能够从庞大的知识库中快速找到与问题相关的信息，为AI提供准确的背景知识。这个节点结合了向量检索和重排序技术，确保检索结果的准确性和相关性。\n技术优势：KnowledgeRetrievalNode采用了先进的RAG（检索增强生成）技术，通过向量相似度计算找到相关文档，再通过重排序模型进一步优化结果质量，这种两阶段的设计确保了检索的精准性。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 flowchart TD A[KnowledgeRetrievalNode执行] --\u0026gt; B[获取查询文本] B --\u0026gt; C[向量检索] C --\u0026gt; D[相似度过滤] D --\u0026gt; E{启用重排序?} E --\u0026gt;|是| F[调用重排序模型] E --\u0026gt;|否| G[直接返回结果] F --\u0026gt; H[重排序结果] H --\u0026gt; I[构建检索结果] G --\u0026gt; I I --\u0026gt; J[更新状态] subgraph \u0026#34;检索配置\u0026#34; K[topK: 返回数量] L[similarityThreshold: 相似度阈值] M[enableRanker: 是否重排序] N[rerankModel: 重排序模型] end C --\u0026gt; K D --\u0026gt; L F --\u0026gt; M F --\u0026gt; N 应用价值：KnowledgeRetrievalNode让AI能够基于企业的私有知识库回答问题，这对于构建企业级AI助手、智能客服等应用具有重要意义。\n1 2 3 4 5 6 7 8 9 KnowledgeRetrievalNode retrievalNode = KnowledgeRetrievalNode.builder() .vectorStore(vectorStore) .userPromptKey(\u0026#34;query\u0026#34;) .topK(5) .similarityThreshold(0.7) .enableRanker(true) .rerankModel(rerankModel) .outputKey(\u0026#34;retrieved_docs\u0026#34;) .build(); 4.2 预定义Agent类型 4.2.1 ReactAgent - 反应式Agent ReactAgent是工作流的智能决策者，它实现了经典的ReAct（Reasoning and Acting）模式，能够根据当前情况动态决定是否需要调用工具。ReactAgent就像一个有经验的助手，知道什么时候需要查找信息，什么时候可以直接回答。\n核心思想：ReactAgent将推理和行动结合在一起，让AI不仅能思考，还能行动。这种设计让AI具备了解决复杂问题的能力，能够通过多轮推理和工具调用来完成复杂任务。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 stateDiagram-v2 [*] --\u0026gt; START START --\u0026gt; LLM: 开始推理 LLM --\u0026gt; Think: 分析是否需要工具 Think --\u0026gt; Tool: 需要工具 Think --\u0026gt; END: 不需要工具 Tool --\u0026gt; LLM: 工具执行完成 note right of Think 检查AssistantMessage 是否包含ToolCalls end note note right of Tool 执行工具调用 获取外部信息 end note 智能循环：ReactAgent的执行过程是一个智能循环，每次循环都会评估当前状态，决定下一步行动，这种设计让AI能够处理各种复杂和动态的任务场景。\n1 2 3 4 5 6 7 8 9 ReactAgent reactAgent = new ReactAgent( \u0026#34;weatherAgent\u0026#34;, chatClient, toolCallbacks, 10 // 最大迭代次数 ); // 编译并使用 CompiledGraph compiledGraph = reactAgent.getAndCompileGraph(); 内部图结构构建：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 private StateGraph initGraph() throws GraphStateException { StateGraph graph = new StateGraph(name, this.keyStrategyFactory); // 添加核心节点 graph.addNode(\u0026#34;llm\u0026#34;, node_async(this.llmNode)); graph.addNode(\u0026#34;tool\u0026#34;, node_async(this.toolNode)); // 构建执行流程 graph.addEdge(START, \u0026#34;llm\u0026#34;) .addConditionalEdges(\u0026#34;llm\u0026#34;, edge_async(this::think), Map.of(\u0026#34;continue\u0026#34;, \u0026#34;tool\u0026#34;, \u0026#34;end\u0026#34;, END)) .addEdge(\u0026#34;tool\u0026#34;, \u0026#34;llm\u0026#34;); return graph; } // 决策逻辑 private String think(OverAllState state) { if (iterations \u0026gt; max_iterations) { return \u0026#34;end\u0026#34;; } List\u0026lt;Message\u0026gt; messages = (List\u0026lt;Message\u0026gt;) state.value(\u0026#34;messages\u0026#34;).orElseThrow(); AssistantMessage message = (AssistantMessage) messages.get(messages.size() - 1); // 检查是否有工具调用 return message.hasToolCalls() ? \u0026#34;continue\u0026#34; : \u0026#34;end\u0026#34;; } 4.2.2 ReflectAgent - 反思Agent ReflectAgent是工作流的质量监督者，它实现了反思模式，能够对自己的输出进行评估和改进。ReflectAgent就像一个严格的编辑，会反复检查和修改内容，直到达到满意的质量标准。\n自我改进机制：ReflectAgent采用了双节点协作的设计，一个节点负责生成内容，另一个节点负责评估质量，通过多轮迭代不断提升输出质量。这种设计让AI具备了自我完善的能力。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 graph TD A[START] --\u0026gt; B[Graph节点\u0026lt;br/\u0026gt;生成内容] B --\u0026gt; C[检查迭代次数] C --\u0026gt; D{达到最大迭代?} D --\u0026gt;|是| E[END] D --\u0026gt;|否| F[Reflection节点\u0026lt;br/\u0026gt;评估质量] F --\u0026gt; G[检查最后消息类型] G --\u0026gt; H{是用户消息?} H --\u0026gt;|是| B H --\u0026gt;|否| E subgraph \u0026#34;反思循环\u0026#34; I[生成初始内容] J[反思评估] K[基于反思改进] L[重复直到满意] end B --\u0026gt; I F --\u0026gt; J B --\u0026gt; K G --\u0026gt; L 质量保证：ReflectAgent特别适合对输出质量要求较高的场景，如文档写作、代码生成、创意内容等，通过反思机制确保最终输出的质量。\n1 2 3 4 5 ReflectAgent reflectAgent = ReflectAgent.builder() .graph(assistantGraphNode) // 生成节点 .reflection(judgeGraphNode) // 评判节点 .maxIterations(3) .build(); 执行流程详解：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 public StateGraph createReflectionGraph(NodeAction graph, NodeAction reflection, int maxIterations) { StateGraph stateGraph = new StateGraph(() -\u0026gt; { HashMap\u0026lt;String, KeyStrategy\u0026gt; keyStrategyHashMap = new HashMap\u0026lt;\u0026gt;(); keyStrategyHashMap.put(MESSAGES, new ReplaceStrategy()); keyStrategyHashMap.put(ITERATION_NUM, new ReplaceStrategy()); return keyStrategyHashMap; }) .addNode(GRAPH_NODE_ID, node_async(graph)) .addNode(REFLECTION_NODE_ID, node_async(reflection)) .addEdge(START, GRAPH_NODE_ID) .addConditionalEdges(GRAPH_NODE_ID, edge_async(this::graphCount), Map.of(REFLECTION_NODE_ID, REFLECTION_NODE_ID, END, END)) .addConditionalEdges(REFLECTION_NODE_ID, edge_async(this::apply), Map.of(GRAPH_NODE_ID, GRAPH_NODE_ID, END, END)); return stateGraph; } // 迭代次数检查 private String graphCount(OverAllState state) { int iterationNum = state.value(ITERATION_NUM, Integer.class).orElse(0); state.updateState(Map.of(ITERATION_NUM, iterationNum + 1)); return iterationNum \u0026gt;= maxIterations ? END : REFLECTION_NODE_ID; } // 消息类型检查 private String apply(OverAllState state) { List\u0026lt;Message\u0026gt; messages = state.value(MESSAGES, List.class).orElse(new ArrayList\u0026lt;\u0026gt;()); if (messages.isEmpty()) return END; Message lastMessage = messages.get(messages.size() - 1); return lastMessage instanceof UserMessage ? GRAPH_NODE_ID : END; } 4.2.3 ReactAgentWithHuman - 人机协作Agent ReactAgentWithHuman是工作流的人机协作专家，它在ReactAgent的基础上增加了人工干预能力，让AI和人类能够协作完成复杂任务。这种设计特别适合需要人工审核、决策确认或专业判断的场景。\n协作机制：ReactAgentWithHuman内置了完善的中断和恢复机制，当遇到需要人工干预的情况时，系统会自动暂停执行，等待人工处理，然后无缝恢复执行。这种设计让人机协作变得自然而流畅。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 flowchart TD A[START] --\u0026gt; B[Agent节点\u0026lt;br/\u0026gt;LLM推理] B --\u0026gt; C[Human节点\u0026lt;br/\u0026gt;人工检查] C --\u0026gt; D{人工决策} D --\u0026gt;|继续Agent| B D --\u0026gt;|调用工具| E[Tool节点\u0026lt;br/\u0026gt;工具执行] D --\u0026gt;|结束| F[END] E --\u0026gt; B subgraph \u0026#34;Human节点逻辑\u0026#34; G[检查中断条件] H[等待人工反馈] I[根据反馈决策] end C --\u0026gt; G C --\u0026gt; H C --\u0026gt; I subgraph \u0026#34;中断恢复机制\u0026#34; J[保存状态快照] K[等待人工处理] L[加载状态恢复] M[继续执行] end H --\u0026gt; J J --\u0026gt; K K --\u0026gt; L L --\u0026gt; M 人机协作实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 private StateGraph initGraph() throws GraphStateException { StateGraph graph = new StateGraph(name, keyStrategyFactory) .addNode(\u0026#34;agent\u0026#34;, node_async(this.llmNode)) .addNode(\u0026#34;human\u0026#34;, node_async(this.humanNode)) .addNode(\u0026#34;tool\u0026#34;, node_async(this.toolNode)) .addEdge(START, \u0026#34;agent\u0026#34;) .addEdge(\u0026#34;agent\u0026#34;, \u0026#34;human\u0026#34;) .addConditionalEdges(\u0026#34;human\u0026#34;, edge_async(humanNode::think), Map.of(\u0026#34;agent\u0026#34;, \u0026#34;agent\u0026#34;, \u0026#34;tool\u0026#34;, \u0026#34;tool\u0026#34;, \u0026#34;end\u0026#34;, END)) .addEdge(\u0026#34;tool\u0026#34;, \u0026#34;agent\u0026#34;); return graph; } // HumanNode的决策逻辑 public String think(OverAllState state) { // 检查是否需要中断 if (shouldInterruptFunc != null \u0026amp;\u0026amp; shouldInterruptFunc.apply(state)) { // 设置中断消息，等待人工处理 state.setInterruptMessage(\u0026#34;等待人工审批\u0026#34;); return \u0026#34;human_interrupt\u0026#34;; } // 检查是否需要工具调用 List\u0026lt;Message\u0026gt; messages = (List\u0026lt;Message\u0026gt;) state.value(\u0026#34;messages\u0026#34;).orElse(new ArrayList\u0026lt;\u0026gt;()); if (!messages.isEmpty()) { Message lastMessage = messages.get(messages.size() - 1); if (lastMessage instanceof AssistantMessage \u0026amp;\u0026amp; ((AssistantMessage) lastMessage).hasToolCalls()) { return \u0026#34;tool\u0026#34;; } } return \u0026#34;agent\u0026#34;; } 5. 高级特性与扩展能力 5.1 可观测性 Spring AI Alibaba Graph提供了企业级的全链路观测能力，基于OpenTelemetry和Micrometer标准，实现了从Graph执行到模型调用的完整追踪。\n5.1.1 核心特性 全链路可观测：实时追踪每个节点的输入、输出和状态变化 流式数据采集：支持异步、并行、流式节点的观测 异常溯源：快速定位异常节点和数据 多平台支持：兼容Langfuse、Jaeger、Zipkin、Prometheus等主流平台 5.1.2 快速接入 使用观测性Starter：\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud.ai\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-ai-alibaba-starter-graph-observation\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-ai-alibaba.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 1 2 3 4 5 @Bean public CompiledGraph compiledGraph(StateGraph observabilityGraph, CompileConfig observationCompileConfig) throws GraphStateException { return observabilityGraph.compile(observationCompileConfig); } 5.1.3 详细文档 关于Spring AI Alibaba Graph观测性的完整架构设计、实现原理、配置方式、最佳实践等详细内容，请参考官方观测性文档：\n📚 Graph观测性完整指南：Spring AI Alibaba Graph观测性设计与实现\n该文档涵盖：\n观测性设计理念与架构 并行与流式观测实现 多平台集成配置 Langfuse等可视化平台使用 最佳实践与扩展建议 🔗 完整示例代码：graph-observability-langfuse\n5.2 并行节点与流式处理 5.2.1 并行节点的两种创建方式 Spring AI Alibaba Graph提供了两种创建并行节点的方式，这两种方式在底层实现上有所不同，但都能实现并行处理的效果。\n方式一：直接创建ParallelNode 直接创建一个ParallelNode实例，并将其注册到StateGraph中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // 创建并行任务列表 List\u0026lt;AsyncNodeActionWithConfig\u0026gt; parallelActions = List.of( node_async(new DataProcessingNode1()), node_async(new DataProcessingNode2()), node_async(new DataProcessingNode3()) ); // 定义状态合并策略 Map\u0026lt;String, KeyStrategy\u0026gt; channels = Map.of( \u0026#34;results\u0026#34;, new AppendStrategy(), \u0026#34;metadata\u0026#34;, new ReplaceStrategy() ); // 创建并行节点 ParallelNode parallelNode = new ParallelNode( \u0026#34;data_processing\u0026#34;, // 节点内部ID parallelActions, // 并行任务列表 channels // KeyStrategy映射 ); // 添加到StateGraph stateGraph.addNode(\u0026#34;parallel_tasks\u0026#34;, parallelNode); 方式二：通过StateGraph描述并行边 这是更常用的方式，通过添加多个指向相同目标的边来定义并行结构：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 StateGraph workflow = new StateGraph(keyStrategyFactory) .addNode(\u0026#34;source\u0026#34;, node_async(sourceNode)) .addNode(\u0026#34;task1\u0026#34;, node_async(task1Node)) .addNode(\u0026#34;task2\u0026#34;, node_async(task2Node)) .addNode(\u0026#34;task3\u0026#34;, node_async(task3Node)) .addNode(\u0026#34;merger\u0026#34;, node_async(mergerNode)) // 创建并行分支 - 从source到多个任务 .addEdge(\u0026#34;source\u0026#34;, \u0026#34;task1\u0026#34;) .addEdge(\u0026#34;source\u0026#34;, \u0026#34;task2\u0026#34;) .addEdge(\u0026#34;source\u0026#34;, \u0026#34;task3\u0026#34;) // 汇聚到merger节点 .addEdge(\u0026#34;task1\u0026#34;, \u0026#34;merger\u0026#34;) .addEdge(\u0026#34;task2\u0026#34;, \u0026#34;merger\u0026#34;) .addEdge(\u0026#34;task3\u0026#34;, \u0026#34;merger\u0026#34;) .addEdge(START, \u0026#34;source\u0026#34;) .addEdge(\u0026#34;merger\u0026#34;, END); 编译时转换机制：\n当StateGraph编译时，框架会自动检测并行边模式，并在内部创建ParallelNode：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // CompiledGraph编译过程中的处理逻辑 if (targets.size() \u0026gt; 1) { // 检测到并行边，获取所有并行目标节点的Action var actions = parallelNodeStream.get() .map(target -\u0026gt; nodes.get(target.id())) .toList(); // 自动创建ParallelNode var parallelNode = new ParallelNode(e.sourceId(), actions, keyStrategyMap); // 替换原有节点和边的映射 nodes.put(parallelNode.id(), parallelNode.actionFactory().apply(compileConfig)); edges.put(e.sourceId(), new EdgeValue(parallelNode.id())); } 5.2.2 并行节点的内部执行机制 ParallelNode的核心实现基于CompletableFuture.allOf()，实现真正的并行执行：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 public class ParallelNode extends Node { record AsyncParallelNodeAction( List\u0026lt;AsyncNodeActionWithConfig\u0026gt; actions, Map\u0026lt;String, KeyStrategy\u0026gt; channels ) implements AsyncNodeActionWithConfig { @Override public CompletableFuture\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; apply(OverAllState state, RunnableConfig config) { Map\u0026lt;String, Object\u0026gt; partialMergedStates = new HashMap\u0026lt;\u0026gt;(); Map\u0026lt;String, Object\u0026gt; asyncGenerators = new HashMap\u0026lt;\u0026gt;(); // 并行执行所有Action var futures = actions.stream() .map(action -\u0026gt; action.apply(state, config) .thenApply(partialState -\u0026gt; { // 分离普通结果和AsyncGenerator partialState.forEach((key, value) -\u0026gt; { if (value instanceof AsyncGenerator\u0026lt;?\u0026gt; || value instanceof GeneratorSubscriber) { ((List) asyncGenerators.computeIfAbsent(key, k -\u0026gt; new ArrayList\u0026lt;\u0026gt;())).add(value); } else { partialMergedStates.put(key, value); } }); // 立即更新状态 state.updateState(partialMergedStates); return action; })) .toList() .toArray(new CompletableFuture[0]); // 等待所有任务完成 return CompletableFuture.allOf(futures) .thenApply((p) -\u0026gt; CollectionUtils.isEmpty(asyncGenerators) ? state.data() : asyncGenerators); } } } 5.2.3 并行流式处理的合并机制 核心挑战：当多个并行分支都产生流式输出时，如何将这些异步流合并成统一的输出流？\nSpring AI Alibaba Graph通过AsyncGeneratorUtils.createMergedGenerator在框架内核中解决了这个复杂问题：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 flowchart TD A[并行节点启动] --\u0026gt; B[分支1: AsyncGenerator] A --\u0026gt; C[分支2: AsyncGenerator] A --\u0026gt; D[分支3: AsyncGenerator] B --\u0026gt; E[AsyncGeneratorUtils.createMergedGenerator] C --\u0026gt; E D --\u0026gt; E E --\u0026gt; F[轮询所有Generator] F --\u0026gt; G[StampedLock并发控制] G --\u0026gt; H[KeyStrategy状态合并] H --\u0026gt; I[统一输出流] subgraph \u0026#34;合并策略\u0026#34; J[ReplaceStrategy\u0026lt;br/\u0026gt;替换合并] K[AppendStrategy\u0026lt;br/\u0026gt;追加合并] L[CustomStrategy\u0026lt;br/\u0026gt;自定义合并] end H --\u0026gt; J H --\u0026gt; K H --\u0026gt; L 5.2.4 MergedGenerator核心实现 AsyncGeneratorUtils.createMergedGenerator是框架内核的核心算法，实现了多个异步流的智能合并：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 public static \u0026lt;T\u0026gt; AsyncGenerator\u0026lt;T\u0026gt; createMergedGenerator( List\u0026lt;AsyncGenerator\u0026lt;T\u0026gt;\u0026gt; generators, Map\u0026lt;String, KeyStrategy\u0026gt; keyStrategyMap) { return new AsyncGenerator\u0026lt;\u0026gt;() { // 使用StampedLock优化并发性能 private final StampedLock lock = new StampedLock(); private AtomicInteger pollCounter = new AtomicInteger(0); private Map\u0026lt;String, Object\u0026gt; mergedResult = new HashMap\u0026lt;\u0026gt;(); private final List\u0026lt;AsyncGenerator\u0026lt;T\u0026gt;\u0026gt; activeGenerators = new CopyOnWriteArrayList\u0026lt;\u0026gt;(generators); @Override public AsyncGenerator.Data\u0026lt;T\u0026gt; next() { while (true) { // 乐观读锁快速检查 long stamp = lock.tryOptimisticRead(); boolean empty = activeGenerators.isEmpty(); if (!lock.validate(stamp)) { stamp = lock.readLock(); try { empty = activeGenerators.isEmpty(); } finally { lock.unlockRead(stamp); } } if (empty) { return AsyncGenerator.Data.done(mergedResult); } // 轮询策略选择Generator final AsyncGenerator\u0026lt;T\u0026gt; current; long writeStamp = lock.writeLock(); try { final int size = activeGenerators.size(); if (size == 0) return AsyncGenerator.Data.done(mergedResult); int currentIdx = pollCounter.updateAndGet(i -\u0026gt; (i + 1) % size); current = activeGenerators.get(currentIdx); } finally { lock.unlockWrite(writeStamp); } // 在无锁状态下执行Generator AsyncGenerator.Data\u0026lt;T\u0026gt; data = current.next(); // 处理结果并更新状态 writeStamp = lock.writeLock(); try { if (!activeGenerators.contains(current)) { continue; } if (data.isDone() || data.isError()) { handleCompletedGenerator(current, data); if (activeGenerators.isEmpty()) { return AsyncGenerator.Data.done(mergedResult); } continue; } handleCompletedGenerator(current, data); return data; } finally { lock.unlockWrite(writeStamp); } } } private void handleCompletedGenerator(AsyncGenerator\u0026lt;T\u0026gt; generator, AsyncGenerator.Data\u0026lt;T\u0026gt; data) { // 移除完成的Generator if (data.isDone() || data.isError()) { activeGenerators.remove(generator); } // 使用KeyStrategy合并结果 data.resultValue().ifPresent(result -\u0026gt; { if (result instanceof Map) { Map\u0026lt;String, Object\u0026gt; mapResult = (Map\u0026lt;String, Object\u0026gt;) result; mergedResult = OverAllState.updateState(mergedResult, mapResult, keyStrategyMap); } }); } }; } 核心算法特点：\n轮询机制：通过pollCounter实现公平的轮询调度 StampedLock优化：使用乐观读锁提高并发性能 状态合并：通过KeyStrategy实现灵活的状态合并策略 线程安全：CopyOnWriteArrayList确保并发访问的安全性 5.2.5 流式输出配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 @RestController @RequestMapping(\u0026#34;/stream\u0026#34;) public class StreamingController { private final CompiledGraph compiledGraph; @GetMapping(value = \u0026#34;/process\u0026#34;, produces = MediaType.TEXT_EVENT_STREAM_VALUE) public Flux\u0026lt;ServerSentEvent\u0026lt;String\u0026gt;\u0026gt; processStream(@RequestParam String input) { return Flux.create(sink -\u0026gt; { try { AsyncGenerator\u0026lt;NodeOutput\u0026gt; generator = compiledGraph.stream( Map.of(\u0026#34;input\u0026#34;, input), RunnableConfig.builder() .threadId(UUID.randomUUID().toString()) .build() ); generator.forEachAsync(output -\u0026gt; { if (output instanceof StreamingOutput) { StreamingOutput streamingOutput = (StreamingOutput) output; String chunk = streamingOutput.chunk().toString(); sink.next(ServerSentEvent.builder(chunk).build()); } }).thenRun(() -\u0026gt; { sink.complete(); }).exceptionally(throwable -\u0026gt; { sink.error(throwable); return null; }); } catch (Exception e) { sink.error(e); } }); } } 5.3 子图节点 子图节点是工作流的模块化组件，它允许将复杂的工作流分解为可重用的子模块。子图节点就像函数调用一样，可以在主工作流中调用预定义的子工作流，实现代码复用和模块化设计。\n5.3.1 子图节点类型 Spring AI Alibaba Graph支持两种类型的子图节点：\nSubStateGraphNode - 未编译子图节点 1 2 3 4 5 6 7 8 9 10 11 12 public class SubStateGraphNode extends Node { private final StateGraph subGraph; public SubStateGraphNode(String id, StateGraph subGraph) { super(id, (config) -\u0026gt; { // 在运行时编译子图 CompiledGraph compiledSubGraph = subGraph.compile(config); return new SubGraphAction(compiledSubGraph); }); this.subGraph = subGraph; } } SubCompiledGraphNode - 预编译子图节点 1 2 3 4 5 6 7 8 public class SubCompiledGraphNode extends Node { private final CompiledGraph subGraph; public SubCompiledGraphNode(String id, CompiledGraph subGraph) { super(id, (config) -\u0026gt; new SubGraphAction(subGraph)); this.subGraph = subGraph; } } 5.3.2 子图定义与使用 定义文档处理子图：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 public class DocumentProcessingSubGraph { public static StateGraph createDocumentProcessingGraph(ChatModel chatModel) { ChatClient chatClient = ChatClient.builder(chatModel).build(); // 文档提取节点 DocumentExtractorNode extractorNode = new DocumentExtractorNode( \u0026#34;document_path\u0026#34;, \u0026#34;extracted_text\u0026#34;, List.of(\u0026#34;pdf\u0026#34;, \u0026#34;docx\u0026#34;, \u0026#34;txt\u0026#34;) ); // 文档分析节点 LlmNode analysisNode = LlmNode.builder() .chatClient(chatClient) .systemPromptTemplate(\u0026#34;你是一个文档分析专家，请分析文档内容并提取关键信息。\u0026#34;) .userPromptTemplate(\u0026#34;请分析以下文档内容：\\n{extracted_text}\u0026#34;) .outputKey(\u0026#34;analysis_result\u0026#34;) .build(); KeyStrategyFactory stateFactory = () -\u0026gt; { Map\u0026lt;String, KeyStrategy\u0026gt; strategies = new HashMap\u0026lt;\u0026gt;(); strategies.put(\u0026#34;document_path\u0026#34;, new ReplaceStrategy()); strategies.put(\u0026#34;extracted_text\u0026#34;, new ReplaceStrategy()); strategies.put(\u0026#34;analysis_result\u0026#34;, new ReplaceStrategy()); return strategies; }; return new StateGraph(\u0026#34;文档处理子图\u0026#34;, stateFactory) .addNode(\u0026#34;extractor\u0026#34;, node_async(extractorNode)) .addNode(\u0026#34;analyzer\u0026#34;, node_async(analysisNode)) .addEdge(START, \u0026#34;extractor\u0026#34;) .addEdge(\u0026#34;extractor\u0026#34;, \u0026#34;analyzer\u0026#34;) .addEdge(\u0026#34;analyzer\u0026#34;, END); } } 在主工作流中使用子图：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 @Configuration public class MainWorkflowConfiguration { @Bean public StateGraph mainWorkflow(ChatModel chatModel) { // 创建子图 StateGraph documentProcessingSubGraph = DocumentProcessingSubGraph .createDocumentProcessingGraph(chatModel); // 创建其他节点 QuestionClassifierNode classifierNode = QuestionClassifierNode.builder() .chatClient(ChatClient.builder(chatModel).build()) .inputTextKey(\u0026#34;input\u0026#34;) .outputKey(\u0026#34;classifier_output\u0026#34;) .categories(List.of(\u0026#34;document_processing\u0026#34;, \u0026#34;general_question\u0026#34;)) .build(); LlmNode generalAnswerNode = LlmNode.builder() .chatClient(ChatClient.builder(chatModel).build()) .systemPromptTemplate(\u0026#34;你是一个通用助手，请回答用户的问题。\u0026#34;) .userPromptTemplate(\u0026#34;用户问题：{input}\u0026#34;) .outputKey(\u0026#34;general_answer\u0026#34;) .build(); KeyStrategyFactory stateFactory = () -\u0026gt; { Map\u0026lt;String, KeyStrategy\u0026gt; strategies = new HashMap\u0026lt;\u0026gt;(); strategies.put(\u0026#34;input\u0026#34;, new ReplaceStrategy()); strategies.put(\u0026#34;classifier_output\u0026#34;, new ReplaceStrategy()); strategies.put(\u0026#34;document_path\u0026#34;, new ReplaceStrategy()); strategies.put(\u0026#34;extracted_text\u0026#34;, new ReplaceStrategy()); strategies.put(\u0026#34;analysis_result\u0026#34;, new ReplaceStrategy()); strategies.put(\u0026#34;general_answer\u0026#34;, new ReplaceStrategy()); return strategies; }; return new StateGraph(\u0026#34;主工作流\u0026#34;, stateFactory) .addNode(\u0026#34;classifier\u0026#34;, node_async(classifierNode)) .addNode(\u0026#34;document_processor\u0026#34;, documentProcessingSubGraph) // 添加子图 .addNode(\u0026#34;general_answer\u0026#34;, node_async(generalAnswerNode)) .addEdge(START, \u0026#34;classifier\u0026#34;) .addConditionalEdges(\u0026#34;classifier\u0026#34;, edge_async(new ClassifierDispatcher()), Map.of(\u0026#34;document_processing\u0026#34;, \u0026#34;document_processor\u0026#34;, \u0026#34;general_question\u0026#34;, \u0026#34;general_answer\u0026#34;)) .addEdge(\u0026#34;document_processor\u0026#34;, END) .addEdge(\u0026#34;general_answer\u0026#34;, END); } } 5.3.3 子图执行流程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 sequenceDiagram participant Main as 主工作流 participant SubNode as 子图节点 participant SubGraph as 子图CompiledGraph participant SubNodes as 子图内部节点 Main-\u0026gt;\u0026gt;SubNode: 执行子图节点 SubNode-\u0026gt;\u0026gt;SubGraph: 调用子图.invoke() SubGraph-\u0026gt;\u0026gt;SubNodes: 执行子图内部流程 loop 子图内部执行 SubNodes-\u0026gt;\u0026gt;SubNodes: 节点间状态流转 end SubNodes--\u0026gt;\u0026gt;SubGraph: 返回子图结果 SubGraph--\u0026gt;\u0026gt;SubNode: 返回执行结果 SubNode--\u0026gt;\u0026gt;Main: 更新主工作流状态 5.3.4 子图状态管理 状态隔离与传递：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 public class SubGraphAction implements AsyncNodeActionWithConfig { private final CompiledGraph subGraph; @Override public CompletableFuture\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; apply(OverAllState state, RunnableConfig config) { return CompletableFuture.supplyAsync(() -\u0026gt; { try { // 从主状态中提取子图需要的数据 Map\u0026lt;String, Object\u0026gt; subGraphInput = extractSubGraphInput(state); // 执行子图 Optional\u0026lt;OverAllState\u0026gt; subGraphResult = subGraph.invoke(subGraphInput, config); // 将子图结果映射回主状态 return mapSubGraphOutput(subGraphResult.orElse(null)); } catch (Exception e) { throw new RuntimeException(\u0026#34;子图执行失败\u0026#34;, e); } }); } private Map\u0026lt;String, Object\u0026gt; extractSubGraphInput(OverAllState state) { Map\u0026lt;String, Object\u0026gt; input = new HashMap\u0026lt;\u0026gt;(); // 根据子图的输入需求提取数据 state.value(\u0026#34;document_path\u0026#34;).ifPresent(value -\u0026gt; input.put(\u0026#34;document_path\u0026#34;, value)); state.value(\u0026#34;input\u0026#34;).ifPresent(value -\u0026gt; input.put(\u0026#34;input\u0026#34;, value)); return input; } private Map\u0026lt;String, Object\u0026gt; mapSubGraphOutput(OverAllState subGraphState) { Map\u0026lt;String, Object\u0026gt; output = new HashMap\u0026lt;\u0026gt;(); if (subGraphState != null) { // 将子图的输出映射到主状态 subGraphState.value(\u0026#34;analysis_result\u0026#34;).ifPresent(value -\u0026gt; output.put(\u0026#34;analysis_result\u0026#34;, value)); subGraphState.value(\u0026#34;extracted_text\u0026#34;).ifPresent(value -\u0026gt; output.put(\u0026#34;extracted_text\u0026#34;, value)); } return output; } } 5.4 中断与恢复机制 中断与恢复机制是工作流的容错保障，它让工作流能够在遇到需要人工干预或外部条件不满足时优雅地暂停执行，并在条件满足后无缝恢复。这种机制对于构建可靠的企业级AI应用至关重要。\n5.4.1 中断机制原理 1 2 3 4 5 6 7 8 9 10 11 stateDiagram-v2 [*] --\u0026gt; Executing: 开始执行 Executing --\u0026gt; CheckingInterrupt: 检查中断条件 CheckingInterrupt --\u0026gt; Interrupted: 满足中断条件 CheckingInterrupt --\u0026gt; ContinueExecuting: 继续执行 ContinueExecuting --\u0026gt; Executing: 下一个节点 Interrupted --\u0026gt; SavingSnapshot: 保存状态快照 SavingSnapshot --\u0026gt; WaitingForResume: 等待恢复 WaitingForResume --\u0026gt; LoadingSnapshot: 加载快照 LoadingSnapshot --\u0026gt; Executing: 恢复执行 Executing --\u0026gt; [*]: 执行完成 5.4.2 中断条件配置 InterruptBefore - 节点执行前中断：\n1 2 3 4 5 6 7 8 9 10 @Configuration public class InterruptConfiguration { @Bean public CompiledGraph interruptableGraph(StateGraph stateGraph) { return stateGraph.compile(CompileConfig.builder() .withInterruptBefore(\u0026#34;human_approval\u0026#34;) // 在human_approval节点前中断 .build()); } } InterruptAfter - 节点执行后中断：\n1 2 3 4 5 6 @Bean public CompiledGraph interruptableGraph(StateGraph stateGraph) { return stateGraph.compile(CompileConfig.builder() .withInterruptAfter(\u0026#34;data_processing\u0026#34;) // 在data_processing节点后中断 .build()); } 动态中断条件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public class DynamicInterruptNode implements AsyncNodeActionWithConfig { @Override public CompletableFuture\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; apply(OverAllState state, RunnableConfig config) { return CompletableFuture.supplyAsync(() -\u0026gt; { // 检查是否需要中断 if (shouldInterrupt(state)) { // 设置中断消息 state.setInterruptMessage(\u0026#34;需要人工审批，请检查数据质量\u0026#34;); Map\u0026lt;String, Object\u0026gt; result = new HashMap\u0026lt;\u0026gt;(); result.put(\u0026#34;interrupt_reason\u0026#34;, \u0026#34;data_quality_check\u0026#34;); result.put(\u0026#34;requires_approval\u0026#34;, true); return result; } // 正常处理逻辑 return processData(state); }); } private boolean shouldInterrupt(OverAllState state) { // 自定义中断条件逻辑 Double confidence = (Double) state.value(\u0026#34;confidence_score\u0026#34;).orElse(1.0); return confidence \u0026lt; 0.8; // 置信度低于80%时中断 } } 5.4.3 状态快照管理 内存快照存储：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Component public class MemorySnapshotManager { private final Map\u0026lt;String, OverAllState\u0026gt; snapshots = new ConcurrentHashMap\u0026lt;\u0026gt;(); public String saveSnapshot(OverAllState state) { String snapshotId = UUID.randomUUID().toString(); snapshots.put(snapshotId, state.snapShot().orElse(state)); return snapshotId; } public OverAllState loadSnapshot(String snapshotId) { OverAllState snapshot = snapshots.get(snapshotId); if (snapshot == null) { throw new IllegalArgumentException(\u0026#34;快照不存在: \u0026#34; + snapshotId); } return snapshot; } public void removeSnapshot(String snapshotId) { snapshots.remove(snapshotId); } } 持久化快照存储：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 @Component public class PersistentSnapshotManager { private final RedisTemplate\u0026lt;String, String\u0026gt; redisTemplate; private final ObjectMapper objectMapper; public String saveSnapshot(OverAllState state) { try { String snapshotId = UUID.randomUUID().toString(); String serializedState = objectMapper.writeValueAsString(state); redisTemplate.opsForValue().set( \u0026#34;snapshot:\u0026#34; + snapshotId, serializedState, Duration.ofHours(24) // 24小时过期 ); return snapshotId; } catch (Exception e) { throw new RuntimeException(\u0026#34;保存快照失败\u0026#34;, e); } } public OverAllState loadSnapshot(String snapshotId) { try { String serializedState = redisTemplate.opsForValue().get(\u0026#34;snapshot:\u0026#34; + snapshotId); if (serializedState == null) { throw new IllegalArgumentException(\u0026#34;快照不存在: \u0026#34; + snapshotId); } return objectMapper.readValue(serializedState, OverAllState.class); } catch (Exception e) { throw new RuntimeException(\u0026#34;加载快照失败\u0026#34;, e); } } } 6. 快速开始与实战指南 6.1 环境准备 6.1.1 依赖配置 在您的Spring Boot项目中添加Spring AI Alibaba Graph依赖：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \u0026lt;properties\u0026gt; \u0026lt;spring-ai-alibaba.version\u0026gt;1.0.0.3-SNAPSHOT\u0026lt;/spring-ai-alibaba.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud.ai\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-ai-alibaba-starter-dashscope\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-ai-alibaba.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud.ai\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-ai-alibaba-graph-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-ai-alibaba.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 6.2 快速开始流程 6.2.1 创建第一个工作流 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 @Configuration public class MyFirstGraphConfiguration { @Bean public StateGraph myFirstGraph(ChatModel chatModel) { // 1. 创建ChatClient ChatClient chatClient = ChatClient.builder(chatModel).build(); // 2. 定义节点 LlmNode welcomeNode = LlmNode.builder() .chatClient(chatClient) .systemPromptTemplate(\u0026#34;你是一个友好的助手\u0026#34;) .userPromptTemplate(\u0026#34;欢迎用户：{input}\u0026#34;) .outputKey(\u0026#34;welcome_message\u0026#34;) .build(); // 3. 定义状态策略 KeyStrategyFactory stateFactory = () -\u0026gt; { Map\u0026lt;String, KeyStrategy\u0026gt; strategies = new HashMap\u0026lt;\u0026gt;(); strategies.put(\u0026#34;input\u0026#34;, new ReplaceStrategy()); strategies.put(\u0026#34;welcome_message\u0026#34;, new ReplaceStrategy()); return strategies; }; // 4. 构建工作流 return new StateGraph(\u0026#34;我的第一个工作流\u0026#34;, stateFactory) .addNode(\u0026#34;welcome\u0026#34;, node_async(welcomeNode)) .addEdge(START, \u0026#34;welcome\u0026#34;) .addEdge(\u0026#34;welcome\u0026#34;, END); } @Bean public CompiledGraph compiledGraph(StateGraph myFirstGraph) { return myFirstGraph.compile(); } } 6.2.2 使用工作流 1 2 3 4 5 6 7 8 9 10 11 @RestController public class GraphController { private final CompiledGraph compiledGraph; @PostMapping(\u0026#34;/chat\u0026#34;) public ResponseEntity\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; chat(@RequestBody String input) { Optional\u0026lt;OverAllState\u0026gt; result = compiledGraph.invoke(Map.of(\u0026#34;input\u0026#34;, input)); return ResponseEntity.ok(result.map(OverAllState::data).orElse(Map.of())); } } 6.3 完整示例项目 为了帮助开发者更好地理解和使用Spring AI Alibaba Graph，我们提供了完整的示例项目：\n📚 官方示例仓库：spring-ai-alibaba-graph-example\n快速体验步骤：\n克隆仓库\n1 2 git clone https://github.com/springaialibaba/spring-ai-alibaba-examples.git cd spring-ai-alibaba-examples/spring-ai-alibaba-graph-example 配置环境\n1 2 # 设置DashScope API Key export AI_DASHSCOPE_API_KEY=your_api_key_here 运行示例\n1 mvn spring-boot:run 6.4 社区支持 技术支持：\nGitHub Issues：提交问题和建议 官方文档：完整文档站点 示例代码：更多示例 通过以上指南和完整的示例项目，您可以快速掌握Spring AI Alibaba Graph的使用方法，并在实际项目中高效地构建智能化应用。\n","date":"2025-07-15T00:00:00Z","permalink":"https://sixiyida.github.io/p/spring-ai-alibaba-graph-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%E4%B8%8E%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/","title":"Spring AI Alibaba Graph 使用指南与源码解读"},{"content":"LangSmith调研记录 主要功能 Observability - 可观测性\nEvaluation - 评估，指的是评估什么？\nPrompt Engineering - 提示词工具？\nObservation Trace OpenAI模型调用 1 2 3 from langsmith.wrappers import wrap_openai openai_client = wrap_openai(OpenAI()) 使用wrapper包装client，就可以接入langsmith。\nTrace整个应用 使用@traceable装饰器：\n1 2 3 4 5 6 7 8 9 10 11 12 from openai import OpenAI from langsmith import traceable from langsmith.wrappers import wrap_openai openai_client = wrap_openai(OpenAI()) def retriever(query: str): //... @traceable def rag(question): //... 注：Traceable可以装饰任何函数，装饰后就可以在LangSmith观测input和output。\nTrace召回 使用@traceable装饰器：\n1 2 3 4 @traceable(run_type=\u0026#34;retriever\u0026#34;) def retriever(query: str): results = [\u0026#34;Harrison worked at Kensho\u0026#34;] return results Feedback/Metadata 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 //MetaData //方式1：在装饰器中加元数据 @traceable(metadata={\u0026#34;llm\u0026#34;: \u0026#34;gpt-4o-mini\u0026#34;}) def rag(question): //... //方式2：在调用后加参数 import uuid run_id = str(uuid.uuid4()) rag( \u0026#34;where did harrison work\u0026#34;, langsmith_extra={\u0026#34;run_id\u0026#34;: run_id, \u0026#34;metadata\u0026#34;: {\u0026#34;user_id\u0026#34;: \u0026#34;harrison\u0026#34;}} ) //反馈与metadata相关联的feedback from langsmith import Client ls_client = Client() ls_client.create_feedback( run_id, key=\u0026#34;user-score\u0026#34;, score=1.0, ) 异步任务提交Trace 1 2 3 4 5 6 7 8 9 10 11 12 13 from langsmith import Client client = Client() @traceable(client=client) async def my_traced_func(): # Your code here... pass try: await my_traced_func() finally: await client.flush() ","date":"2025-06-26T00:00:00Z","permalink":"https://sixiyida.github.io/p/langsmith%E8%B0%83%E7%A0%94%E8%AE%B0%E5%BD%95/","title":"LangSmith调研记录"},{"content":"可观测性的三大支柱 日志Log 用于回溯和调试，略。\n指标Metrics Metrics 是系统运行状态的量化数据，通常是随时间变化的数值。比如：\n每秒处理的请求数（QPS） 请求平均耗时（RT） 服务器CPU使用率 错误请求的比例 追踪Traces Traces 用于记录一个请求在分布式系统中的完整执行路径。想象用户一次点击，可能经过网关→订单服务→库存服务→支付服务→数据库。Traces 能完整还原这个链条中每一步发生了什么、花了多久。\n核心概念：Span（跨度） 每个服务处理请求的过程被记录为一个 Span，包含：\n操作名（如createOrder） 开始/结束时间戳 关键属性（HTTP状态码、DB查询语句） 父子关系（哪个服务调用了哪个服务） Trace ID：贯穿全链路的唯一标识，用于串联所有Span 工具解释 Micrometer 核心作用： Micrometer 是 ​​Java 应用的指标埋点门面库​​，提供统一 API（如计数器、计时器），让开发者无需关心后端监控系统（Prometheus、Datadog 等）。\n数据流向： 应用代码埋点 → Micrometer 生成指标数据 → 直接输出给 Prometheus。\n示例场景： 在 Spring Boot 中配置 Micrometer 的 Prometheus 导出器，指标会通过 /actuator/prometheus 端点暴露，供 Prometheus 拉取。\nOpenTelemetry（OTel） OTel是跨语言的可观测数据采集框架，统一处理 Metrics、Traces、Logs 的生成、转换和导出。\n与Micrometer的关系：OTel SDK可以包装Micrometer注册的 MeterRegistry ，将数据通过OTLP协议导出。\nTraces场景下：\nOTel是Trace 数据的主要采集器，可将Trace数据发给SkyWalking、Jaeger等。\nPrometheus 核心作用： 专注 ​​指标（Metrics）的存储、查询和告警​​，不处理 Trace 数据。\n与 Micrometer 协作： Micrometer 将指标暴露为 Prometheus 格式 → Prometheus 定时拉取并存储 → Grafana 可视化\nSkyWalking 定位：开源APM (Application Performance Management) 系统，专注于全链路追踪（Tracing） 和拓扑分析。\n核心能力：\n**调用链追踪：**记录请求跨服务的完整路径，可视化每个环节耗时与状态（Span 数据）。 服务拓扑：自动绘制服务依赖关系图，快速定位瓶颈节点。 指标集成：支持基础资源（JVM/线程池）和链路指标（慢请求比例）。 OTLP协议 OTLP（OpenTelemetry Protocol）是OpenTelemetry项目定义的标准数据传输协议，用于在分布式系统中高效、可靠地传输遥测数据（包括追踪信息、指标和日志）。\n传输方式 协议 默认端口 适用场景 OTLP/gRPC gRPC + Protobuf 4317 高性能内部通信（如应用→收集器） OTLP/HTTP HTTP/1.1或HTTP/2 + Protobuf/JSON 4318 穿透防火墙或兼容HTTP的环境 数据路径：\n应用 →（OTLP/gRPC）→ OpenTelemetry Collector →（转换格式）→ Prometheus/Jaeger。\n阿里云ARMS 定位：企业级全栈监控产品，整合日志、指标、追踪能力。\n兼容 OpenTelemetry、SkyWalking 等开源协议。\nMicrometer和OTel集成 Springboot对于Micrometer和OTel的集成做的较好，我们主要关注Micrometer的采集即可。\nMicrometer最佳实践 Micrometer Observation API的官方推荐架构模式：\n📋 Documentation (文档定义) ↓ 定义标准\n🎛️ Convention (约定实现) ↓ 处理规则\n📦 Context (上下文数据) ↓ 数据载体\n🔧 Handler (处理器执行) ↓ 实际处理\n📊 Metrics \u0026amp; Logs (输出结果)\nContext 是实际观测数据的载体，存储需要观测的所有信息。以GraphObservation实现为例：\n1 2 3 4 5 6 7 8 9 10 11 public class GraphNodeObservationContext extends Observation.Context { private final String nodeName; // 节点名称 private final String event; // 事件类型 (onStart/before/after/onError/onComplete) private final Map\u0026lt;String, Object\u0026gt; state; // 节点状态 private final Map\u0026lt;String, Object\u0026gt; output; // 节点输出 // 构造函数 + Getter方法 + Builder模式 public static Builder builder() { return new Builder(); } } Documentation 是制定的观测标准，约定观测的标签、指标名称等，同时分类高低基数标签。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 public enum GraphNodeObservationDocumentation implements ObservationDocumentation { GRAPH_NODE { @Override public Class\u0026lt;? extends ObservationConvention\u0026lt;? extends Context\u0026gt;\u0026gt; getDefaultConvention() { return GraphNodeObservationConvention.class; // 👈 指定约定类 } @Override public KeyName[] getLowCardinalityKeyNames() { return LowCardinalityKeyNames.values(); // 👈 低基数标签 } @Override public KeyName[] getHighCardinalityKeyNames() { return HighCardinalityKeyNames.values(); // 👈 高基数标签 } }; // 低基数标签定义 (适合聚合查询) public enum LowCardinalityKeyNames implements KeyName { SPRING_AI_ALIBABA_KIND, // spring.ai.alibaba.kind GRAPH_NODE_NAME, // spring.ai.alibaba.graph.node.name GRAPH_EVENT // spring.ai.alibaba.graph.event } // 高基数标签定义 (详细信息) public enum HighCardinalityKeyNames implements KeyName { GRAPH_NODE_STATE, // spring.ai.alibaba.graph.node.state GRAPH_NODE_OUTPUT // spring.ai.alibaba.graph.node.output } } Convention 处理Documentation，分离高低基数标签，将Context数据转换为观测标签。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 public class DefaultGraphNodeObservationConvention implements GraphNodeObservationConvention { @Override public String getName() { return \u0026#34;spring.ai.alibaba.graph.node\u0026#34;; // 👈 观测名称 } @Override public String getContextualName(GraphNodeObservationContext context) { if (StringUtils.hasText(context.getName())) { return \u0026#34;%s %s\u0026#34;.formatted(DEFAULT_OPERATION_NAME, context.getName()); } return DEFAULT_OPERATION_NAME; // 👈 上下文名称生成 } @Override public KeyValues getLowCardinalityKeyValues(GraphNodeObservationContext context) { return KeyValues.of( KeyValue.of(\u0026#34;spring.ai.alibaba.kind\u0026#34;, \u0026#34;graph_node\u0026#34;), KeyValue.of(\u0026#34;spring.ai.alibaba.graph.node.name\u0026#34;, context.getNodeName()), KeyValue.of(\u0026#34;spring.ai.alibaba.graph.event\u0026#34;, context.getEvent()) ); // 👈 低基数标签生成 } @Override public KeyValues getHighCardinalityKeyValues(GraphNodeObservationContext context) { return KeyValues.of( KeyValue.of(\u0026#34;spring.ai.alibaba.graph.node.state\u0026#34;, context.getState().toString()), KeyValue.of(\u0026#34;spring.ai.alibaba.graph.node.output\u0026#34;, context.getOutput().toString()) ); // 👈 高基数标签生成 } } Handler 处理观测的事件，具体作用参见组件协作流程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 public class GraphNodeObservationHandler implements ObservationHandler\u0026lt;GraphNodeObservationContext\u0026gt; { private final MeterRegistry meterRegistry; @Override public void onStop(GraphNodeObservationContext context) { // 1. 记录成功日志 logger.info(\u0026#34;Graph nodeName: {} event: {} state: {} output: {}\u0026#34;, context.getNodeName(), context.getEvent(), context.getState(), context.getOutput()); // 2. 生成成功指标 GraphMetricsGenerator.generate(context, meterRegistry, true); } @Override public void onError(GraphNodeObservationContext context) { // 1. 记录错误日志 logger.error(\u0026#34;Graph nodeName: {} event: {} state: {} output: {}\u0026#34;, ...); // 2. 生成失败指标 GraphMetricsGenerator.generate(context, meterRegistry, false); } @Override public boolean supportsContext(Observation.Context context) { return context instanceof GraphNodeObservationContext; // 👈 支持类型判断 } } 组件协作流程 当创建一个观测时：\n1 2 3 4 // 1. 创建观测时 Observation.start(GraphObservationDocumentation.GRAPH.getName(), () -\u0026gt; new GraphObservationContext(nodeId, state, null), observationRegistry) 会发生以下步骤：\n首先根据Observation传入的Convention将Context里面的数据转换成KeyValue对（其中Convention会从对应的Documentation里面去找高低基数键和名字） Convention的应用在Handler被调用之前，他会给Observation.Context基类中添加Convention标准化后的KeyValue，然后这个Context会被后续的Handler所使用 然后被注册到ObservationReg里面的Handler，会使用MetricsGenerator去创建Metrics，同时Metrics会注册到meterReg里面 MetircsGenerator会创建所需要的Tag，包括直接创建的和被KeyValue中的Key所转换的。 ObservationReg的作用 作用和职责：\nHandler 管理：注册和管理 ObservationHandler Convention 管理：管理观测约定（如何转换Context为标签） Filter 管理：管理观测过滤器 观测生命周期控制：协调观测的创建、启动、停止 MeterReg的作用 作用和职责：\n指标管理中心：创建、注册和管理所有的指标对象（Counter、Timer、Gauge等） 指标数据存储：在内存中维护指标的当前值 指标数据发布：将收集的指标数据发布到各种监控系统 Trace相关 刚刚的最佳实践仅仅落脚在metrics，关于trace，并没有说明。\n在SpringBoot中，当有Micrometer Tracing桥接库时候，自动配置会生效，配置TracingObservationHandler以及相关组件。\n1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.micrometer\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;micrometer-tracing-bridge-otel\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; TracingObservationHandler 会被自动注册到 ObservationRegistry 中，监听 start、stop、error 等事件，生成对应的 Span 数据。\n基本概念的区分 Tag和Metrics的关系 Tag是Metrics的组成部分，一个完整的Metric由name + tags + value组成。\n1 2 3 4 5 6 7 // 一个完整的Metric由 name + tags + value 组成 Counter.builder(\u0026#34;api.requests\u0026#34;) // ← Metric名称 .tag(\u0026#34;method\u0026#34;, \u0026#34;GET\u0026#34;) // ← Tag 1 .tag(\u0026#34;status\u0026#34;, \u0026#34;200\u0026#34;) // ← Tag 2 .tag(\u0026#34;endpoint\u0026#34;, \u0026#34;/users\u0026#34;) // ← Tag 3 .register(registry) .increment(); // ← 值的操作 同时，Tag可以为Metric提供聚合能力，比如可以筛选出Tag=特定值的Metric个数。\n聚合以后的Metrics，也可以叫做Metric，更精准的叫法是Calculated Metric。\nTag的基数 高低基数是Tag的分类依据，基数是什么意思呢，就是说Tag的可能值。比如Tag的key是用户用时，那么可能的value就会非常多，就是高基数Tag。反之，Tag的key可能是RESTful API的method，那一共就那么几种，就是低基数Tag。\nSpan和Metrics的关系 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // Metric 示例：聚合统计 Counter.builder(\u0026#34;http.requests.total\u0026#34;) .tag(\u0026#34;method\u0026#34;, \u0026#34;GET\u0026#34;) .tag(\u0026#34;status\u0026#34;, \u0026#34;200\u0026#34;) .register(registry) .increment(); // 结果：http_requests_total{method=\u0026#34;GET\u0026#34;,status=\u0026#34;200\u0026#34;} 1500 // Span 示例：单个请求详情 Span span = tracer.spanBuilder(\u0026#34;http-request\u0026#34;) .setAttribute(\u0026#34;http.method\u0026#34;, \u0026#34;GET\u0026#34;) .setAttribute(\u0026#34;http.url\u0026#34;, \u0026#34;/api/users/12345\u0026#34;) .setAttribute(\u0026#34;http.status_code\u0026#34;, 200) .setAttribute(\u0026#34;user.id\u0026#34;, \u0026#34;12345\u0026#34;) .setAttribute(\u0026#34;response.size\u0026#34;, 2048) .startSpan(); 对比来看，Span是微观视图，Metric是宏观视图。\nTrace和Span的关系 Trace的基本单位是一个一个的span，多个span通过parent-child关系组成完整的Trace。\n每个span包含：\n1 2 3 4 5 6 7 8 9 10 11 12 { \u0026#34;traceId\u0026#34;: \u0026#34;c227f936a3eb510e7da12fda10a8ffab\u0026#34;, \u0026#34;spanId\u0026#34;: \u0026#34;884c2f1abf7f956b\u0026#34;, \u0026#34;parentSpanId\u0026#34;: \u0026#34;293e5b7de78ff24c\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;chat qwen-max\u0026#34;, \u0026#34;kind\u0026#34;: 1, \u0026#34;startTimeUnixNano\u0026#34;: \u0026#34;1733482368328941400\u0026#34;, \u0026#34;endTimeUnixNano\u0026#34;: \u0026#34;1733482372190192300\u0026#34;, \u0026#34;attributes\u0026#34;: [...], \u0026#34;events\u0026#34;: [...], \u0026#34;status\u0026#34;: {...} } Span的上传时机 自动上传时机：\nSpan完成时：当一个操作结束，对应的span会自动结束并触发上传\n缓冲区满时：当内存中积累的span数据达到一定大小（如1MB）时批量上传\n定时上传：OpenTelemetry SDK会定期flush未上传的span\n应用关闭时：通过shutdown()方法确保所有span都被上传\n手动上传时机：\n调用flush()：可以手动触发span上传\n应用重启前：确保数据不丢失\nspan结束后的上传：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Override public CompletableResultCode export(Collection\u0026lt;SpanData\u0026gt; spans) { if (!studioObservabilityProperties.isEnabled()) { return CompletableResultCode.ofSuccess(); } if (isShutdown.get()) { return CompletableResultCode.ofFailure(); } // 立即处理span数据 ResourceSpansMarshaler[] allResourceSpans = ResourceSpansMarshaler.create(spans); return studioObservabilityService.export(List.of(allResourceSpans)); } 到达阈值后批量上传：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 try (BufferedWriter writer = Files.newBufferedWriter(outputPath, StandardOpenOption.APPEND)) { StringBuilder sb = new StringBuilder(); for (ResourceSpansMarshaler resourceSpans : allResourceSpans) { String json = generateJson(resourceSpans); sb.append(json).append(LINE_SEPARATOR); // 当缓存达到1MB时批量写入 if (sb.length() \u0026gt; 1024 * 1024) { writer.write(sb.toString()); sb.setLength(0); } } if (!sb.isEmpty()) { writer.write(sb.toString()); } } Spring AI通过OTel与Langfuse集成 Spring AI实现了基于micrometer的埋点，可以轻松的使用OTLP协议导出，进而实现观测数据上传至Langfuse。\n引入依赖 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-actuator\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud.ai\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-ai-alibaba-starter-dashscope\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.ai\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-ai-autoconfigure-model-chat-observation\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.ai\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-ai-autoconfigure-model-embedding-observation\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.ai\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-ai-autoconfigure-model-image-observation\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.ai\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-ai-autoconfigure-vector-store-observation\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.ai\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-ai-vector-store\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud.ai\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-ai-alibaba-starter-tool-calling-weather\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.opentelemetry.instrumentation\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;opentelemetry-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.9.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.micrometer\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;micrometer-tracing-bridge-otel\u0026lt;/artifactId\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-api\u0026lt;/artifactId\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.opentelemetry\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;opentelemetry-exporter-otlp\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 配置LangFuse 注册账号、获取API Key：\nhttps://cloud.langfuse.com\nLinux/MacOS：\n1 echo -n \u0026#34;public_key:secret_key\u0026#34; | base64 Windows PowerShell：\n1 [System.Convert]::ToBase64String([System.Text.Encoding]::UTF8.GetBytes(\u0026#34;public_key:secret_key\u0026#34;)) 配置application.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 spring: application: name: observability-models-dashscope ai: dashscope: api-key: ${AI_DASHSCOPE_API_KEY} # spring ai alibaba weather tool calling config alibaba: toolcalling: weather: api-key: ${WEATHER_API_KEY} enabled: true # Chat config items chat: client: observations: # default value is false. log-prompt: true observations: log-prompt: true log-completion: true include-error-logging: true # vector store config items vectorstore: observations: log-query-response: true # tools config items tools: observations: # default value is false. include-content: true image: observations: log-prompt: true http: client: read-timeout: 60s management: endpoints: web: exposure: include: \u0026#34;*\u0026#34; endpoint: health: # health status check with detailed messages show-details: always tracing: sampling: # trace information with every request probability: 1.0 observations: annotations: enabled: true otel: service: name: spring-ai-alibaba-graph-langfuse resource: attributes: deployment.environment: development # configure exporter traces: exporter: otlp sampler: always_on metrics: exporter: otlp # logs exportation inhibited for langfuse currently cannot support logs: exporter: none exporter: otlp: endpoint: \u0026#34;https://cloud.langfuse.com/api/public/otel\u0026#34; headers: Authorization: \u0026#34;Basic ${YOUR_BASE64_ENCODED_CREDENTIALS}\u0026#34; protocol: http/protobuf ","date":"2025-06-25T00:00:00Z","permalink":"https://sixiyida.github.io/p/%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7observation%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"可观测性Observation学习笔记"},{"content":"\nList ArrayList LinkedList Vector CopyOnWriteArrayList 类似C++的Vector，略 类似C++的List，略 同步ArrayList 写时复制，读无锁，提升并发性能 遍历时修改 用foreach不能修改，容易出现问题。\n用迭代器/for遍历，可以修改，迭代器修改要使用迭代器的set方法。\n对COWA，可以修改，因为在副本上修改。\nArrayList多线程访问下可能出现的问题 以多线程add元素为例。\n竞争扩容导致部分值设置为null。 竞争导致不扩容，导致越界访问。 覆盖同一位置的值。 扩容操作 类似C++中Vector，只是在Java中扩容倍数是1.5倍，而Vector是两倍。\nCOAW的线程安全 读时无锁，写时获取互斥锁并复制。\nMAP HashMap LinkedHashMap TreeMap HashTable ConcurrentHashMap unordered_map + 红黑树链地址法 双向链表维护底层，迭代顺序和插入顺序一致。 map 加大锁的HashMap 元素级锁的HashMap 遍历方法 For-each+entrySet/keySet 迭代器 foreach方法 StreamAPI HashMap竞争问题 JDK1.7之前 Entry散链死循环问题：\n由于头插法（在链表头部插入），当线程T1、T2同时扩容时，可能会出现以下情况：\nT2扩容后反转链表为B-\u0026gt;A，但是T1仍然操纵旧链表的头节点A，且认为A的next是B，导致AB之间相互指向。\n数据丢失问题：\n类似于List的扩容null问题。\nJDK1.8之后 散链改成了红黑树结构，只存在数据覆盖问题。 Put流程 前面hash-\u0026gt;CAS跳过，后续是：检查散链大小（8）-\u0026gt;转红黑树？-\u0026gt;检查负载因子-\u0026gt;扩容两倍？\n注意：key可以为null，当为null时候令hashCode为0\nHashMap用String做Key的原因 String不可变，保证Key稳定性。\n对重写hashCode()和equals()的限制 equals是hashCode相等的充分不必要条件。\nHashMap扩容是两倍的原因 新hash值=旧哈希值+新hash值最高位代表数值（0或者是旧容量）。\nConcurrentHashMap原理 1.8以后：当容器为空/散链为空，用CAS初始化；当不为空，对散链头节点加互斥锁，锁粒度减小，并发量上升。\n","date":"2025-06-24T00:00:00Z","permalink":"https://sixiyida.github.io/p/%E5%85%AB%E8%82%A1%E6%96%87%E4%B9%8Bjava%E9%9B%86%E5%90%88/","title":"八股文之Java集合"},{"content":"深拷贝的三种方法 实现clone接口，要求引用属性全部实现clonable接口，递归调用。 直接序列化然后反序列化，要求引用属性全部实现serializable接口。 手动递归复制。 反射的应用场景 加载数据库驱动，动态加载驱动类。 IOC容器自动装配，根据类名动态加载实例。（这个在spring八股里面细说） 注解 本质上是一种继承自Annotation的特殊接口，在定义注解时候，编译器会将其转换为接口并生成字节码。\n根据作用范围分类：\n源码级别注解 类文件级别注解（在.class中但是运行不可见） 运行时（在.class中运行可见） 注解的解析 所有可以被注解修饰的元素都实现了AnnotatedElement接口，底层依赖本地方法，JVM在加载类的时候会解析.class中的注解信息存储在内存中，并创建注解代理对象获取注解属性值。\n作用域 类、方法、属性、构造函数、局部变量。\n异常 Error：严重问题，程序无法处理，无法捕捉。 RuntimeException：运行时的问题，如非法内存访问。 非运行时异常：编译时候的问题，如类文件不存在等。 Try-Catch 注意：finally中的return会覆盖try中的。\nLambda表达式和匿名内部类 匿名内部类：\n1 2 3 4 new Runnable(){ @Override public void run(){} } lambda表达式：\n1 () -\u0026gt; {} //等于重写函数式接口唯一方法 异步编程 Future 表示异步计算的结果，只能阻塞或者轮询获取，不支持回调方法。\n回调地狱：指的是当异步操作需要顺序执行的时候，需要将每个操作的回调函数嵌套在上一个工作的回调中，形成深层嵌套。\nCompletableFuture 更为简洁，可读性更好。\n可以通过函数式编程思想对异步调用进行编排。\n（例子待补充）\n单例模式实现 双重检查锁定：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class SingleTon { // volatile 关键字修饰变量 防止指令重排序 private static volatile SingleTon instance = null; private SingleTon(){} public static SingleTon getInstance(){ if(instance == null){ synchronized(SingleTon.class){ if(instance == null){ instance = new SingleTon(); } } } return instance; } } **第一重检查：**优化性能，否则每次都进入方法级加锁同步。\n**第二重检查：**解决竞争问题。\n与C++对比：不支持局部静态变量。\n代理模式和适配器模式 代理模式 略。\n适配器模式 指将旧类适配新接口的新类。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 目标接口（新接口） interface PaymentProcessor { void processPayment(double amount); } // 适配者（旧类） class OldPaymentSystem { void makePayment(double amount) { System.out.println(\u0026#34;旧支付系统扣款\u0026#34;); } } // 适配器 class PaymentAdapter implements PaymentProcessor { private OldPaymentSystem oldSystem; @Override public void processPayment(double amount) { oldSystem.makePayment(amount); // 调用旧类方法 } } 对比 维度 代理模式 适配器模式 核心目标 控制对对象的访问，添加额外功能 解决接口不兼容问题，无功能增强。 角色关系 代理与目标对象实现相同接口 适配器实现目标接口，但包装适配者。 功能增强 可添加逻辑（如日志、权限） 仅转换接口，不增强功能。 应用场景 权限控制、延迟加载、远程调用 旧系统整合、第三方库兼容。 实现关键 代理持有目标对象引用 适配器持有适配者对象引用。 主要区别：就是目的不同，一个增强功能，一个转换适配。\nI/O BIO/NIO/AIO BIO 同步阻塞IO，传统java.io包。\nNIO Java1.4引入，同步非阻塞IO，包含IO多路复用，经典NIO框架是Netty，实现了Reactor和Proactor模式。\nAIO Java1.7引入，异步IO，对内存访问也是异步的。\nNative方法 类似于C++动态库加载函数 ，步骤有以下几步：\n**生成JNI头文件：**使用javah工具从你的Java类生成C/C++的头文件，这个头文件包含了所有native方法的原型。\n**编写本地代码：**使用C/C++编写本地方法的实现，并确保方法签名与生成的头文件中的原型匹配。\n**编译本地代码：**将C/C++代码编译成动态链接库（DLL，在Windows上），共享库（SO，在Linux上）。\n**加载本地库：**在Java程序中，使用System.loadLibrary()方法来加载你编译好的本地库，这样JVM就能找到并调用native方法的实现了。\n","date":"2025-06-20T00:00:00Z","permalink":"https://sixiyida.github.io/p/%E5%85%AB%E8%82%A1%E6%96%87%E4%B9%8Bjava%E5%9F%BA%E7%A1%80/","title":"八股文之Java基础"},{"content":"多线程竞争下的问题 **原子性：**互斥访问，原子操作atomic/串行访问synchronized限制。\n**可见性：**直接操作主内存，使用synchronized和volatile实现。\nvolatile\n读写直达主内存，绕过缓存。 写以后其他CPU变量的缓存自动失效强制重新加载。 有序性： 指令重排序导致的线程观测其他线程指令执行顺序不一致。\n线程的创建方式 继承Thread类，重写run()方法，用start()方法启动线程。 实现Runnable接口，函数式传给Thread构造函数。 实现Callable接口，并将其封装入FutureTask，最后函数式传给Thread构造函数。 Executor框架，executor.submit即可。 如何停止线程运行 在run方法中判断interrupted状态，如果是的话抛出异常/return。然后直接调用interrupt方法即可。如果线程正在执行Thread.sleep() / Thread.join() / Object.wait()等可中断方法，则解除阻塞并抛出异常。 根据约定变量显式判断 通过executor + future取消任务 有资源的情况下直接销毁资源，会弹出异常以退出 Java线程的状态 NEW：尚未start\nRUNNABLE：已经start等待调度/正在运行\nBLOCKED：等待锁\nWAITING：等待零一线程操作\nTIMED_WAITING：具有等待时间的等待\nTERMINATED：终止\nsleep vs wait sleep：任意位置调用，和锁无关，超时释放，释放cpu不是放锁\nwait：有锁下调用，notify/超时唤醒，作用主要是释放锁\nblocked vs waiting blocked：锁竞争失败进入，到锁可用解开阻塞，自动触发\nwaiting：特定方法主动唤醒\n线程的通信方式 Object类下wait/notify/notifyAll方法。\nLock和Condition接口：\n1 2 3 Condition condition = lock.newCondition(); condition.await(); condition.signal(); 基于volatile的共享变量\nCountDownLatch：计数同步辅助类\n1 2 3 4 5 6 CountDownLatch latch = new CountDownLatch(threadCount); new Thread(() -\u0026gt; { latch.countDown(); }).start(); latch.await(); CyclicBarrier：线程内部屏障点，等待所有/一定线程到达屏障点后继续运行。\n1 2 3 4 5 var barrier = new CyclicBarrier(threadCount, () -\u0026gt; {}); new Thread(() -\u0026gt; { barrier.await(;) }).start(); Semaphore：计数信号量，允许控制访问资源的线程数量\n1 2 3 Semaphore(int permits); // 构造函数 acquire(); // 线程内部aquire release(); // 线程内部释放 Java线程安全的保证 synchronized：通过监视器锁实现的同步代码块\nvolatile：通过直写内存/失效通知机制实现的确保变量在不同线程中的观测一致性\nlock/ReentrantLock：更多锁\nAtomic：原子操作\nThreadLocal：当前线程中的存储空间\n并发安全集合\nJUC工具类：如信号量/屏障等\n常见锁 监视器锁（sychronized）： Java提供的原子性内置锁，在同步的代码块前后加上monitorrenter和monitorexit字节码指令，底层依赖操作系统互斥锁。\n接着就是可重入锁的逻辑。\n1.6后的锁升级机制：\nNo Lock -\u0026gt; （首次访问同步块）-\u0026gt; Biased Lock(比对线程ID) -\u0026gt; (二线程锁竞争)\n-\u0026gt; 轻量级锁 (CAS) -\u0026gt; (CAS失败 )-\u0026gt; 大锁\n**轻量级锁：**线程备份锁对象Mark Word，CAS Mark Word指向备份的指针\nCAS成功：线程获得锁\nCAS失败：检查是否重入，如果重入则进入，如果不是则锁升级\n解锁：用CAS还原Mark Word\n还原成功：锁释放\n还原失败：已经是大锁，唤醒阻塞线程\n优化：锁消除（无竞争可能性消除锁）、锁粗化（多锁合一）、自旋锁（减少上下文切换开销）\nReentrantLock 引用计数，进入+1，出去-1，是0则释放锁。\n其他锁 读写锁：读写分离的锁，读和写线程分开获取锁\n乐观锁：版本号比较\n自旋锁/互斥锁：见OS\nAQS (AbstractQueuedSynchronizer) 1. 同步状态（int state） 核心共享变量（volatile int state） 由子类定义语义（例如）： ReentrantLock：重入次数 Semaphore：剩余许可数 CountDownLatch：未完成计数 2. FIFO 等待队列（CLH 变体） 双向链表结构（非严格的 CLH 队列）\n节点 Node存储线程 + 等待状态：\n1 2 3 4 5 6 static final class Node { volatile int waitStatus; // 状态：CANCELLED、SIGNAL、CONDITION等 volatile Node prev; // 前驱节点 volatile Node next; // 后继节点 volatile Thread thread; // 等待线程 } 3. 模板方法模式 子类仅需实现关键钩子方法：\n模版方法 需实现的方法 职责 acquire() tryAcquire() 尝试独占获取锁（需操作 state） release() tryRelease() 尝试独占释放锁 acquireShared() tryAcquireShared() 尝试共享获取（如 Semaphore 许可） releaseShared() tryReleaseShared() 尝试共享释放 4. 线程阻塞与唤醒机制 LockSupport.park()：阻塞当前线程 LockSupport.unpark(thread)：唤醒指定线程 ThreadLocal的原理 每个线程中都有一个独立的ThreadLocalMap，这个东西是哈希表，他的key是ThreadLocal，value是值。\n线程池的ThreadLocal泄露问题\n由于ThreadLocalMap中的value是强引用，线程不结束GC不能回收，所以由于线程池线程长久运行，导致资源无法自动释放。\nCAS的ABA问题 即CS之间存在A-\u0026gt;B-\u0026gt;A的变化，但是CAS会成功。\n解决方法：维护一个版本号（Java的办法）\nvolatile的作用 保证变量对所有线程的可见性 禁止重排序优化：保证写在所有读写完成之后，保证读在所有读写之前进行。 公平锁和非公平锁 **公平锁：**先进等待队列，需要切换两次上下文，慢\n非公平锁：先抢锁，失败进等待队列，成功则不需要切换上下文，快\nsynchronized是非公平锁，可重入锁是公平锁。\n线程池 线程池7个参数 核心线程数、最大线程数、阻塞队列、最大淘汰时间、工厂类、淘汰策略、时间单位\n拒绝策略 异常拒绝、默拒绝、主线程执行、抛弃最老任务\n线程池参数设置 CPU密集型：CPU核+1\nIO密集型：CPU核*2\n为什么不能用默认executor FixedThreadPool内部使用无界任务队列，导致如果消费速度小于生产速度，会无限堆积，导致内存占用过多OOM。\nCachedThreadPool内部使用无界任务队列，且核心线程数为0，如果生产速度大于消费速度，会导致线程无限创建，导致CPU过载等问题。\n","date":"2025-06-20T00:00:00Z","permalink":"https://sixiyida.github.io/p/%E5%85%AB%E8%82%A1%E6%96%87%E4%B9%8Bjava%E5%B9%B6%E5%8F%91/","title":"八股文之Java并发"},{"content":"spring-ai-alibaba-graph-core 源码阅读 ​\tSpring AI Alibaba Graph 是社区核心实现之一，也是整个框架在设计理念上区别于 Spring AI 只做底层原子抽象的地方，Spring AI Alibaba 期望帮助开发者更容易的构建智能体应用。基于 Graph 开发者可以构建工作流、多智能体应用。Spring AI Alibaba Graph 在设计理念上借鉴 Langgraph，因此在一定程度上可以理解为是 Java 版的 Langgraph 实现，社区在此基础上增加了大量预置 Node、简化了 State 定义过程等，让开发者更容易编写对等低代码平台的工作流、多智能体等。\n核心功能\n支持 Multi-agent，内置 ReAct Agent、Supervisor 等常规智能体模式 支持工作流，内置工作流节点，与主流低代码平台对齐 原生支持 Streaming Human-in-the-loop，通过人类确认节点，支持修改状态、恢复执行 支持记忆与持久存储 支持流程快照 支持嵌套分支、并行分支 PlantUML、Mermaid 可视化导出 1 StateGraph 1.1 基础结构 1 2 3 4 5 6 7 8 9 10 public class StateGraph { // 核心数据结构 final Nodes nodes = new Nodes(); // 存储所有节点 final Edges edges = new Edges(); // 存储所有边 // 特殊节点常量 public static final String END = \u0026#34;__END__\u0026#34;; // 结束节点 public static final String START = \u0026#34;__START__\u0026#34;; // 起始节点 public static final String ERROR = \u0026#34;__ERROR__\u0026#34;; // 错误节点 } 1.2 构造方法 1 public StateGraph(String name, KeyStrategyFactory keyStrategyFactory, PlainTextStateSerializer stateSerializer) 参数必选KeyStrategyFactory，其他可选，序列化默认JacksonSerializer()。\n1.3 节点管理 节点具体实现请见2\n1 2 3 4 5 6 7 8 public static class Nodes { public final Set\u0026lt;Node\u0026gt; elements; // 节点集合 // 节点操作方法 public boolean anyMatchById(String id) // 检查节点是否存在 public List\u0026lt;SubStateGraphNode\u0026gt; onlySubStateGraphNodes() // 获取子图节点 public List\u0026lt;Node\u0026gt; exceptSubStateGraphNodes() // 获取非子图节点 } 1.4 边管理 1 2 3 4 5 6 7 public static class Edges { public final List\u0026lt;Edge\u0026gt; elements; // 边集合 // 边操作方法 public Optional\u0026lt;Edge\u0026gt; edgeBySourceId(String sourceId) // 根据源节点查找边 public List\u0026lt;Edge\u0026gt; edgesByTargetId(String targetId) // 根据目标节点查找边 } 1.5 添加节点 1 2 3 4 5 6 7 8 // 添加普通节点 public StateGraph addNode(String id, AsyncNodeAction action) // 添加带配置的节点 public StateGraph addNode(String id, AsyncNodeActionWithConfig actionWithConfig) // 添加子图节点 public StateGraph addNode(String id, StateGraph subGraph) // 添加Command节点 public StateGraph addNode(String id, AsyncCommandAction action, Map\u0026lt;String, String\u0026gt; mappings) 1.6 添加边 1 2 3 4 // 添加普通边 public StateGraph addEdge(String sourceId, String targetId) // 添加条件边 public StateGraph addConditionalEdges(String sourceId, AsyncCommandAction condition, Map\u0026lt;String, String\u0026gt; mappings) 1.7 图验证、编译和可视化 1 2 3 4 5 6 // 验证图的正确性 void validateGraph() throws GraphStateException // 编译图 public CompiledGraph compile(CompileConfig config) throws GraphStateException // 可视化 public GraphRepresentation getGraph(GraphRepresentation.Type type, String title) 1.8 序列化器 1 2 3 static class JacksonSerializer extends JacksonStateSerializer static class GsonSerializer extends GsonStateSerializer 1.9 状态管理 1 2 3 4 // 状态工厂 private OverAllStateFactory overAllStateFactory; // 键策略工厂 private KeyStrategyFactory keyStrategyFactory; 2 Node 2.1 Node基础节点 1 2 3 4 5 6 7 8 9 public class Node { private final String id; // 节点唯一标识 private final ActionFactory actionFactory; // 动作工厂 // 动作工厂接口 public interface ActionFactory { AsyncNodeActionWithConfig apply(CompileConfig config) throws GraphStateException; } } 2.2 ParalellNode 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class ParallelNode extends Node { public static final String PARALLEL_PREFIX = \u0026#34;__PARALLEL__\u0026#34;; // 并行动作实现 record AsyncParallelNodeAction( List\u0026lt;AsyncNodeActionWithConfig\u0026gt; actions, // 并行执行的动作列表 Map\u0026lt;String, KeyStrategy\u0026gt; channels // 通道策略 ) implements AsyncNodeActionWithConfig { // 并行执行所有动作 public CompletableFuture\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; apply(OverAllState state, RunnableConfig config) { // 使用 CompletableFuture 实现并行执行 } } } 具体流转逻辑参见8.2.1.3 并行节点。\n2.3 子图节点 2.3.1 子图节点接口 1 2 3 4 5 6 7 public interface SubGraphNode { String PREFIX_FORMAT = \u0026#34;%s-%s\u0026#34;; // 节点ID格式化模板 String id(); // 获取节点ID StateGraph subGraph(); // 获取子图 String formatId(String nodeId); // 格式化节点ID } 2.3.2 状态图子图节点 1 2 3 4 5 6 7 8 public class SubStateGraphNode extends Node implements SubGraphNode { private final StateGraph subGraph; // 子图 // 格式化节点ID public String formatId(String nodeId) { return SubGraphNode.formatId(id(), nodeId); } } 2.3.3 编译后的子图节点 1 2 3 4 5 6 7 8 public class SubCompiledGraphNode extends Node implements SubGraphNode { private final CompiledGraph subGraph; // 编译后的子图 public SubCompiledGraphNode(String id, CompiledGraph subGraph) { super(id, (config) -\u0026gt; new SubCompiledGraphNodeAction(subGraph)); this.subGraph = subGraph; } } 3 Edge 3.1 基础边Edge 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public record Edge(String sourceId, List\u0026lt;EdgeValue\u0026gt; targets) { // 构造函数 public Edge(String sourceId, EdgeValue target) { this(sourceId, List.of(target)); } // 判断是否为并行边 public boolean isParallel() { return targets.size() \u0026gt; 1; } // 验证边的有效性 public void validate(StateGraph.Nodes nodes) throws GraphStateException { // 验证源节点存在 // 验证目标节点存在 // 验证并行边的目标不重复 } } 3.2 EdgeCondition 1 2 3 4 5 6 public record EdgeCondition( AsyncCommandAction action, // 异步命令动作 Map\u0026lt;String, String\u0026gt; mappings // 条件映射 ) { // 条件执行逻辑 } 3.3 EdgeValue 1 2 3 4 5 6 7 8 9 10 11 public record EdgeValue(String id, EdgeCondition value) { // 简单边值（只有ID） public EdgeValue(String id) { this(id, null); } // 条件边值（只有条件） public EdgeValue(EdgeCondition value) { this(null, value); } } 4 Command Command是一个record类，包含两个核心属性：\n1 public record Command(String gotoNode, Map\u0026lt;String, Object\u0026gt; update) Command用于用于在图的执行过程中动态地决定下一个要执行的节点并更新状态。\n4.1 CommandAction 1 2 3 4 5 6 @FunctionalInterface public interface CommandAction { Command apply(OverAllState state, RunnableConfig config) throws Exception; } 定义了返回Command的逻辑，同时，它可以是异步的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public interface AsyncCommandAction extends BiFunction\u0026lt;OverAllState, RunnableConfig, CompletableFuture\u0026lt;Command\u0026gt;\u0026gt; { static AsyncCommandAction node_async(CommandAction syncAction) { return (state, config) -\u0026gt; { var result = new CompletableFuture\u0026lt;Command\u0026gt;(); try { result.complete(syncAction.apply(state, config)); } catch (Exception e) { result.completeExceptionally(e); } return result; }; } static AsyncCommandAction of(AsyncEdgeAction action) { return (state, config) -\u0026gt; action.apply(state).thenApply(Command::new); } } 4.2 Command的使用 4.2.1 作为节点使用 1 2 3 public StateGraph addNode(String id, AsyncCommandAction action, Map\u0026lt;String, String\u0026gt; mappings) throws GraphStateException { return addNode(id, new CommandNode(id, action, mappings)); } 4.2.1.1 CommandNode apply方法直接返回一个包含有CommandAction和mappings的completeFuture。\n这块的mappings是指：当Command返回key时，跳转到value的节点。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 public class CommandNode extends Node { private final Map\u0026lt;String, String\u0026gt; mappings; private final AsyncCommandAction action; public CommandNode(String id, AsyncCommandAction action, Map\u0026lt;String, String\u0026gt; mappings) { super(id, (config) -\u0026gt; new AsyncCommandNodeActionWithConfig(action, mappings)); this.mappings = mappings; this.action = action; } public Map\u0026lt;String, String\u0026gt; getMappings() { return mappings; } public AsyncCommandAction getAction() { return action; } public record AsyncCommandNodeActionWithConfig(AsyncCommandAction action, Map\u0026lt;String, String\u0026gt; mappings) implements AsyncNodeActionWithConfig { @Override public CompletableFuture\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; apply(OverAllState state, RunnableConfig config) { return CompletableFuture.completedFuture(Map.of(\u0026#34;command\u0026#34;, action, \u0026#34;mappings\u0026#34;, mappings)); } } } 4.2.2 作为条件边的条件使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public StateGraph addConditionalEdges(String sourceId, AsyncCommandAction condition, Map\u0026lt;String, String\u0026gt; mappings) throws GraphStateException { if (Objects.equals(sourceId, END)) { throw Errors.invalidEdgeIdentifier.exception(END); } if (mappings == null || mappings.isEmpty()) { throw Errors.edgeMappingIsEmpty.exception(sourceId); } var newEdge = new Edge(sourceId, new EdgeValue(new EdgeCondition(condition, mappings))); if (edges.elements.contains(newEdge)) { throw Errors.duplicateConditionalEdgeError.exception(sourceId); } else { edges.elements.add(newEdge); } return this; } 5 OverAllState OverAllState 是状态管理的核心，它贯穿整个图的执行过程。\n所有的 Action 都需要依赖状态来执行和传递数据。\n5.1 核心数据结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public final class OverAllState implements Serializable { // 状态数据存储 private final Map\u0026lt;String, Object\u0026gt; data; // 键策略映射 private final Map\u0026lt;String, KeyStrategy\u0026gt; keyStrategies; // 恢复标志 private Boolean resume; // 人工反馈 private HumanFeedback humanFeedback; // 中断消息 private String interruptMessage; } 5.2 状态控制 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public void cover(OverAllState overAllState){ // 替换所有数据 } public OverAllState input(Map\u0026lt;String, Object\u0026gt; input) { // input是null或空直接返回 // 使用keyStrategies操作key对应value Map\u0026lt;String, KeyStrategy\u0026gt; keyStrategies = keyStrategies(); input.keySet().stream().filter(key -\u0026gt; keyStrategies.containsKey(key)).forEach(key -\u0026gt; { this.data.put(key, keyStrategies.get(key).apply(value(key, null), input.get(key))); }); return this; } public Map\u0026lt;String, Object\u0026gt; updateState(Map\u0026lt;String, Object\u0026gt; partialState) { // 用partialState更新状态，和input一样 } public static Map\u0026lt;String, Object\u0026gt; updateState(Map\u0026lt;String, Object\u0026gt; state, Map\u0026lt;String, Object\u0026gt; partialState, Map\u0026lt;String, KeyStrategy\u0026gt; keyStrategies){ // 同上 } private static Map\u0026lt;String, Object\u0026gt; updatePartialStateFromSchema(Map\u0026lt;String, Object\u0026gt; state, Map\u0026lt;String, Object\u0026gt; partialState, Map\u0026lt;String, KeyStrategy\u0026gt; keyStrategies){ // 返回更新后的partialState但不更新状态 } 5.3 策略控制 1 2 3 4 5 6 // 注册键策略 public OverAllState registerKeyAndStrategy(String key, KeyStrategy strategy) public OverAllState registerKeyAndStrategy(Map\u0026lt;String, KeyStrategy\u0026gt; keyStrategies) // 检查策略 public boolean containStrategy(String key) 6 Action 提供了Node、Edge、Command的同异步action接口，其中同步action可以转换为异步。\n1 2 3 4 5 6 7 8 9 10 // DeepResearch中的节点 public class BackgroundInvestigationNode implements NodeAction { @Override public Map\u0026lt;String, Object\u0026gt; apply(OverAllState state) throws Exception { //... return resultMap; } } 7 Config 7.1 CompileConfig CompileConfig主要用于在图编译阶段设置各种配置选项。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class CompileConfig { // 检查点保存器配置 private SaverConfig saverConfig = new SaverConfig().register(MEMORY, new MemorySaver()); // 待阅读 // 生命周期监听器队列 private Deque\u0026lt;GraphLifecycleListener\u0026gt; lifecycleListeners = new LinkedBlockingDeque\u0026lt;\u0026gt;(25); // 中断点配置 private Set\u0026lt;String\u0026gt; interruptsBefore = Set.of(); // 节点执行前中断 private Set\u0026lt;String\u0026gt; interruptsAfter = Set.of(); // 节点执行后中断 // 线程释放标志 private boolean releaseThread = false; } 一般配置用法：\n1 2 3 4 5 6 7 8 CompileConfig config = CompileConfig.builder() .interruptBefore(\u0026#34;node1\u0026#34;, \u0026#34;node2\u0026#34;) // 在node1和node2前中断 .interruptAfter(\u0026#34;node3\u0026#34;) // 在node3后中断 .withLifecycleListener(listener) // 添加生命周期监听器 .releaseThread(true) // 启用线程释放 .build(); CompiledGraph graph = stateGraph.compile(config); 7.2 RunnableConfig 主要用于在图执行过程中传递运行时参数。\nthreadId: 线程标识符，用于多线程场景\ncheckPointId: 检查点ID，用于状态恢复\nnextNode: 指定下一个要执行的节点\nstreamMode: 流模式配置\nmetadata: 自定义元数据\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 public final class RunnableConfig implements HasMetadata\u0026lt;RunnableConfig.Builder\u0026gt; { private final String threadId; private final String checkPointId; private final String nextNode; private final CompiledGraph.StreamMode streamMode; private final Map\u0026lt;String, Object\u0026gt; metadata; public CompiledGraph.StreamMode streamMode() { return streamMode; } public Optional\u0026lt;String\u0026gt; threadId() { return ofNullable(threadId); } public Optional\u0026lt;String\u0026gt; checkPointId() { return ofNullable(checkPointId); } public Optional\u0026lt;String\u0026gt; nextNode() { return ofNullable(nextNode); } public RunnableConfig withStreamMode(CompiledGraph.StreamMode streamMode) { if (this.streamMode == streamMode) { return this; } return RunnableConfig.builder(this).streamMode(streamMode).build(); } public RunnableConfig withCheckPointId(String checkPointId) { if (Objects.equals(this.checkPointId, checkPointId)) { return this; } return RunnableConfig.builder(this).checkPointId(checkPointId).build(); } 一般配置用法：\n1 2 3 4 5 6 7 8 9 RunnableConfig runConfig = RunnableConfig.builder() .threadId(\u0026#34;thread-001\u0026#34;) .checkPointId(\u0026#34;checkpoint-123\u0026#34;) .nextNode(\u0026#34;startNode\u0026#34;) .streamMode(CompiledGraph.StreamMode.VALUES) .addMetadata(\u0026#34;userId\u0026#34;, \u0026#34;user123\u0026#34;) .build(); graph.invoke(initialState, runConfig); 7.3 ActionWithConfig 主要作用就是允许Action在运行时访问RunnableConfig。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 public interface AsyncNodeActionWithConfig extends BiFunction\u0026lt;OverAllState, RunnableConfig, CompletableFuture\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt;\u0026gt; { /** * Applies this action to the given agent state. * @param state the agent state * @return a CompletableFuture representing the result of the action */ CompletableFuture\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; apply(OverAllState state, RunnableConfig config); static AsyncNodeActionWithConfig node_async(NodeActionWithConfig syncAction) { return (state, config) -\u0026gt; { CompletableFuture\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; result = new CompletableFuture\u0026lt;\u0026gt;(); try { result.complete(syncAction.apply(state, config)); } catch (Exception e) { result.completeExceptionally(e); } return result; }; } /** * Adapts a simple AsyncNodeAction to an AsyncNodeActionWithConfig. * @param action the simple AsyncNodeAction to be adapted * @return an AsyncNodeActionWithConfig that wraps the given AsyncNodeAction */ static AsyncNodeActionWithConfig of(AsyncNodeAction action) { return (t, config) -\u0026gt; action.apply(t); } } 8 CompiledGraph CompiledGraph是Graph框架的核心，提供了以下功能：\n图编译: 将StateGraph转换为可执行结构 流式执行: 支持异步流式处理 状态管理: 完整的状态历史和检查点机制 中断控制: 支持执行前后的中断点 生命周期管理: 完整的执行生命周期监听 子图支持: 递归处理子图结构 异常处理: 完善的错误处理机制 8.1 核心属性 1 2 3 4 5 6 7 public final StateGraph stateGraph; // 状态图 private final Map\u0026lt;String, KeyStrategy\u0026gt; keyStrategyMap; // 键策略映射 final Map\u0026lt;String, AsyncNodeActionWithConfig\u0026gt; nodes; // 节点映射 final Map\u0026lt;String, EdgeValue\u0026gt; edges; // 边映射 private final ProcessedNodesEdgesAndConfig processedData; // 处理后的节点和边配置 private int maxIterations = 25; // 最大迭代次数 public final CompileConfig compileConfig; // 编译配置 8.2 状态流转逻辑 8.2.1 流式模式 8.2.1.1 入口接口 以DeepResearch的实现为例子：\n1 2 3 4 5 6 7 8 9 10 11 @RequestMapping(value = \u0026#34;/chat/stream\u0026#34;, method = RequestMethod.POST, produces = MediaType.TEXT_EVENT_STREAM_VALUE) public Flux\u0026lt;ServerSentEvent\u0026lt;String\u0026gt;\u0026gt; chatStream(@RequestBody(required = false) ChatRequest chatRequest) throws GraphRunnerException { //... else { ChatRequestProcess.initializeObjectMap(chatRequest, objectMap); logger.info(\u0026#34;init inputs: {}\u0026#34;, objectMap); AsyncGenerator\u0026lt;NodeOutput\u0026gt; resultFuture = compiledGraph.stream(objectMap, runnableConfig); graphProcess.processStream(resultFuture, sink); } } 这是一个Controller接口，可以看到，图是从这个方法进去的compiledGraph.stream(objectMap, runnableConfig);。\n我们来看看具体实现：\n1 2 3 4 5 public AsyncGenerator\u0026lt;NodeOutput\u0026gt; stream(Map\u0026lt;String, Object\u0026gt; inputs, RunnableConfig config) throws GraphRunnerException { Objects.requireNonNull(config, \u0026#34;config cannot be null\u0026#34;); final AsyncNodeGenerator\u0026lt;NodeOutput\u0026gt; generator = new AsyncNodeGenerator\u0026lt;\u0026gt;(stateCreate(inputs), config); return new AsyncGenerator.WithEmbed\u0026lt;\u0026gt;(generator); } 这个地方返回了一个AsyncGenerator.WithEmbed，这玩意是什么呢？\n简而言之，这个东西是一个允许其他的AsyncGenerator在其执行过程中执行的包装类。\n执行流程是：\n从堆栈顶部获取当前生成器\n调用当前生成器的next()方法获取结果\n如果结果表示生成器已完成：\n清除之前的返回值（如果有）\n将结果推入返回值堆栈\n执行完成回调（如果有）\n如果这是最后一个生成器，返回结果\n否则，弹出当前生成器，递归调用next()继续处理下一个生成器\n如果结果包含一个嵌入生成器： 检查嵌套深度（目前不支持递归嵌套）\n将嵌入生成器推入堆栈\n递归调用next()处理嵌入生成器\n否则，直接返回结果 看看具体实现：\n1 2 protected final Deque\u0026lt;Embed\u0026lt;E\u0026gt;\u0026gt; generatorsStack = new ArrayDeque\u0026lt;\u0026gt;(2); private final Deque\u0026lt;Data\u0026lt;E\u0026gt;\u0026gt; returnValueStack = new ArrayDeque\u0026lt;\u0026gt;(2); 首先核心数据结构是利用这两个双端队列维护返回值和生成器栈。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @Override public Data\u0026lt;E\u0026gt; next() { if (generatorsStack.isEmpty()) { // GUARD throw new IllegalStateException(\u0026#34;no generator found!\u0026#34;); } final Embed\u0026lt;E\u0026gt; embed = generatorsStack.peek(); final Data\u0026lt;E\u0026gt; result = embed.generator.next(); if (result.isDone()) { clearPreviousReturnsValuesIfAny(); returnValueStack.push(result); if (embed.onCompletion != null) { try { embed.onCompletion.accept(result.resultValue); } catch (Exception e) { return Data.error(e); } } if (isLastGenerator()) { return result; } generatorsStack.pop(); return next(); } if (result.embed != null) { if (generatorsStack.size() \u0026gt;= 2) { return Data.error(new UnsupportedOperationException( \u0026#34;Currently recursive nested generators are not supported!\u0026#34;)); } generatorsStack.push(result.embed); return next(); } return result; } 这个方法是核心方法，递归地处理了嵌入的生成器。\n在状态流转中，处理嵌入的Generator的逻辑如下：\n主AsyncNodeGenerator → 发现嵌入生成器 → WithEmbed接管 → 执行嵌入生成器 → 完成后恢复 → 主AsyncNodeGenerator继续\n8.2.1.2 状态流转 AsyncNodeGenerator是整个图流转执行的唯一状态机，\n然后我们来看看AsyncNodeGenerator的实现：\n核心方法是next，其实现了状态图流转。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 @Override public Data\u0026lt;o\u0026gt; next() { try { // 检查最大迭代次数 if (++iteration \u0026gt; maxIterations) { return Data.error(new IllegalStateException( format(\u0026#34;Maximum number of iterations (%d) reached!\u0026#34;, maxIterations))); } // 检查是否已结束 if (nextNodeId == null \u0026amp;\u0026amp; currentNodeId == null) { return releaseThread().map(Data::\u0026lt;o\u0026gt;done).orElseGet(() -\u0026gt; Data.done(currentState)); } // 是否从嵌入恢复 if (resumedFromEmbed) { final CompletableFuture\u0026lt;o\u0026gt; future = getNodeOutput(); resumedFromEmbed = false; return Data.of(future); } // 处理START节点 if (START.equals(currentNodeId)) { doListeners(START, null); var nextNodeCommand = getEntryPoint(currentState, config); nextNodeId = nextNodeCommand.gotoNode(); currentState = nextNodeCommand.update(); var cp = addCheckpoint(config, START, currentState, nextNodeId); var output = (cp.isPresent() \u0026amp;\u0026amp; config.streamMode() == StreamMode.SNAPSHOTS) ? buildStateSnapshot(cp.get()) : buildNodeOutput(currentNodeId); currentNodeId = nextNodeId; return Data.of(output); } // 处理END节点 if (END.equals(nextNodeId)) { nextNodeId = null; currentNodeId = null; doListeners(END, null); return Data.of(buildNodeOutput(END)); } // 检查中断条件 if (shouldInterruptAfter(currentNodeId, nextNodeId)) { return Data.done(currentNodeId); } if (shouldInterruptBefore(nextNodeId, currentNodeId)) { return Data.done(currentNodeId); } // 更新当前节点ID currentNodeId = nextNodeId; // 获取当前节点对应的动作 var action = nodes.get(currentNodeId); if (action == null) throw RunnableErrors.missingNode.exception(currentNodeId); // 执行节点动作 return evaluateAction(action, this.overAllState).get(); } catch (Exception e) { doListeners(ERROR, e); log.error(e.getMessage(), e); return Data.error(e); } } 其中evaluateAction执行了nodeAction，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 private Command nextNodeId(String nodeId, OverAllState overAllState, Map\u0026lt;String, Object\u0026gt; state, RunnableConfig config) throws Exception { EdgeValue route = edges.get(nodeId); if (route == null) { throw RunnableErrors.missingEdge.exception(nodeId); } // 如果边有固定的目标ID if (route.id() != null) { return new Command(route.id(), state); } // 如果边有条件逻辑 if (route.value() != null) { // 执行边的条件动作 var command = route.value().action().apply(overAllState, config).get(); var newRoute = command.gotoNode(); // 根据条件结果查找映射的目标节点 String result = route.value().mappings().get(newRoute); if (result == null) { throw RunnableErrors.missingNodeInEdgeMapping.exception(nodeId, newRoute); } // 更新状态 var currentState = OverAllState.updateState(state, command.update(), keyStrategyMap); overAllState.updateState(command.update()); return new Command(result, currentState); } throw RunnableErrors.executionError.exception(format(\u0026#34;invalid edge value for nodeId: [%s] !\u0026#34;, nodeId)); } 下一个节点由nextNodeId方法决定：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 private Command nextNodeId(String nodeId, OverAllState overAllState, Map\u0026lt;String, Object\u0026gt; state, RunnableConfig config) throws Exception { EdgeValue route = edges.get(nodeId); if (route == null) { throw RunnableErrors.missingEdge.exception(nodeId); } // 如果边有固定的目标ID if (route.id() != null) { return new Command(route.id(), state); } // 如果边有条件逻辑 if (route.value() != null) { // 执行边的条件动作 var command = route.value().action().apply(overAllState, config).get(); var newRoute = command.gotoNode(); // 根据条件结果查找映射的目标节点 String result = route.value().mappings().get(newRoute); if (result == null) { throw RunnableErrors.missingNodeInEdgeMapping.exception(nodeId, newRoute); } // 更新状态 var currentState = OverAllState.updateState(state, command.update(), keyStrategyMap); overAllState.updateState(command.update()); return new Command(result, currentState); } throw RunnableErrors.executionError.exception(format(\u0026#34;invalid edge value for nodeId: [%s] !\u0026#34;, nodeId)); } 8.2.1.3 并行节点 首先，编译时会检测边的target数量，发现有并行边以后就创建并行节点并替换图结构。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 for (var e : processedData.edges().elements) { var targets = e.targets(); if (targets.size() == 1) { edges.put(e.sourceId(), targets.get(0)); // 单一目标，正常处理 } else { // 发现多个目标，处理并行分支 Supplier\u0026lt;Stream\u0026lt;EdgeValue\u0026gt;\u0026gt; parallelNodeStream = () -\u0026gt; targets.stream() .filter(target -\u0026gt; nodes.containsKey(target.id())); // 验证并行分支的合法性 var parallelNodeTargets = parallelNodeEdges.stream() .map(ee -\u0026gt; ee.target().id()) .collect(Collectors.toSet()); if (parallelNodeTargets.size() \u0026gt; 1) { // 检查条件边 - 并行分支不允许条件边 var conditionalEdges = parallelNodeEdges.stream() .filter(ee -\u0026gt; ee.target().value() != null) .toList(); if (!conditionalEdges.isEmpty()) { throw Errors.unsupportedConditionalEdgeOnParallelNode.exception(...); } // 检查多目标 - 所有分支必须汇聚到同一个节点 throw Errors.illegalMultipleTargetsOnParallelNode.exception(...); } // 创建ParallelNode var actions = parallelNodeStream.get() .map(target -\u0026gt; nodes.get(target.id())) // 收集所有分支的Action .toList(); var parallelNode = new ParallelNode(e.sourceId(), actions, keyStrategyMap); // 替换图结构 nodes.put(parallelNode.id(), parallelNode.actionFactory().apply(compileConfig)); edges.put(e.sourceId(), new EdgeValue(parallelNode.id())); // 原节点 → ParallelNode edges.put(parallelNode.id(), new EdgeValue(parallelNodeTargets.iterator().next())); // ParallelNode → 汇聚节点 } } 运行时，ParallelNode执行逻辑如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 @Override public CompletableFuture\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; apply(OverAllState state, RunnableConfig config) { Map\u0026lt;String, Object\u0026gt; partialMergedStates = new HashMap\u0026lt;\u0026gt;(); Map\u0026lt;String, Object\u0026gt; asyncGenerators = new HashMap\u0026lt;\u0026gt;(); // 创建所有分支的并行执行任务 var futures = actions.stream().map(action -\u0026gt; action.apply(state, config).thenApply(partialState -\u0026gt; { partialState.forEach((key, value) -\u0026gt; { if (value instanceof AsyncGenerator\u0026lt;?\u0026gt; || value instanceof GeneratorSubscriber) { // AsyncGenerator类型 → 放入异步生成器集合 ((List) asyncGenerators.computeIfAbsent(key, k -\u0026gt; new ArrayList\u0026lt;\u0026gt;())).add(value); } else { // 普通值 → 放入状态合并集合 partialMergedStates.put(key, value); } }); state.updateState(partialMergedStates); // 立即更新状态 return action; }) ).toList().toArray(new CompletableFuture[0]); // 等待所有分支完成 return CompletableFuture.allOf(futures) .thenApply((p) -\u0026gt; CollectionUtils.isEmpty(asyncGenerators) ? state.data() : // 没有AsyncGenerator，返回合并状态 asyncGenerators); // 有AsyncGenerator，触发嵌入机制 } 此时，会被evaluateAction的thenApply回调所处理，由于返回了AsnycGenerator，会进入getEmbedGenerator进行处理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 return action.apply(withState, config).thenApply(updateState -\u0026gt; { try { // updateState 就是NodeAction返回的Map\u0026lt;String,Object\u0026gt; // 1. 特殊处理：CommandNode ... // 2. 检查嵌入生成器 Optional\u0026lt;Data\u0026lt;o\u0026gt;\u0026gt; embed = getEmbedGenerator(updateState); if (embed.isPresent()) { return embed.get(); // 触发嵌入生成器处理 } // 3. 常规状态更新 ... // 4. 计算下一个节点 ... } catch (Exception e) { throw new CompletionException(e); } }); 来看看getEmbedGenerator的实现：\n这里主要做了两件事：1. 看partialState里面有几个embedGenerator 2. 如果有多个，就合并成一个。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 private Optional\u0026lt;Data\u0026lt;Output\u0026gt;\u0026gt; getEmbedGenerator(Map\u0026lt;String, Object\u0026gt; partialState) { // Extract all AsyncGenerator instances List\u0026lt;AsyncGenerator\u0026lt;Output\u0026gt;\u0026gt; asyncNodeGenerators = new ArrayList\u0026lt;\u0026gt;(); var generatorEntries = partialState.entrySet().stream().filter(e -\u0026gt; { // Fixed when parallel nodes return asynchronous generating the same key Object value = e.getValue(); if (value instanceof AsyncGenerator) { return true; } if (value instanceof Collection collection) { collection.forEach(o -\u0026gt; { if (o instanceof AsyncGenerator\u0026lt;?\u0026gt;) { asyncNodeGenerators.add((AsyncGenerator\u0026lt;Output\u0026gt;) o); } }); } return false; }).collect(Collectors.toList()); if (generatorEntries.isEmpty() \u0026amp;\u0026amp; asyncNodeGenerators.isEmpty()) { return Optional.empty(); } // Log information about found generators if (generatorEntries.size() \u0026gt; 1) { log.debug(\u0026#34;Multiple generators found: {} - keys: {}\u0026#34;, generatorEntries.size(), generatorEntries.stream().map(Map.Entry::getKey).collect(Collectors.joining(\u0026#34;, \u0026#34;))); } // Create appropriate generator (single or merged) AsyncGenerator\u0026lt;Output\u0026gt; generator = AsyncGeneratorUtils.createAppropriateGenerator(generatorEntries, asyncNodeGenerators, keyStrategyMap); // Create data processing logic for the generator return Optional.of(Data.composeWith(generator.map(n -\u0026gt; { n.setSubGraph(true); return n; }), data -\u0026gt; processGeneratorOutput(data, partialState, generatorEntries))); } 来看看合并Generator的代码具体实现：\n这可能看起来很复杂，主要就是返回了一个新的AsnycGenerator，它可以轮询执行所有输入的生成器。\n同时，这个AsnycGenerator可能被并发访问，故需要加锁。\n执行路径：\n使用乐观锁检查是否已经merge完成，如果有线程获取写锁，就获取悲观读锁读取验证。 开始merge，首先获取写锁，保证轮询符合操作的原子性。 释放写锁，无锁下执行next方法获取单个结果，由于前面保证了获取的不是同一个generator，所以这里是线程安全的。 再次获取写锁，更新状态，保证activeGenerators ↔ mergedResult ↔ generatorResults的状态一致性。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 public static \u0026lt;T\u0026gt; AsyncGenerator\u0026lt;T\u0026gt; createMergedGenerator(List\u0026lt;AsyncGenerator\u0026lt;T\u0026gt;\u0026gt; generators, Map\u0026lt;String, KeyStrategy\u0026gt; keyStrategyMap) { return new AsyncGenerator\u0026lt;\u0026gt;() { // Switch to StampedLock to simplify lock management private final StampedLock lock = new StampedLock(); private AtomicInteger pollCounter = new AtomicInteger(0); private Map\u0026lt;String, Object\u0026gt; mergedResult = new HashMap\u0026lt;\u0026gt;(); private final List\u0026lt;AsyncGenerator\u0026lt;T\u0026gt;\u0026gt; activeGenerators = new CopyOnWriteArrayList\u0026lt;\u0026gt;(generators); private final Map\u0026lt;AsyncGenerator\u0026lt;T\u0026gt;, Map\u0026lt;String, Object\u0026gt;\u0026gt; generatorResults = new HashMap\u0026lt;\u0026gt;(); @Override public AsyncGenerator.Data\u0026lt;T\u0026gt; next() { while (true) { // Read optimistically and check quickly long stamp = lock.tryOptimisticRead(); boolean empty = activeGenerators.isEmpty(); if (!lock.validate(stamp)) { stamp = lock.readLock(); try { empty = activeGenerators.isEmpty(); } finally { lock.unlockRead(stamp); } } if (empty) { return AsyncGenerator.Data.done(mergedResult); } // Fine-grained lock control final int currentIdx; AsyncGenerator\u0026lt;T\u0026gt; current; long writeStamp = lock.writeLock(); try { final int size = activeGenerators.size(); if (size == 0) return AsyncGenerator.Data.done(mergedResult); currentIdx = pollCounter.updateAndGet(i -\u0026gt; (i + 1) % size); current = activeGenerators.get(currentIdx); } finally { lock.unlockWrite(writeStamp); } // Execute the generator \u0026#39;next()\u0026#39; in the unlocked state AsyncGenerator.Data\u0026lt;T\u0026gt; data = current.next(); writeStamp = lock.writeLock(); try { // Double checks prevent status changes if (!activeGenerators.contains(current)) { continue; } if (data.isDone() || data.isError()) { handleCompletedGenerator(current, data); if (activeGenerators.isEmpty()) { return AsyncGenerator.Data.done(mergedResult); } continue; } handleCompletedGenerator(current, data); return data; } finally { lock.unlockWrite(writeStamp); } } } /** * Helper method to handle completed or errored generators */ private void handleCompletedGenerator(AsyncGenerator\u0026lt;T\u0026gt; generator, AsyncGenerator.Data\u0026lt;T\u0026gt; data) { // Remove generator if done or error if (data.isDone() || data.isError()) { activeGenerators.remove(generator); } // Process result if exists data.resultValue().ifPresent(result -\u0026gt; { if (result instanceof Map) { @SuppressWarnings(\u0026#34;unchecked\u0026#34;) Map\u0026lt;String, Object\u0026gt; mapResult = (Map\u0026lt;String, Object\u0026gt;) result; mergedResult = OverAllState.updateState(mergedResult, mapResult, keyStrategyMap); } }); // Remove from generator results if present generatorResults.remove(generator); } }; } 8.2.2 AsyncGenerator 施工中。。。\n8.3 GraphLifeCycleLister 暴露的钩子函数，可以通过配置Lister队列来在图的不同状态触发自定义函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 private void doListeners(String scene, Exception e) { Deque\u0026lt;GraphLifecycleListener\u0026gt; listeners = new LinkedBlockingDeque\u0026lt;\u0026gt;(compileConfig.lifecycleListeners()); processListenersLIFO(listeners, scene, e); } private void processListenersLIFO(Deque\u0026lt;GraphLifecycleListener\u0026gt; listeners, String scene, Exception e) { if (listeners.isEmpty()) { return; } GraphLifecycleListener listener = listeners.pollLast(); try { if (START.equals(scene)) { listener.onStart(START, this.currentState); } else if (END.equals(scene)) { listener.onComplete(END, this.currentState); } else if (ERROR.equals(scene)) { listener.onError(this.currentNodeId, this.currentState, e); } processListenersLIFO(listeners, scene, e); } catch (Exception ex) { log.debug(\u0026#34;Error occurred during listener processing: {}\u0026#34;, ex.getMessage()); } } 8.4 子图处理 主要实现了：\n把子图的节点和边嫁接到主图上面，然后返回修改后的主图。\n把子图中断转移到子图入口。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 record ProcessedNodesEdgesAndConfig(StateGraph.Nodes nodes, StateGraph.Edges edges, Set\u0026lt;String\u0026gt; interruptsBefore, Set\u0026lt;String\u0026gt; interruptsAfter) { /** * Instantiates a new Processed nodes edges and config. * @param stateGraph the state graph * @param config the config */ ProcessedNodesEdgesAndConfig(StateGraph stateGraph, CompileConfig config) { this(stateGraph.nodes, stateGraph.edges, config.interruptsBefore(), config.interruptsAfter()); } /** * Process processed nodes edges and config. * @param stateGraph the state graph * @param config the config * @return the processed nodes edges and config * @throws GraphStateException the graph state exception */ static ProcessedNodesEdgesAndConfig process(StateGraph stateGraph, CompileConfig config) throws GraphStateException { var subgraphNodes = stateGraph.nodes.onlySubStateGraphNodes(); if (subgraphNodes.isEmpty()) { return new ProcessedNodesEdgesAndConfig(stateGraph, config); } var interruptsBefore = config.interruptsBefore(); var interruptsAfter = config.interruptsAfter(); var nodes = new StateGraph.Nodes(stateGraph.nodes.exceptSubStateGraphNodes()); var edges = new StateGraph.Edges(stateGraph.edges.elements); for (var subgraphNode : subgraphNodes) { var sgWorkflow = subgraphNode.subGraph(); // // Process START Node // var sgEdgeStart = sgWorkflow.edges.edgeBySourceId(START).orElseThrow(); if (sgEdgeStart.isParallel()) { throw new GraphStateException(\u0026#34;subgraph not support start with parallel branches yet!\u0026#34;); } var sgEdgeStartTarget = sgEdgeStart.target(); if (sgEdgeStartTarget.id() == null) { throw new GraphStateException(format(\u0026#34;the target for node \u0026#39;%s\u0026#39; is null!\u0026#34;, subgraphNode.id())); } var sgEdgeStartRealTargetId = subgraphNode.formatId(sgEdgeStartTarget.id()); // Process Interruption (Before) Subgraph(s) interruptsBefore = interruptsBefore.stream() .map(interrupt -\u0026gt; Objects.equals(subgraphNode.id(), interrupt) ? sgEdgeStartRealTargetId : interrupt) .collect(Collectors.toUnmodifiableSet()); var edgesWithSubgraphTargetId = edges.edgesByTargetId(subgraphNode.id()); if (edgesWithSubgraphTargetId.isEmpty()) { throw new GraphStateException( format(\u0026#34;the node \u0026#39;%s\u0026#39; is not present as target in graph!\u0026#34;, subgraphNode.id())); } for (var edgeWithSubgraphTargetId : edgesWithSubgraphTargetId) { var newEdge = edgeWithSubgraphTargetId.withSourceAndTargetIdsUpdated(subgraphNode, Function.identity(), id -\u0026gt; new EdgeValue((Objects.equals(id, subgraphNode.id()) ? subgraphNode.formatId(sgEdgeStartTarget.id()) : id))); edges.elements.remove(edgeWithSubgraphTargetId); edges.elements.add(newEdge); } // // Process END Nodes // var sgEdgesEnd = sgWorkflow.edges.edgesByTargetId(END); var edgeWithSubgraphSourceId = edges.edgeBySourceId(subgraphNode.id()).orElseThrow(); if (edgeWithSubgraphSourceId.isParallel()) { throw new GraphStateException(\u0026#34;subgraph not support routes to parallel branches yet!\u0026#34;); } // Process Interruption (After) Subgraph(s) if (interruptsAfter.contains(subgraphNode.id())) { var exceptionMessage = (edgeWithSubgraphSourceId.target() .id() == null) ? \u0026#34;\u0026#39;interruption after\u0026#39; on subgraph is not supported yet!\u0026#34; : format( \u0026#34;\u0026#39;interruption after\u0026#39; on subgraph is not supported yet! consider to use \u0026#39;interruption before\u0026#39; node: \u0026#39;%s\u0026#39;\u0026#34;, edgeWithSubgraphSourceId.target().id()); throw new GraphStateException(exceptionMessage); } sgEdgesEnd.stream() .map(e -\u0026gt; e.withSourceAndTargetIdsUpdated(subgraphNode, subgraphNode::formatId, id -\u0026gt; (Objects.equals(id, END) ? edgeWithSubgraphSourceId.target() : new EdgeValue(subgraphNode.formatId(id))))) .forEach(edges.elements::add); edges.elements.remove(edgeWithSubgraphSourceId); // // Process edges // sgWorkflow.edges.elements.stream() .filter(e -\u0026gt; !Objects.equals(e.sourceId(), START)) .filter(e -\u0026gt; !e.anyMatchByTargetId(END)) .map(e -\u0026gt; e.withSourceAndTargetIdsUpdated(subgraphNode, subgraphNode::formatId, id -\u0026gt; new EdgeValue(subgraphNode.formatId(id)))) .forEach(edges.elements::add); // // Process nodes // sgWorkflow.nodes.elements.stream().map(n -\u0026gt; { if (n instanceof CommandNode commandNode) { Map\u0026lt;String, String\u0026gt; mappings = commandNode.getMappings(); HashMap\u0026lt;String, String\u0026gt; newMappings = new HashMap\u0026lt;\u0026gt;(); mappings.forEach((key, value) -\u0026gt; { newMappings.put(key, subgraphNode.formatId(value)); }); return new CommandNode(subgraphNode.formatId(n.id()), AsyncCommandAction.node_async((state, config1) -\u0026gt; { Command command = commandNode.getAction().apply(state, config1).join(); String NewGoToNode = subgraphNode.formatId(command.gotoNode()); return new Command(NewGoToNode, command.update()); }), newMappings); } return n.withIdUpdated(subgraphNode::formatId); }).forEach(nodes.elements::add); } return new ProcessedNodesEdgesAndConfig(nodes, edges, interruptsBefore, interruptsAfter); } 8.5 中断处理 8.5.1 中断 CompiledConfig中定义了中断点。graph运行时会自动生成每个节点的Checkpoint并存到Saver里面。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 private boolean shouldInterruptBefore(String nodeId, String previousNodeId) { if (previousNodeId == null) { // FIX RESUME ERROR return false; } return compileConfig.interruptsBefore().contains(nodeId); } private boolean shouldInterruptAfter(String nodeId, String previousNodeId) { if (nodeId == null) { // FIX RESUME ERROR return false; } return compileConfig.interruptsAfter().contains(nodeId); } private Optional\u0026lt;Checkpoint\u0026gt; addCheckpoint(RunnableConfig config, String nodeId, Map\u0026lt;String, Object\u0026gt; state, String nextNodeId) throws Exception { if (compileConfig.checkpointSaver().isPresent()) { var cp = Checkpoint.builder().nodeId(nodeId).state(cloneState(state)).nextNodeId(nextNodeId).build(); compileConfig.checkpointSaver().get().put(config, cp); return Optional.of(cp); } return Optional.empty(); } 运行时，到达中断点后，直接return Data.done()\n1 2 3 4 5 6 7 8 9 10 11 12 // check on previous node if (shouldInterruptAfter(currentNodeId, nextNodeId)) { return Data.done(currentNodeId); } if (shouldInterruptBefore(nextNodeId, currentNodeId)) { return Data.done(currentNodeId); } currentNodeId = nextNodeId; var action = nodes.get(currentNodeId); 8.5.2 恢复 AsyncNodeGenerator构造函数中，会检查是开始还是恢复。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 protected AsyncNodeGenerator(OverAllState overAllState, RunnableConfig config) throws GraphRunnerException { if (overAllState.isResume()) { // ← 检查是否为恢复请求 log.trace(\u0026#34;RESUME REQUEST\u0026#34;); // 1. 获取CheckpointSaver实例 BaseCheckpointSaver saver = compileConfig.checkpointSaver() .orElseThrow(() -\u0026gt; (new IllegalStateException( \u0026#34;inputs cannot be null (ie. resume request) if no checkpoint saver is configured\u0026#34;))); // 2. 从CheckpointSaver读取检查点数据 ← 核心读取位置！ Checkpoint startCheckpoint = saver.get(config) .orElseThrow(() -\u0026gt; (new IllegalStateException(\u0026#34;Resume request without a saved checkpoint!\u0026#34;))); // 3. 恢复状态数据 this.currentState = startCheckpoint.getState(); // ← 状态恢复 this.config = config.withCheckPointId(null); this.overAllState = overAllState.input(this.currentState); this.nextNodeId = startCheckpoint.getNextNodeId(); // ← 恢复下一个节点 this.currentNodeId = null; log.trace(\u0026#34;RESUME FROM {}\u0026#34;, startCheckpoint.getNodeId()); } } 9 序列化 9.1 使用场景 9.1.1 Checkpoint保存（持久化状态） 1 2 3 4 5 6 7 8 9 10 private Optional\u0026lt;Checkpoint\u0026gt; addCheckpoint(RunnableConfig config, String nodeId, Map\u0026lt;String, Object\u0026gt; state, String nextNodeId) throws Exception { if (compileConfig.checkpointSaver().isPresent()) { var cp = Checkpoint.builder().nodeId(nodeId).state(cloneState(state)).nextNodeId(nextNodeId).build(); compileConfig.checkpointSaver().get().put(config, cp); return Optional.of(cp); } return Optional.empty(); } 9.1.2 Resume反序列化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 protected AsyncNodeGenerator(OverAllState overAllState, RunnableConfig config) throws GraphRunnerException { if (overAllState.isResume()) { log.trace(\u0026#34;RESUME REQUEST\u0026#34;); BaseCheckpointSaver saver = compileConfig.checkpointSaver() .orElseThrow(() -\u0026gt; (new IllegalStateException( \u0026#34;inputs cannot be null (ie. resume request) if no checkpoint saver is configured\u0026#34;))); Checkpoint startCheckpoint = saver.get(config) .orElseThrow(() -\u0026gt; (new IllegalStateException(\u0026#34;Resume request without a saved checkpoint!\u0026#34;))); this.currentState = startCheckpoint.getState(); // Reset checkpoint id this.config = config.withCheckPointId(null); this.overAllState = overAllState.input(this.currentState); this.nextNodeId = startCheckpoint.getNextNodeId(); this.currentNodeId = null; log.trace(\u0026#34;RESUME FROM {}\u0026#34;, startCheckpoint.getNodeId()); } 9.1.3 状态深拷贝 1 2 3 OverAllState cloneState(Map\u0026lt;String, Object\u0026gt; data) throws IOException, ClassNotFoundException { return stateGraph.getStateSerializer().cloneObject(data); } ","date":"2025-06-06T00:00:00Z","permalink":"https://sixiyida.github.io/p/spring-ai-alibaba-graph-core-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/","title":"spring-ai-alibaba-graph-core 源码阅读"},{"content":"1. Deep Research Executor节点并行 1.1 问题描述 ​\t当前架构中，Research Team节点后的负责执行plan的Executors (Researcher/Coder) 是串行执行的，每一步都需要等待上一个step执行完毕，耗费大量时间。经测试，一个5step的plan耗时需要4分钟，占据了整个执行流程的70%。\n​\t测试观察发现，ResearcherNode的step基本没有上下文依赖，每个step相对独立，所以可以异步并行执行，增加速度。CoderNode在获取了ResearcherNode的上下文后，也可以异步并行执行。\n1.2 修改策略 ​\t并行实现有两种方案：\n​\t（1）直接在ResearcherTeam中，异步动态创建nodeaction并执行，即有多少个Step就创建多少个ExecutorNode，一次即可完成整个step，并在ResearcherNode连一条自旋边，阻塞线程以等待。\n​\t（2）利用Graph库提供的并行节点，即创建一个节点，异步执行nodeaction，这样利用了已有的能力，维护性较好。\n1.3 具体实现 ​\t两种方案都需要依赖在step中进行状态控制，即三种状态：assigned、processing、completed。并且附上给节点分配的id。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Data public static class Step { @JsonProperty(\u0026#34;need_web_search\u0026#34;) private boolean needWebSearch; private String title; private String description; @JsonProperty(\u0026#34;step_type\u0026#34;) private StepType stepType; private String executionRes; private String executionStatus; } 1.3.1 方案1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 step.setExecutionStatus(assignedStatus); CompletableFuture.runAsync(() -\u0026gt; { try { if (step.getStepType() == Plan.StepType.RESEARCH) { logger.info(\u0026#34;Executing research step {}: {}\u0026#34;, stepIndex, step.getTitle()); // 为每个研究步骤创建新的Agent ChatClient researchAgent = applicationContext.getBean(\u0026#34;researchAgent\u0026#34;, ChatClient.class); ResearcherNode researcherNode = new ResearcherNode(researchAgent, executorNodeId); researcherNode.apply(state); } else { logger.info(\u0026#34;Executing processing step {}: {}\u0026#34;, stepIndex, step.getTitle()); // 为每个处理步骤创建新的Agent ChatClient coderAgent = applicationContext.getBean(\u0026#34;coderAgent\u0026#34;, ChatClient.class); CoderNode coderNode = new CoderNode(coderAgent, executorNodeId); coderNode.apply(state); } } catch (Exception e) { logger.error(\u0026#34;Error executing step {}: {}\u0026#34;, stepIndex, step.getTitle(), e); } }, executorService); 以上为核心代码，比较简单粗暴。即ResearcherTeamNode直接创建新节点，并且等待。\n1.3.2 方案2 方案2是最终采纳的方案。阅读Graph发现当前graph实现有以下限制：\n（1）子图节点不能包含有并行节点\n（2）并行节点必须是总分总的结构，并且会在汇总节点等待所有异步任务执行完毕。\n（3）并行节点总分总结构中所有边不能是conditional。\n（4）不支持并行流式处理。\n为绕开/解决限制，采取以下方案：\n对于（1），直接不使用子图节点，在大图中进行结构修改。\n对于（3），由于当前researcherTeamNode需要到reporterNode或者executorNode，故并行节点不能是researcherTeamNode，需要单独创建一个ParallelExecutorNode来给ExecutorNode分配任务。\n对于（2），采取researcherTeamNode -\u0026gt; ParallelExecutorNode -\u0026gt; ExecutorNodes -\u0026gt; researcherTeamNode的环形结构，在第二次进入researcherTeamNode的时候等待。\n对于（4），分析并修改Graph Core代码。\n1.3.2.1 ParallelExecutorNode 主要任务：分配step给后续节点。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 /* * Copyright 2025 the original author or authors. * * Licensed under the Apache License, Version 2.0 (the \u0026#34;License\u0026#34;); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * https://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \u0026#34;AS IS\u0026#34; BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.alibaba.cloud.ai.example.deepresearch.node; import com.alibaba.cloud.ai.example.deepresearch.model.ParallelEnum; import com.alibaba.cloud.ai.example.deepresearch.model.dto.Plan; import com.alibaba.cloud.ai.example.deepresearch.util.StateUtil; import com.alibaba.cloud.ai.example.deepresearch.config.DeepResearchProperties; import com.alibaba.cloud.ai.graph.OverAllState; import com.alibaba.cloud.ai.graph.action.NodeAction; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.util.CollectionUtils; import org.springframework.util.StringUtils; import java.util.Map; /** * @author sixiyida * @since 2025/6/12 */ public class ParallelExecutorNode implements NodeAction { private static final Logger logger = LoggerFactory.getLogger(ParallelExecutorNode.class); private final Map\u0026lt;String, Integer\u0026gt; parallelNodeCount; public ParallelExecutorNode(DeepResearchProperties properties) { this.parallelNodeCount = properties.getParallelNodeCount(); } @Override public Map\u0026lt;String, Object\u0026gt; apply(OverAllState state) throws Exception { long currResearcher = 0; long currCoder = 0; Plan curPlan = StateUtil.getPlan(state); for (Plan.Step step : curPlan.getSteps()) { // 跳过不需要处理的步骤 if (StringUtils.hasText(step.getExecutionRes()) || StringUtils.hasText(step.getExecutionStatus())) { continue; } Plan.StepType stepType = step.getStepType(); switch (stepType) { case PROCESSING: if (areAllResearchStepsCompleted(curPlan)) { step.setExecutionStatus(assignRole(stepType, currCoder)); currCoder = (currCoder + 1) % parallelNodeCount.get(ParallelEnum.RESEARCHER.getValue()); } logger.info(\u0026#34;Waiting for remaining research steps executed\u0026#34;); break; case RESEARCH: step.setExecutionStatus(assignRole(stepType, currResearcher)); currResearcher = (currResearcher + 1) % parallelNodeCount.get(ParallelEnum.CODER.getValue()); break; // 处理其他可能的StepType default: logger.debug(\u0026#34;Unhandled step type: {}\u0026#34;, stepType); } } return Map.of(); } private String assignRole(Plan.StepType type, long executorId) { String role = type == Plan.StepType.PROCESSING ? ParallelEnum.CODER.getValue() : ParallelEnum.RESEARCHER.getValue(); return StateUtil.EXECUTION_STATUS_ASSIGNED_PREFIX + role + \u0026#34;_\u0026#34; + executorId; } private boolean areAllResearchStepsCompleted(Plan plan) { if (CollectionUtils.isEmpty(plan.getSteps())) { return true; } return plan.getSteps() .stream() .filter(step -\u0026gt; step.getStepType() == Plan.StepType.RESEARCH) .allMatch(step -\u0026gt; step.getExecutionStatus().startsWith(StateUtil.EXECUTION_STATUS_COMPLETED_PREFIX)); } } 1.3.2.2 ResearcherNode 主要任务：执行step，流式返回，更新状态。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 /* * Copyright 2025 the original author or authors. * * Licensed under the Apache License, Version 2.0 (the \u0026#34;License\u0026#34;); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * https://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \u0026#34;AS IS\u0026#34; BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.alibaba.cloud.ai.example.deepresearch.node; import com.alibaba.cloud.ai.example.deepresearch.model.dto.Plan; import com.alibaba.cloud.ai.example.deepresearch.util.StateUtil; import com.alibaba.cloud.ai.graph.OverAllState; import com.alibaba.cloud.ai.graph.action.NodeAction; import com.alibaba.cloud.ai.graph.streaming.StreamingChatGenerator; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.ai.chat.client.ChatClient; import org.springframework.ai.chat.messages.Message; import org.springframework.ai.chat.messages.UserMessage; import org.springframework.util.StringUtils; import java.util.ArrayList; import java.util.HashMap; import java.util.List; import java.util.Map; import java.util.Objects; /** * @author sixiyida * @since 2025/6/14 11:17 */ public class ResearcherNode implements NodeAction { private static final Logger logger = LoggerFactory.getLogger(ResearcherNode.class); private final ChatClient researchAgent; private final String executorNodeId; private final String nodeName; public ResearcherNode(ChatClient researchAgent) { this(researchAgent, \u0026#34;0\u0026#34;); } public ResearcherNode(ChatClient researchAgent, String executorNodeId) { this.researchAgent = researchAgent; this.executorNodeId = executorNodeId; this.nodeName = \u0026#34;researcher_\u0026#34; + executorNodeId; } @Override public Map\u0026lt;String, Object\u0026gt; apply(OverAllState state) throws Exception { logger.info(\u0026#34;researcher node {} is running.\u0026#34;, executorNodeId); Plan currentPlan = StateUtil.getPlan(state); List\u0026lt;String\u0026gt; observations = StateUtil.getMessagesByType(state, \u0026#34;observations\u0026#34;); Map\u0026lt;String, Object\u0026gt; updated = new HashMap\u0026lt;\u0026gt;(); Plan.Step assignedStep = null; for (Plan.Step step : currentPlan.getSteps()) { if (Plan.StepType.RESEARCH.equals(step.getStepType()) \u0026amp;\u0026amp; !StringUtils.hasText(step.getExecutionRes()) \u0026amp;\u0026amp; StringUtils.hasText(step.getExecutionStatus()) \u0026amp;\u0026amp; step.getExecutionStatus().equals(StateUtil.EXECUTION_STATUS_ASSIGNED_PREFIX + nodeName)) { assignedStep = step; break; } } // 如果没有找到分配的步骤，直接返回 if (assignedStep == null) { logger.info(\u0026#34;No remaining steps to be executed by {}\u0026#34;, nodeName); return updated; } // 标记步骤为正在执行 assignedStep.setExecutionStatus(StateUtil.EXECUTION_STATUS_PROCESSING_PREFIX + nodeName); // 添加任务消息 List\u0026lt;Message\u0026gt; messages = new ArrayList\u0026lt;\u0026gt;(); Message taskMessage = new UserMessage(String.format(\u0026#34;# Current Task\\n\\n##title\\n\\n%s\\n\\n##description\\n\\n%s\u0026#34;, assignedStep.getTitle(), assignedStep.getDescription())); messages.add(taskMessage); // 添加研究者特有的引用提醒 Message citationMessage = new UserMessage( \u0026#34;IMPORTANT: DO NOT include inline citations in the text. Instead, track all sources and include a References section at the end using link reference format. Include an empty line between each citation for better readability. Use this format for each reference:\\n- [Source Title](URL)\\n\\n- [Another Source](URL)\u0026#34;); messages.add(citationMessage); logger.debug(\u0026#34;researcher Node messages: {}\u0026#34;, messages); // 调用agent var streamResult = researchAgent.prompt().messages(messages).stream().chatResponse(); Plan.Step finalAssignedStep = assignedStep; logger.info(\u0026#34;ResearcherNode {} starting streaming with key: {}\u0026#34;, executorNodeId, \u0026#34;researcher_llm_stream_\u0026#34; + executorNodeId); var generator = StreamingChatGenerator.builder() .startingNode(\u0026#34;researcher_llm_stream_\u0026#34; + executorNodeId) .startingState(state) .mapResult(response -\u0026gt; { finalAssignedStep.setExecutionStatus(StateUtil.EXECUTION_STATUS_COMPLETED_PREFIX + executorNodeId); String researchContent = response.getResult().getOutput().getText(); finalAssignedStep.setExecutionRes(Objects.requireNonNull(researchContent)); logger.info(\u0026#34;{} completed, content: {}\u0026#34;, nodeName, researchContent); observations.add(researchContent); updated.put(\u0026#34;observations\u0026#34;, observations); updated.put(\u0026#34;researcher_content_\u0026#34; + executorNodeId, List.of(researchContent)); return updated; }) .build(streamResult); updated.put(\u0026#34;researcher_content_\u0026#34; + executorNodeId, generator); return updated; } } 1.3.2.3 CoderNode 同上，跳过。\n1.4 Graph Core修改 主要问题：不支持并行流式处理。\n1.4.1 调用链路分析 我们来看看目前的流式返回是如何实现的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 var generator = StreamingChatGenerator.builder() .startingNode(\u0026#34;researcher_llm_stream_\u0026#34; + executorNodeId) .startingState(state) .mapResult(response -\u0026gt; { finalAssignedStep.setExecutionStatus(StateUtil.EXECUTION_STATUS_COMPLETED_PREFIX + executorNodeId); String researchContent = response.getResult().getOutput().getText(); finalAssignedStep.setExecutionRes(Objects.requireNonNull(researchContent)); logger.info(\u0026#34;{} completed, content: {}\u0026#34;, nodeName, researchContent); observations.add(researchContent); updated.put(\u0026#34;observations\u0026#34;, observations); updated.put(\u0026#34;researcher_content_\u0026#34; + executorNodeId, List.of(researchContent)); return updated; }) .build(streamResult); updated.put(\u0026#34;researcher_content_\u0026#34; + executorNodeId, generator); 以上代码来自researcherNode，返回一个Map后，我们来看是在哪里执行的。\n1.4.1.1 入口接口 1 2 3 4 5 6 7 8 9 10 11 @RequestMapping(value = \u0026#34;/chat/stream\u0026#34;, method = RequestMethod.POST, produces = MediaType.TEXT_EVENT_STREAM_VALUE) public Flux\u0026lt;ServerSentEvent\u0026lt;String\u0026gt;\u0026gt; chatStream(@RequestBody(required = false) ChatRequest chatRequest) throws GraphRunnerException { //... else { ChatRequestProcess.initializeObjectMap(chatRequest, objectMap); logger.info(\u0026#34;init inputs: {}\u0026#34;, objectMap); AsyncGenerator\u0026lt;NodeOutput\u0026gt; resultFuture = compiledGraph.stream(objectMap, runnableConfig); graphProcess.processStream(resultFuture, sink); } } 这是一个Controller接口，可以看到，图是从这个方法进去的compiledGraph.stream(objectMap, runnableConfig);。\n我们来看看具体实现：\n1 2 3 4 5 public AsyncGenerator\u0026lt;NodeOutput\u0026gt; stream(Map\u0026lt;String, Object\u0026gt; inputs, RunnableConfig config) throws GraphRunnerException { Objects.requireNonNull(config, \u0026#34;config cannot be null\u0026#34;); final AsyncNodeGenerator\u0026lt;NodeOutput\u0026gt; generator = new AsyncNodeGenerator\u0026lt;\u0026gt;(stateCreate(inputs), config); return new AsyncGenerator.WithEmbed\u0026lt;\u0026gt;(generator); } 这个地方返回了一个AsyncGenerator.WithEmbed，这玩意是什么呢？\n简而言之，这个东西是一个允许其他的AsyncGenerator在其执行过程中执行的包装类。\n执行流程是：\n从堆栈顶部获取当前生成器\n调用当前生成器的next()方法获取结果\n如果结果表示生成器已完成：\n清除之前的返回值（如果有）\n将结果推入返回值堆栈\n执行完成回调（如果有）\n如果这是最后一个生成器，返回结果\n否则，弹出当前生成器，递归调用next()继续处理下一个生成器\n如果结果包含一个嵌入生成器： 检查嵌套深度（目前不支持递归嵌套）\n将嵌入生成器推入堆栈\n递归调用next()处理嵌入生成器\n否则，直接返回结果 看看具体实现：\n1 2 protected final Deque\u0026lt;Embed\u0026lt;E\u0026gt;\u0026gt; generatorsStack = new ArrayDeque\u0026lt;\u0026gt;(2); private final Deque\u0026lt;Data\u0026lt;E\u0026gt;\u0026gt; returnValueStack = new ArrayDeque\u0026lt;\u0026gt;(2); 首先核心数据结构是利用这两个双端队列维护返回值和生成器栈。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @Override public Data\u0026lt;E\u0026gt; next() { if (generatorsStack.isEmpty()) { // GUARD throw new IllegalStateException(\u0026#34;no generator found!\u0026#34;); } final Embed\u0026lt;E\u0026gt; embed = generatorsStack.peek(); final Data\u0026lt;E\u0026gt; result = embed.generator.next(); if (result.isDone()) { clearPreviousReturnsValuesIfAny(); returnValueStack.push(result); if (embed.onCompletion != null) { try { embed.onCompletion.accept(result.resultValue); } catch (Exception e) { return Data.error(e); } } if (isLastGenerator()) { return result; } generatorsStack.pop(); return next(); } if (result.embed != null) { if (generatorsStack.size() \u0026gt;= 2) { return Data.error(new UnsupportedOperationException( \u0026#34;Currently recursive nested generators are not supported!\u0026#34;)); } generatorsStack.push(result.embed); return next(); } return result; } 这个方法是核心方法，递归地处理了嵌入的生成器。\n1.4.1.2 状态流转 然后我们来看看AsyncNodeGenerator的实现：\n核心方法是next，其实现了状态图流转。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 @Override public Data\u0026lt;o\u0026gt; next() { try { // 检查最大迭代次数 if (++iteration \u0026gt; maxIterations) { return Data.error(new IllegalStateException( format(\u0026#34;Maximum number of iterations (%d) reached!\u0026#34;, maxIterations))); } // 检查是否已结束 if (nextNodeId == null \u0026amp;\u0026amp; currentNodeId == null) { return releaseThread().map(Data::\u0026lt;o\u0026gt;done).orElseGet(() -\u0026gt; Data.done(currentState)); } // 是否从嵌入恢复 if (resumedFromEmbed) { final CompletableFuture\u0026lt;o\u0026gt; future = getNodeOutput(); resumedFromEmbed = false; return Data.of(future); } // 处理START节点 if (START.equals(currentNodeId)) { doListeners(START, null); var nextNodeCommand = getEntryPoint(currentState, config); nextNodeId = nextNodeCommand.gotoNode(); currentState = nextNodeCommand.update(); var cp = addCheckpoint(config, START, currentState, nextNodeId); var output = (cp.isPresent() \u0026amp;\u0026amp; config.streamMode() == StreamMode.SNAPSHOTS) ? buildStateSnapshot(cp.get()) : buildNodeOutput(currentNodeId); currentNodeId = nextNodeId; return Data.of(output); } // 处理END节点 if (END.equals(nextNodeId)) { nextNodeId = null; currentNodeId = null; doListeners(END, null); return Data.of(buildNodeOutput(END)); } // 检查中断条件 if (shouldInterruptAfter(currentNodeId, nextNodeId)) { return Data.done(currentNodeId); } if (shouldInterruptBefore(nextNodeId, currentNodeId)) { return Data.done(currentNodeId); } // 更新当前节点ID currentNodeId = nextNodeId; // 获取当前节点对应的动作 var action = nodes.get(currentNodeId); if (action == null) throw RunnableErrors.missingNode.exception(currentNodeId); // 执行节点动作 return evaluateAction(action, this.overAllState).get(); } catch (Exception e) { doListeners(ERROR, e); log.error(e.getMessage(), e); return Data.error(e); } } 其中evaluateAction执行了nodeAction，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 private Command nextNodeId(String nodeId, OverAllState overAllState, Map\u0026lt;String, Object\u0026gt; state, RunnableConfig config) throws Exception { EdgeValue route = edges.get(nodeId); if (route == null) { throw RunnableErrors.missingEdge.exception(nodeId); } // 如果边有固定的目标ID if (route.id() != null) { return new Command(route.id(), state); } // 如果边有条件逻辑 if (route.value() != null) { // 执行边的条件动作 var command = route.value().action().apply(overAllState, config).get(); var newRoute = command.gotoNode(); // 根据条件结果查找映射的目标节点 String result = route.value().mappings().get(newRoute); if (result == null) { throw RunnableErrors.missingNodeInEdgeMapping.exception(nodeId, newRoute); } // 更新状态 var currentState = OverAllState.updateState(state, command.update(), keyStrategyMap); overAllState.updateState(command.update()); return new Command(result, currentState); } throw RunnableErrors.executionError.exception(format(\u0026#34;invalid edge value for nodeId: [%s] !\u0026#34;, nodeId)); } 下一个节点由nextNodeId方法决定：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 private Command nextNodeId(String nodeId, OverAllState overAllState, Map\u0026lt;String, Object\u0026gt; state, RunnableConfig config) throws Exception { EdgeValue route = edges.get(nodeId); if (route == null) { throw RunnableErrors.missingEdge.exception(nodeId); } // 如果边有固定的目标ID if (route.id() != null) { return new Command(route.id(), state); } // 如果边有条件逻辑 if (route.value() != null) { // 执行边的条件动作 var command = route.value().action().apply(overAllState, config).get(); var newRoute = command.gotoNode(); // 根据条件结果查找映射的目标节点 String result = route.value().mappings().get(newRoute); if (result == null) { throw RunnableErrors.missingNodeInEdgeMapping.exception(nodeId, newRoute); } // 更新状态 var currentState = OverAllState.updateState(state, command.update(), keyStrategyMap); overAllState.updateState(command.update()); return new Command(result, currentState); } throw RunnableErrors.executionError.exception(format(\u0026#34;invalid edge value for nodeId: [%s] !\u0026#34;, nodeId)); } ","date":"2025-06-06T00:00:00Z","permalink":"https://sixiyida.github.io/p/spring-ai-alibaba%E7%BB%B4%E6%8A%A4%E8%AE%B0%E5%BD%95/","title":"spring-ai-alibaba维护记录"},{"content":"分库分表和分页 1. 分表（Table Sharding） 定义：将单张数据表按特定规则（如哈希、范围）拆分为多个结构相同的小表，存储在同一数据库或不同数据库中\n目的：解决单表数据量过大导致的查询性能下降（如索引膨胀、磁盘I/O瓶颈）\n适用场景：单表数据超千万级，但数据库实例资源未达瓶颈\n2. 分库（Database Sharding） 定义：将整个数据库按业务或数据维度拆分为多个独立的数据库实例，每个实例存储部分数据\n目的：解决单库连接数不足、磁盘空间不足、写并发压力大等问题\n适用场景：单库QPS过高、连接数耗尽或需故障隔离\n3. 分片（Sharding） 定义：分库+分表的组合策略，将数据按规则（如哈希、范围）分布到多个数据库节点（分片），每个节点包含部分库和表。\n目的：实现真正的水平扩展，支持海量数据与高并发\n适用场景：超大规模数据（TB/PB级）、需全局负载均衡\n核心区别总结 维度 分表 分库 分片 拆分对象 单张表 整个数据库实例 库+表组合的分布式节点 主要目标 解决单表性能瓶颈 解决单库资源瓶颈 全局水平扩展与高可用 数据分布 表内数据拆分 库间数据隔离 跨节点数据分片 典型场景 大表查询优化 高并发写入/连接数不足 超大规模系统（如社交平台） ","date":"2025-06-02T00:00:00Z","permalink":"https://sixiyida.github.io/p/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/","title":"系统设计"},{"content":"0. 前言 花了5天时间是跟着做完了黑马点评项目。虽说是烂大街项目之一，但我还是学到了不少东西。这个项目让我第一次看到了后端的全貌。这篇文章会记录我优化这个项目的过程，涉及中间件、功能拓展、LLM的引入等。\n1. 引入消息队列中间件 在项目的秒杀业务中，优惠券下单和数据持久化至数据库利用Redis Stream实现的消息队列解耦，优势主要在：\n简化下单流程，提高系统响应速度。 提高并发量和鲁棒性，防止数据库击穿。 1.1 为什么引入消息队列中间件？ 持久化：Redis Stream依赖AOF/RDB持久化，主从切换时异步复制可能导致数据丢失；消息队列中间件，如RocketMQ，同步刷盘+多副本（RAFT协议），提供金融级可靠性。\n消息积压：\n能力 Redis Stream 专业消息队列 存储介质 内存（成本高） 磁盘（成本低） 积压容忍度 需设置MAXLEN截断旧消息 支持TB级堆积（如Kafka） 内存风险 可能触发OOM（需手动扩内存） 磁盘空间自动扩容无压力 运维与生态：专业消息队列工具链更完善。\n高级功能：消息队列中间件引入了延迟队列、死信路由等企业级特性。\n1.2 引入哪一种？ 三种中间件对比：\n能力维度 RabbitMQ Kafka RocketMQ 吞吐量 万级 TPS 百万级 TPS 十万级 TPS 延迟 微秒级 毫秒级（批处理设计） 毫秒级 事务支持 轻量级事务（同步阻塞） 支持（≥0.11 版本） 分布式事务消息 顺序性保障 单队列有序 分区内有序 队列/分区严格有序 可靠性机制 镜像队列+持久化 多副本+ISR 同步刷盘+多副本+RAFT 协议 秒杀核心优势 削峰填谷、异步解耦 超高吞吐、日志流处理 高并发+强一致性+低延迟 结论：选择RocketMQ，秒杀场景在需要高吞吐量的同时，需要强一致性和可靠性。同时RocketMQ支撑阿里多次双十一活动，非常无敌，必须喽他。\n1.3 引入RocketMQ 1.3.1 部署RocketMQ 由于本人太穷，服务器只有2核2G，但又不想妥协用轻量级的MQ，为验证项目逻辑，在本地Windows环境部署RocketMQ。\n下载跳过。\n配置环境变量：\n1 2 %ROCKETMQ_HOME% = ...\\rocketmq-all-5.3.3-bin-release %NAMESRV_ADDR% = localhost:9876 启动NameServer和Broker：\n1 2 3 cd %ROCKETMQ_HOME% bin/mqnamesrv bin/mqbroker -n localhost:9876 测试生产消费：\n1 2 bin/tools org.apache.rocketmq.example.quickstart.Producer bin/tools org.apache.rocketmq.example.quickstart.Consumer 1.3.2 引入Java客户端依赖 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.rocketmq\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;rocketmq-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 1.3.3 修改applications.yml 1 2 3 4 5 rocketmq: name-server: http://localhost:9876 producer: group: ${spring.application.name} send-message-timeout: 3000 1.4 架构更新 目前架构：\n主线程：Lua(Redis校验下单资格 -\u0026gt; 创建订单至Redis) -\u0026gt; 向异步线程阻塞队列提交订单\n子线程：异步线程获取分布式锁 -\u0026gt; 持久化至数据库(Transactional) -\u0026gt; 解锁\n其中分布式锁的设计是原本在多台Tomcat下，会导致重复下单问题。但现在Redis由于是串行化的，无论多少台Tomcat都不会出现并发问题，且MQ也将创建订单的消息串行化了，故分布式锁可以取消。\n更新后架构：\n主线程：Lua(Redis校验下单资格 -\u0026gt; 创建订单至Redis) -\u0026gt; 向MQ生产订单消息\n子线程：消费MQ消息 -\u0026gt; 持久化至数据库(Transactional)\n需要注意的是，在秒杀场景下，用户不应该为DB的错误买单，而且分布式事务违背了异步下单提高性能的初衷。故如果DB更新失败，不应该回滚Redis，而是应该重试DB更新操作。\n1.5 RocketMQ分布式事务逻辑 1.6 代码实现 1.6.1 MQ配置类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @Configuration public class RocketMQConfig { @Value(\u0026#34;${rocketmq.name-server}\u0026#34;) private String nameServer; // 事务消息生产者 @Bean(initMethod = \u0026#34;start\u0026#34;, destroyMethod = \u0026#34;shutdown\u0026#34;) public TransactionMQProducer transactionProducer() { TransactionMQProducer producer = new TransactionMQProducer(\u0026#34;voucher_order_group\u0026#34;); producer.setNamesrvAddr(nameServer); producer.setTransactionListener(transactionListener()); // 绑定事务监听器 return producer; } // 事务监听器实现 @Bean public TransactionListener transactionListener() { return new VoucherOrderTransactionListener(); } } 简单，跳过。\n1.6.2 订单事务监听器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @Component public class VoucherOrderTransactionListener implements TransactionListener { @Lazy @Resource private VoucherOrderServiceImpl voucherOrderService; // 执行本地事务（订单创建） @Override public LocalTransactionState executeLocalTransaction(Message msg, Object arg) { try { VoucherOrder order = JSON.parseObject(msg.getBody(), VoucherOrder.class); voucherOrderService.createVoucherOrder(order); // 调用订单创建方法 return LocalTransactionState.COMMIT_MESSAGE; } catch (Exception e) { voucherOrderService.rollbackRedis(order.getVoucherId(), order.getUserId()); // 非数据库操作导致的回滚 return LocalTransactionState.ROLLBACK_MESSAGE; } } // 事务回查（防止本地事务未提交） @Override public LocalTransactionState checkLocalTransaction(MessageExt msg) { String orderId = msg.getKeys(); VoucherOrder order = voucherOrderService.getById(orderId); return order != null ? LocalTransactionState.COMMIT_MESSAGE : LocalTransactionState.ROLLBACK_MESSAGE; } } 这里几个关键点：\n@Lazy：由于Service中注入了transactionProducer，而其依赖配置类中创建的TransactionListener，故产生循环依赖，需要使用懒加载打破循环依赖。\n回滚：如注释。\n1.6.3 修改秒杀下单逻辑 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 @Resource private TransactionMQProducer transactionProducer; @Override public Result seckillVoucher(Long voucherId) { Long userId = UserHolder.getUser().getId(); Long result = stringRedisTemplate.execute( SECKILL_SCRIPT, Collections.emptyList(), voucherId.toString(), userId.toString() ); int r = result.intValue(); if (r != 0) { return Result.fail(r == 1 ? \u0026#34;库存不足\u0026#34; : \u0026#34;不能重复下单\u0026#34;); } // 保存order VoucherOrder order = new VoucherOrder(); order.setId(redisIdWorker.nextId(\u0026#34;order\u0026#34;)); order.setUserId(UserHolder.getUser().getId()); order.setVoucherId(voucherId); // 构造消息 Message msg = new Message(\u0026#34;voucher_order_topic\u0026#34;, JSON.toJSONBytes(order)); msg.setKeys(order.getId().toString()); try { transactionProducer.sendMessageInTransaction(msg, null); } catch (MQClientException e) { log.error(\u0026#34;MQ错误\u0026#34;); } return Result.ok(order.getId()); } @Transactional public void createVoucherOrder(VoucherOrder voucherOrder) { Long userId = voucherOrder.getUserId(); Long voucherId = voucherOrder.getVoucherId(); boolean success = seckillVoucherService.update() .setSql(\u0026#34;stock = stock - 1\u0026#34;) .eq(\u0026#34;voucher_id\u0026#34;, voucherId) .gt(\u0026#34;stock\u0026#34;, 0) // CAS乐观锁 .update(); if (!success) { // 数据库操作失败 // 1. 删除购买记录 String key = RedisConstants.SECKILL_ORDER_KEY + voucherId; stringRedisTemplate.opsForSet().remove(key, userId.toString()); // 2. 恢复预扣库存 stringRedisTemplate.opsForValue() .increment(RedisConstants.SECKILL_STOCK_KEY + voucherId, 1); throw new RuntimeException(\u0026#34;数据库扣减失败\u0026#34;); } save(voucherOrder); } //幂等Redis回滚 public void rollbackRedis(Long voucherId, Long userId) { String luaScript = \u0026#34;local orderKey = KEYS[1] \u0026#34; + \u0026#34;local stockKey = KEYS[2] \u0026#34; + \u0026#34;local userId = ARGV[1] \u0026#34; + // 只回滚存在的订单记录 \u0026#34;if redis.call(\u0026#39;sismember\u0026#39;, orderKey, userId) == 1 then \u0026#34; + \u0026#34; redis.call(\u0026#39;srem\u0026#39;, orderKey, userId) \u0026#34; + \u0026#34; redis.call(\u0026#39;incr\u0026#39;, stockKey) \u0026#34; + // 库存+1 \u0026#34; return 1 \u0026#34; + \u0026#34;else \u0026#34; + \u0026#34; return 0 \u0026#34; + // 已处理或无记录 \u0026#34;end\u0026#34;; String orderKey = RedisConstants.SECKILL_ORDER_KEY + voucherId; String stockKey = RedisConstants.SECKILL_STOCK_KEY + voucherId; // 执行Lua脚本 Long result = stringRedisTemplate.execute( new DefaultRedisScript\u0026lt;\u0026gt;(luaScript, Long.class), Arrays.asList(orderKey, stockKey), userId.toString() ); log.debug(\u0026#34;回滚结果: {}\u0026#34;, result); } ","date":"2025-06-01T00:00:00Z","permalink":"https://sixiyida.github.io/p/%E7%82%B9%E8%AF%84%E9%A1%B9%E7%9B%AE%E4%BC%98%E5%8C%96/","title":"点评项目优化"},{"content":"@Configuration和@Component @Configuration自身也是一个Bean，默认启用 CGLIB 代理（proxyBeanMethods=true）。当配置类中的 @Bean 方法相互调用时，Spring 会拦截调用并返回容器中的单例 Bean，而非重新创建，可直接注入方法参数的Bean。\n1 2 3 4 5 6 7 @Configuration public class Config { @Bean public A a() { return new A(); } @Bean public B b() { return new B(a()); } // 注入容器中的单例A } @Component无代理机制。方法间调用视为普通 Java 方法，每次调用 @Bean 方法都会创建新实例，破坏单例， 依赖注入需要显式@Autowired：\n1 2 3 4 5 6 7 @Component public class ComponentConfig { @Bean public A a() { return new A(); } @Bean public B b() { return new B(a()); } // 每次调用a()创建新实例！ } @PathVariable 1 2 3 4 @GetMapping(\u0026#34;/{id}\u0026#34;) public Result queryBlogById(@PathVariable(\u0026#34;id\u0026#34;) Long id) { } 将url的值绑定至方法参数中。\n","date":"2025-05-30T00:00:00Z","permalink":"https://sixiyida.github.io/p/spring%E7%9B%B8%E5%85%B3/","title":"Spring相关"},{"content":"为什么需要消息队列？ 在异步任务，如生产者-消费者模型中，两者的运行速度并不相同，使用消息队列可以做一个缓冲，减小系统压力。\nRedis消息队列 1. 基于List Redis的list数据结构是一个双向链表，利用LPUSH和RPOP实现，若需要阻塞，使用BRPOP实现阻塞队列效果\n缺陷：每次取出消息直接从队列中移除，造成\n无法避免消息丢失：移除后如果宕机，则消息丢失。 无法有多消费者：只能消费一次并移除，无法多次消费。 2. 基于Pub/Sub 类似ROS：\n1 2 3 SUBSCRIBE channel [channel] PUBLISH channel msg PSUBSCRIBE pattern [pattern] // 订阅匹配pattern的所有频道 缺陷：每次取出消息直接从队列中移除，造成\n不支持数据持久化：数据不在Redis（内存）中保存。 无法避免消息丢失：如上。 消息堆积有上限，超出时丢失：只在消费者处缓存，有上限。 3. 基于Stream Stream是一种为消息队列设计的数据类型。\n基本添加/读取消息 1 XADD users * name jack age 21 // 向user发{name = jack, age = 21} 1 XREAD COUNT 1 BLOCK 2000 STREAMS users $ // 读users最新的1个消息，无消息阻塞2秒 消费者组 特点：\n消息分流：队列中消息分流而不是重复消费，加快速度。 消息表示：记录最后一个被处理的消息，宕机后也能恢复。 消息确认：消息被获取后存入pending-list，必须要消费者使用XACK确认消息，才会移除。 1 2 3 4 5 6 7 8 9 10 11 XGROUP CREATE mqName groupName ID [MKSTREAM] // ID(0):第一个消息/ID($):最后一个消息 // 为mqName创建名为groupName的消费者组 XGROUP DESTROY mqName groupName XGROUP CREATECONSUMER mqName groupName consumerName XGROUP DELCONSUMER mqName groupName consumerName XREADGROUP GROUP group consumer [COUNT count] [BLOCK milliseconds] [NOACK] STREAMS mqName [mqName ...] ID [ID ...] //ID为获取消息起始id //\u0026#34;\u0026gt;\u0026#34; : 从未消费消息开始 //“数字”: 从pending-list中第一个消息开始 RocketMQ NameServer-Broker NameServer 是 轻量级的服务注册与发现中心，类似于分布式系统中的“电话簿”或“目录服务”。\nBroker 是消息队列中实际存储、转发消息的核心角色。它是生产者和消费者直接打交道的节点，真正处理消息的存储、查询、投递等操作。\n","date":"2025-05-28T00:00:00Z","permalink":"https://sixiyida.github.io/p/message-queue/","title":"Message Queue"},{"content":"锁 行级锁 **行级锁：**在select for update等场景，即当前读（另一种是快照读MVCC）场景使用。\n包括Record Lock, Gap Lock 和 Next-key Lock(前两种的合并)\n包括X(Exclusive)和S(share)两种\nGap Lock是只锁相邻两条记录之间的()，NK-lock是锁(]\nGap Lock的X和S型是一样的，都可以重复获取，NK-lock要看右区间的记录锁是否互斥，无限除外。\n怎么加？（MySQL8.0.26, 可重复读） 对索引加，基本单位是nk-lock，不同情况可能出现退化为前两种\n主键索引等值查询：\n记录存在-\u0026gt;退化为记录\n记录不存在-\u0026gt;退化为间隙锁\n1 select * from performance_schema.data_locks //查加了什么锁 如果MODE是GAP， LOCK_DATA是右区间界。\n主键索引范围查询：\n大于：不退化\n大于等于：如果等于存在，则左边退化为记录锁，不存在则不退化\n小于：最右侧退化为间隙锁\n小于等于：若等于存在，则不退化，不存在则最右侧退化为间隙锁\n**注：**记录锁属于记录，在GAP锁中是属于LOCK_DATA，右区间界的记录。\n二级索引（非唯一）等值查询：\n记录不存在：二级索引上GAPLOCK，对于左右端点，能否插入要看二级索引B+树下一条记录有无GAPLOCK\n记录不存在的特殊情况：如果是超过了最大id，是next-keyLock\n注：二级索引GAPLOCK的LOCK_DATA包含两个值，二级索引和回表的主键索引\n记录存在：对二级索引匹配的记录加nk锁，对不匹配的第一个nk锁退化为间隙锁，且在主键索引加记录锁。\n对于端点是否能插入，和要看二级索引B+树下一条记录有无LOCK\n在不匹配的第一个索引加nk锁的目的：防止幻读（id \u0026gt; lock_id）的情况\n二级索引（非唯一）范围查询：不退化，二级的nk和主键的记录锁都加\n如果不走索引全表扫描，则所有记录全部加nk锁，全锁，是事故\n解决方案：将sql_safe_updates设置为1，此时必须使用where+索引 / limit\n当前读的语句：update、delete、select for update，会加意向锁和行锁\n死锁的形成 例子：如果两个事务都获取了间隔锁，且希望插入对方间隔，则尝试获取插入意向锁（和间隔锁互斥），环路等待导致死锁。\ninsert语句加行级锁 **记录之间有间隙锁：**加插入意向锁\n注：mysql的锁是先生成锁结构，锁此时是等待状态，再获取锁，如果不能获取则阻塞。\n**唯一键（主键或唯一二级索引）冲突：**失败后加S型锁\n主键：加S记录锁\n唯一二级索引：加S型NK锁\n例子：在select for update中，尝试加X型锁，和S型冲突，所以失败。\n并发insert导致的唯一键冲突\n第一个insert但事务没提交时，构造隐式锁。\n第二个insert时，隐式锁变成X型锁，和第二个insert想要获取的S型nk锁冲突\n避免死锁的方法 设置事务等待回滚时间：超时回滚\n1 innodb_lock_wait_timeout = 50 // default 开启主动死锁检测：主动回滚\n1 innodb_deadlock_detect = on 日志 保证ACID特性：Atomic, Consisitency, isolation, duration\nundo log 注：对于增删改语句，innodb会隐式启动事务。\n特殊处理：delete只在记录上打标记，真正删除由purge线程完成\nupdate非主键列：直接update，且在undolog中记录update之前的值\nupdate主键列：先删再插\nundolog的存储形式：由roll_pointer指针形成链表穿起来\nbufferpool 指的是innodb引擎中的内存bufferpool。\n类似于pagecache，由后台线程实现脏页写回机制。\n内存结构：首先申请连续的内存空间，接着按照16kb大小划分出缓存页。\n包括数据页、索引页、undo页、插入缓存页、自适应哈希索引、锁信息等。\nredolog **redolog的作用：**对修改实现持久化。\nWAL技术(write-ahead logging)：在写入磁盘之前先写入redolog。\n每对Bufferpool进行修改就写入redolog，包括undolog的修改\nredolog和undolog对比：\nredolog是记录修改后，保证持久化\nundolog是记录修改前，保证原子化\n写入数据和写入redolog对比：\nredolog：是顺序写入，高效\n数据：是随机写入，低效\nredolog也有buffer，落盘时机：\nmysql正常关闭，buffer空间超过一半，每一秒写回一次。\ninnodb_flush_log_at_trx_commit参数：提交事务时的行为\n0：不写回，后台线程每隔一秒用write()和fsync()\n1：直接持久化到磁盘\n2：写入文件（pagecache）由操作系统写回，后台线程每隔一秒用fsync()\nredolog存储方式：两个redolog文件循环存储类似于环形队列。\n有个tail和head，在tail处写，持久化bufferpool进入数据后更新head。\nbinlog Server层的日志， 用于备份恢复、主从复制。三种格式类型：\nSTATEMENT：记录SQL语句逻辑操作\nROW：记录行数据最终修改情况\nMIXED：根据情况使用STATEMENT或者ROW\n使用追加写，写满文件就创建新文件继续写，全量日志。\n主从复制 主库server层直接写入binlog，后台log dump线程异步将binlog日志发给从库，从库relaylog记录binlog，后台线程异步执行relaylog。\n**从库的数量选择：**对主库的资源消耗、网络带宽。\n其他模型：\n同步模型：要所有从库relaylog记录完毕后返回成功，主库再返回客户端。没法用\n异步模型：默认模型，主库宕机就gg\n半同步：一部分库返回成功即可。\nbinlog也有cache，每个线程各一个。\n持久化的时机：\nbinlog_cache_size：超过这个大小就写入\nsync_binlog：\n0：只write，操作系统控制写回\n1：write+fsync\nn：write，累积n个以后fsync\n注：binlog在语句执行完成后在记录。事务提交时候才持久化。\n两阶段提交 问题：如果redolog和binlog一个完成一个不完成，则会出现主从不一致的问题。\n内部XA事务：在事务提交后开启，由binlog协调。\n将redolog写入拆为prepare和commit，中间插入binlog持久化。\nprepare：将内部XID写入redolog并持久化，将状态设置为prepare。\ncommit：将内部XID写入binlog并持久化，接着将redolog设置为commit。\n崩溃时，redolog处于prepare状态，检查binlog中有无XA事务的id，有则提交事务，无则回滚。\n**问题：**性能差\n磁盘IO次数高\n在多事务下，不能保证两者提交顺序一致，需要加锁以保证提交的原子性\n上述问题：binlog组提交机制\n分为flush(write)、sync(fsync)、commit阶段，每个阶段都有队列，用锁保证事务写入顺序。\nredolog的组提交机制\n将redolog刷盘延迟到flush阶段中\nBufferPool default = 128MB\neach page 16kb\n结构：控制块1到n，接着page1到n\n注：查询时候直接将innodb的整个页加载至bufferpool中，然后在bufferpool中通过页目录定位记录\nFREE链表：管理空闲页，节点是控制块，头结点包括链表头尾地址和控制块数量。\nFLUSH链表：管理空闲页，节点是控制块，头结点包括链表头尾地址和控制块数量。\n如何管理bufferpool：\n传统LRU问题：\n**预读失效：**预读时会把相邻的数据页一并加载，为了减少磁盘IO，如果这些没有被访问，且淘汰末尾页，则降低缓存命中率。\n**解决方法：**划分LRU的优先级，前面是YOUNG，后面是OLD，预读先加入OLD，真正访问才加入YOUNG区域。\n**缓存污染：**当扫描大量数据，会淘汰大量热数据，导致命中率下降。\n**解决方法：**提高加入YOUNG的门槛，记录第一次OLD被访问的时间，如果后续访问时间超过第一次1s，则放入young区域。\n**Linux的做法：**第二次的时候将才升级到active，比MYSQL简单。\n","date":"2025-05-28T00:00:00Z","permalink":"https://sixiyida.github.io/p/mysql/","title":"MySQL"},{"content":"为什么需要分布式锁？ 在单JVM环境中，对于一人一单的场景，可以使用互斥锁实现。但是在负载均衡的集群场景中，需要全局锁，即分布式锁。\n常见的分布式锁实现方式：MySQL、Redis、Zookeeper。\nMySQL分布式锁实现方式：\n1.利用唯一索引，插入唯一键值成功则获取锁，释放锁则直接删除该记录。\n2.利用MySQL排他锁（SELECT FOR UPDATE），提交事务时释放锁。\nRedis分布式锁 加锁 1 SET lock thread1 NX EX 10 1 Boolean success = stringRedisTemplate.opsForValue().setIfAbsent(KEY_PREFIX + name, threadId + \u0026#34;\u0026#34;, timeoutSec, TimeUnit.SECONDS); 解锁 1 DEL lock 1 stringRedisTemplate.delete(KEY_PREFIX + name); 误删问题 由于可能出现线程阻塞超时自动释放，且锁在当前线程恢复之前被其他线程获取，该线程恢复之后如果直接释放锁，会释放其他线程获取的分布式锁，出现混乱。\n解决方法：\n判断锁所有权，再删除。问题：当判断所有权之后如果线程阻塞，同样会出现上述问题。 将1中操作变成原子的，使用Redis提供的Lua脚本。 1 2 3 4 if (redis.call(\u0026#39;get\u0026#39;, KEYS[1]) == ARGV[1]) then return redis.call(\u0026#39;del\u0026#39;, KEYS[1]) end return 0 1 2 3 4 5 stringRedisTemplate.execute( UNLOCK_SCRIPT, Collections.singletonList(KEY_PREFIX + name), threadId ); 基于setnx实现的分布式锁的问题 不可重入：同线程无法多次获取同一把锁，可能会导致同线程不同方法相互依赖导致死锁。 不可重试：获取锁失败没有重试机制 超时释放：执行时间长可能导致锁意外自动超时释放。 主从一致性：加锁后主节点宕机，从节点未同步，导致重复获取锁。 Redisson 基于Redis实现的分布式工具。\nStep0：Maven添加依赖\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.redisson\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;redisson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.22.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; **Step1：**注入RedissonClient\n1 2 3 4 5 6 7 8 9 10 11 @Configuration public class RedissonConfig { @Bean public RedissonClient redissonClient(){ Config config = new Config(); config.useSingleServer().setAddress(\u0026#34;redis://localhost:6379\u0026#34;).setPassword(\u0026#34;password\u0026#34;); return Redisson.create(config); } } **Step2：**使用工具\n1 RLock lock = redissonClient.getLock(RedisConstants.ORDER_LOCK_KEY + userId); Redisson分布式锁原理 基于Lua脚本的可重入 利用hash结构，记录线程id和引用次数。\n加锁：判断是否为当前线程id，如果是，则引用计数+1，重置锁有效期。\n解锁：判断是否为当前线程id，如果不是，不用处理；如果是，则引用计数-1并重置锁有效期。最后判断如果引用计数为0，则释放锁。\n可重试 在解锁时使用信号量/Pub，通知解锁。\n加锁失败后若有剩余等待时间，收到解锁信号后，异步重试。\n锁续期 加锁成功后启动后台线程Watchdog，每10秒检查锁是否被持有，若持有则续期为30秒。\nMultiLock 1 Rlock lock = redissonClient.getMulitLock(lock1, lock2, ...); 原理：\n获取锁：遍历获取 + 失败回滚\n建立锁List，遍历获取锁，遍历时分配每个锁的等待时间。\n若出现获取失败，则释放所有已经获取的锁，并返回失败。\n如果所有锁获取成功则返回成功。\n解锁：遍历释放 + 异常容忍\n遍历所有锁并逐一释放（无论是否属于当前线程）。\n即使某个锁释放失败（如锁已超时），仍继续释放其他锁，最大限度避免死锁。\n","date":"2025-05-28T00:00:00Z","permalink":"https://sixiyida.github.io/p/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","title":"Redis分布式锁"},{"content":"静态代码块初始化 1 2 3 4 5 static { UNLOCK_SCRIPT = new DefaultRedisScript\u0026lt;\u0026gt;(); UNLOCK_SCRIPT.setLocation(new ClassPathResource(\u0026#34;unlock.lua\u0026#34;)); UNLOCK_SCRIPT.setResultType(Long.class); } 在类首次加载时执行一次，如通过new创建对象、访问静态成员或反射加载类时触发\n多个静态代码块按定义顺序依次执行\n可以进行复杂逻辑初始化\n非静态成员变量初始化 在对象创建时完成，顺序为声明赋值 → 初始化块 → 构造函数，每种与代码书写顺序一致。\nSpringBoot中的classpath 一句话总结：classpath 等价于 main/java + main/resources + 第三方jar包的根目录。\n1 UNLOCK_SCRIPT.setLocation(new ClassPathResource(\u0026#34;unlock.lua\u0026#34;)); ClassPathResource对应main/resources目录下文件。\nAOP的内部调用问题 在使用AOP的场景中，如@Transactional，如果使用this指针调用内部方法，会绕过代理导致AOP失效。\n解决方法：\n使用AopContext.currentProxy()直接获取当前代理对象，原理是通过 ThreadLocal 存储当前线程的代理对象。 缺陷：在多线程场景下，如果子线程调用父线程的事务函数，由于ThreadLocal不互通，导致无法获取代理对象，事务失效。\n缺陷的解决方法：直接在主线程中将获取的代理对象传给子线程任务。\n直接使用@Autowired将自身注入。 **缺陷：**循环依赖风险，三级缓存性能低。\nRESTful API：PUT 更新或创建指定位置的资源。客户端需提供完整的资源数据，服务器会完全替换目标 URI 对应的资源。若资源不存在，则新建资源。\n与POST对比：\n特性 PUT POST 幂等性 ✅ 是（多次请求结果一致） ❌ 否（可能产生多个资源） URI 含义 资源唯一标识（如 /users/123） 资源集合（如 /users） 数据完整性 必须提供完整资源 可提交部分数据 典型响应码 200 OK（更新）或 201 Created（新建） 201 Created（新建资源） @Resource和@Autowired对比 @Resource流程\n指定name → 按名称查找 → 失败抛异常\n未指定name → 先按字段名匹配 → 失败则按类型匹配\n指定type → 按类型唯一匹配 → 多匹配抛异常\n@Autowired 流程\n按类型查找 → 找到唯一 Bean → 注入成功\n找到多个同类型 Bean → 需结合 @Qualifier(\u0026quot;beanName\u0026quot;) 指定名称\n无匹配且→ 注入required=false → 注入 null\no instanceof Node node的用法（Java 16+） 等于以下代码：\n1 2 3 if (o instanceof Node) { Node node = (Node) o; } record（Java 16+） 1 public record Person(String name, int age) {} 自动生成内容：\n全参构造器（如Person(String name, int age)） 字段访问器（如name()、age()，而非传统getName()） equals()、hashCode()、toString()方法 所有字段默认为final，实例化后不可修改\nthis() 调用其他构造函数 1 2 3 4 5 6 public record Edge(String sourceId, List\u0026lt;EdgeValue\u0026gt; targets) { // 构造函数 public Edge(String sourceId, EdgeValue target) { this(sourceId, List.of(target)); } } PECS原则 Producer Extends, Consumer Super.\n1 private static List\u0026lt;? extend K\u0026gt; produce() 原因：PE可以保证获取的至少是一个K，这样获取出来的可以直接用K来接，是类型安全的。\n1 private static consume(List\u0026lt;? super U\u0026gt;, U) 原因：CS可以保证接收消费对象的容器装的是其父类对象，可以保证传入的对象可以被向上转型，是类型安全的。\n自定义Collector Collector接口定义了5个核心方法，需全部实现：\nsupplier() 创建结果容器（如ArrayList::new），用于存储中间结果\naccumulator() 定义如何将元素添加到容器（如List::add），处理单个元素的累加逻辑\ncombiner() 合并并行流的子结果（如合并两个List：list1.addAll(list2)），需保证线程安全\nfinisher() 将中间容器转换为最终结果（如StringBuilder::toString），可进行最终转换或过滤\ncharacteristics() 返回收集器特性的Set，影响性能优化：\nCONCURRENT：支持多线程并发操作容器（需线程安全）\nUNORDERED：结果与元素顺序无关（如Set）\nIDENTITY_FINISH：跳过finisher()，直接返回中间容器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 private static \u0026lt;T, K, U\u0026gt; Collector\u0026lt;T, ?, Map\u0026lt;K, U\u0026gt;\u0026gt; toMapRemovingNulls(Function\u0026lt;? super T, ? extends K\u0026gt; keyMapper, Function\u0026lt;? super T, ? extends U\u0026gt; valueMapper, BinaryOperator\u0026lt;U\u0026gt; mergeFunction) { return Collector.of(HashMap::new, (map, element) -\u0026gt; { K key = keyMapper.apply(element); U value = valueMapper.apply(element); if (value == null) { map.remove(key); } else { map.merge(key, value, mergeFunction); } }, (map1, map2) -\u0026gt; { map2.forEach((key, value) -\u0026gt; { if (value != null) { map1.merge(key, value, mergeFunction); } }); return map1; }, Collector.Characteristics.UNORDERED); } Optional对象 将可能为 null 的对象包装在 Optional 容器中，强制开发者显式处理空值场景。\n1 Optional\u0026lt;String\u0026gt; name = Optional.ofNullable(getName()); 提供 map(), flatMap(), filter() 等方法，支持以函数式风格处理值：\n1 2 3 4 5 // 链式获取嵌套属性（避免多层判空） String province = Optional.ofNullable(user) .map(User::getAddress) // 若user非空，提取地址 .map(Address::getProvince) // 若地址非空，提取省份 .orElse(\u0026#34;未知地区\u0026#34;); // 若为空，返回默认值 深拷贝的三种方法 实现clone接口，要求引用属性全部实现clonable接口，递归调用。 直接序列化然后反序列化，要求引用属性全部实现serializable接口。 手动递归复制。 ","date":"2025-05-28T00:00:00Z","permalink":"https://sixiyida.github.io/p/%E6%97%A5%E5%B8%B8%E9%97%AE%E9%A2%98%E9%9B%86/","title":"日常问题集"},{"content":"线段树 核心思想：分治\n节点上维护[l, r]的某个值，左儿子节点维护[l, mid]，右儿子节点维护[mid + 1, r]。\n例题：LeetCode3479\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 class SegmentTree{ vector\u0026lt;int\u0026gt; mx; void maintain(int o){ mx[o] = max(mx[o * 2], mx[o * 2 + 1]); } void build(const vector\u0026lt;int\u0026gt; \u0026amp; a, int o, int l, int r) { if (l == r) { mx[o] = a[l]; return; } int m = (l + r) / 2; build(a, o * 2, l, m); build(a, o * 2 + 1, m + 1, r); maintain(o); //更新的关键操作 } public: SegmentTree(const vector\u0026lt;int\u0026gt; \u0026amp; a) { size_t n = a.size(); mx.resize(2 \u0026lt;\u0026lt; bit_width(n - 1));//? build(a, 1, 0, n - 1); } int findFirstAndUpdate(int o, int l, int r, int x) { if (mx[o] \u0026lt; x) { return -1; } if (l == r) { mx[o] = -1; return l; } int m = (l + r) /2; int i = findFirstAndUpdate(o * 2, l, m, x); if (i \u0026lt; 0) i = findFirstAndUpdate(o * 2 + 1, m + 1, r, x); maintain(o); return i; } }; Lazy线段树 为什么lazy？ ​\t待节点区间完全在需要更新的区间内时，则不继续向下更新，而是标为lazy标记，待下一次需要更新到子节点的时候，再把这个标记向下传递。\n例题：LeetCode2569\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 class LazySegmentTree{ private: vector\u0026lt;int\u0026gt; cnt; vector\u0026lt;int\u0026gt; todo; void maintain(int o) { cnt[o] = cnt[o * 2] + cnt[o * 2 + 1]; } void build(const vector\u0026lt;int\u0026gt; \u0026amp; a, int o, int l, int r) { if (l == r) { cnt[o] = a[l]; return; } int mid = (l + r) / 2; build(a, o * 2, l, mid); build(a, o * 2 + 1, mid + 1, r); maintain(o); } void reverse(int o, int l, int r) { cnt[o] = r - l + 1 - cnt[o]; todo[o] = !todo[o]; } public: LazySegmentTree(const vector\u0026lt;int\u0026gt; \u0026amp; a) { int n = a.size(); cnt.resize(4 * n); todo.resize(4 * n); build(a, 1, 0, n - 1); } void update(int o, int l, int r, int L, int R) { if (L \u0026lt;= l \u0026amp;\u0026amp; r \u0026lt;= R) { //cout \u0026lt;\u0026lt; l \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; r \u0026lt;\u0026lt; endl; reverse(o, l, r); return; } int m = (l + r) / 2; if (todo[o]) { reverse(o * 2, l, m); reverse(o * 2 + 1, m + 1, r); todo[o] = false; } if (m \u0026gt;= L) { update(o * 2, l, m, L, R); } if (m \u0026lt; R) { // m + 1 \u0026lt;= R update(o * 2 + 1, m + 1, r, L, R); } maintain(o); } int getRootVal() { return cnt[1]; } }; KMP算法 核心思想：主串指针不动，子串动。子串从next[sub_ptr]的位置启动，next的含义是从[0, fail_sub_ptr]的子串中，相同的最长真前后缀长度。\n","date":"2025-04-28T00:00:00Z","permalink":"https://sixiyida.github.io/p/algorithms/","title":"Algorithms"}]